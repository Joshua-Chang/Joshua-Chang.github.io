<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://Joshua-Chang.github.io</id>
    <title>Joshua-Chang`Blog</title>
    <updated>2021-07-06T05:37:59.110Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://Joshua-Chang.github.io"/>
    <link rel="self" href="https://Joshua-Chang.github.io/atom.xml"/>
    <subtitle>温故而知新</subtitle>
    <logo>https://Joshua-Chang.github.io/images/avatar.png</logo>
    <icon>https://Joshua-Chang.github.io/favicon.ico</icon>
    <rights>All rights reserved 2021, Joshua-Chang`Blog</rights>
    <entry>
        <title type="html"><![CDATA[JVM]]></title>
        <id>https://Joshua-Chang.github.io/post/jvm/</id>
        <link href="https://Joshua-Chang.github.io/post/jvm/">
        </link>
        <updated>2021-07-03T04:54:11.000Z</updated>
        <content type="html"><![CDATA[<table>
<thead>
<tr>
<th><img src="https://i.imgur.com/FlYWN1d.png" alt="image-20210703132213706" loading="lazy"></th>
<th><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210703131238763.png" alt="123" loading="lazy"></th>
</tr>
</thead>
<tbody></tbody>
</table>
<p>之所以要在虚拟机中运行，是因为它提供了可移植性。一旦 Java 代码被编译为 Java 字节码，便可以在不同平台上的 Java 虚拟机实现上运行。此外，虚拟机还提供了一个代码托管的环境，代替我们处理部分冗长而且容易出错的事务，例如内存管理。</p>
<table>
<thead>
<tr>
<th><img src="https://static001.geekbang.org/resource/image/ab/77/ab5c3523af08e0bf2f689c1d6033ef77.png" style="zoom:50%;" /></th>
<th><img src="https://static001.geekbang.org/resource/image/5e/3b/5ee351091464de78eed75438b6f9183b.png" style="zoom:50%;" /></th>
</tr>
</thead>
<tbody></tbody>
</table>
<p>Java 虚拟机将运行时内存区域划分为五个部分，分别为方法区、堆、PC 寄存器、Java 方法栈和本地方法栈。Java 程序编译而成的 class 文件，需要先加载至方法区中，方能在 Java 虚拟机中运行。<br>
为了提高运行效率，标准 JDK 中的 HotSpot 虚拟机采用的是一种混合执行的策略。它会解释执行 Java 字节码，然后会将其中反复执行的热点代码，以方法为单位进行即时编译，翻译成机器码后直接运行在底层硬件之上。<br>
HotSpot 装载了多个不同的即时编译器，以便在编译时间和生成代码的执行效率之间做取舍。</p>
<figure data-type="image" tabindex="1"><img src="https://static001.geekbang.org/resource/image/77/45/77dfb788a8ad5877e77fc28ed2d51745.png" alt="1" loading="lazy"></figure>
<p>boolean 类型在 Java 虚拟机中被映射为整数类型：“true”被映射为 1，而“false”被映射为 0。Java 代码中的逻辑运算以及条件跳转，都是用整数相关的字节码来实现的。</p>
<p>除 boolean 类型之外，Java 还有另外 7 个基本类型。它们拥有不同的值域，但默认值在内存中均为 0。这些基本类型之中，浮点类型比较特殊。基于它的运算或比较，需要考虑 +0.0F、-0.0F 以及 NaN 的情况。</p>
<p>在局部变量中除 long 和 double 外，boolean、byte、char、short 这四种类型，在栈上占用的空间和 int 是一样的，和引用类型也是一样的在 32/64位的 HotSpot 中，这些类型在栈上将占用 4 /8个字节。</p>
<p>但在存储于堆中的字段或者数组元素上。对于 byte、char 以及 short 这三种类型的字段或者数组单元，它们在堆上占用的空间分别为一字节、两字节，以及两字节，跟这些类型的值域相吻合。</p>
<p>在将 boolean、byte、char 以及 short 的值存入字段或者数组单元时，Java 虚拟机会进行掩码操作。在读取时，Java 虚拟机则会将其扩展为 int 类型。</p>
<p>Java 虚拟机将字节流转化为 Java 类的过程分为加载、链接以及初始化三大步骤。</p>
<p>加载是指查找字节流，并且据此创建类的过程。加载需要借助类加载器，在 Java 虚拟机中，类加载器使用了双亲委派模型，即接收到加载请求时，会先将请求转发给父类加载器。</p>
<p>链接，是指将创建成的类合并至 Java 虚拟机中，使之能够执行的过程。链接还分验证、准备和解析三个阶段。其中，解析阶段为非必须的。</p>
<p>初始化，则是为标记为常量值的字段赋值，以及执行 &lt; clinit &gt; 方法的过程。Java 虚拟机会通过加锁来确保类的 &lt; clinit &gt; 方法仅被执行一次，这个特性被用来实现单例的延迟初始化。</p>
<p>在 Java 中，方法存在重载以及重写的概念，重载指的是方法名相同而参数类型不相同的方法之间的关系，重写指的是方法名相同并且参数类型也相同的方法之间的关系。</p>
<p>Java 虚拟机识别方法的方式略有不同，除了方法名和参数类型之外，它还会考虑返回类型。</p>
<p>在 Java 虚拟机中，静态绑定指的是在解析时便能够直接识别目标方法的情况，而动态绑定则指的是需要在运行过程中根据调用者的动态类型来识别目标方法的情况。由于 Java 编译器已经区分了重载的方法，因此可以认为 Java 虚拟机中不存在重载。</p>
<p>在 class 文件中，Java 编译器会用符号引用指代目标方法。在执行调用指令前，它所附带的符号引用需要被解析成实际引用。对于可以静态绑定的方法调用而言，实际引用为目标方法的指针。对于需要动态绑定的方法调用而言，实际引用为辅助动态绑定的信息。</p>
<img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210703193948926.png" alt="image-20210703193948926" style="zoom:50%;" />
<table>
<thead>
<tr>
<th><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210703194854583.png" alt="83" loading="lazy"></th>
<th><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210703195002837.png" alt="" loading="lazy"></th>
</tr>
</thead>
<tbody></tbody>
</table>
<table>
<thead>
<tr>
<th>jdk9模块化</th>
<th>Jdk8没模块化</th>
</tr>
</thead>
<tbody>
<tr>
<td><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210703215452248.png" alt="image-20210703215452248" loading="lazy"></td>
<td><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210703215551942.png" alt="image-20210703215551942" loading="lazy"></td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210703222834382.png" alt="image-20210703222834382" loading="lazy"></th>
<th><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210703224610137.png" alt="image-20210703224610137" loading="lazy"></th>
</tr>
</thead>
<tbody></tbody>
</table>
<p>Java 类的过程分为加载、链接(验证、准备和解析)以及初始化。然后才能使用，用完既可卸载。</p>
<table>
<thead>
<tr>
<th><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210703235422140.png" alt="image-20210703235422140" loading="lazy"><br /><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210703235546550.png" alt="image-20210703235546550" loading="lazy"></th>
<th>类连结中的准备：为类的静态变量分配内存并赋缺省值如0，赋真正的初始值（=?）实在初始化阶段<img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210703235014519.png" alt="image-20210703235014519" loading="lazy"></th>
<th><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210703235942762.png" alt="image-20210703235942762" loading="lazy"><br/>初始化语句=静态属性/方法/代码块<img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210704000507286.png" alt="image-20210704000507286" loading="lazy"><br /><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210704000811687.png" alt="image-20210704000811687" loading="lazy"></th>
</tr>
</thead>
<tbody>
<tr>
<td><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210704101912989.png" alt="image-20210704101912989" loading="lazy"><br />8）初次调用 MethodHandle 时</td>
<td><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210704102210346.png" alt="image-20210704102210346" loading="lazy"><br />主类=main方法类</td>
<td><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210704115557956.png" alt="image-20210704115557956" loading="lazy"></td>
</tr>
</tbody>
</table>
<p>不会触发类的初始化的特殊情况即<strong>被动引用</strong>：</p>
<ol>
<li>通过子类去引用父类的静态字段时，不会导致子类的初始化。<code>System.out.println(ChildClazz.parentStr);</code></li>
<li>数组引用类时，不会触发类的初始化 <code>MyClazz clz=new MyClazz[2]</code></li>
<li>引用类的常量(static final)不会导致类的初始化。</li>
</ol>
<pre><code class="language-java">public class MyClassIS {
    private static MyClassIS myClassIS = new MyClassIS();
    private static int a = 0;
    private static int b;//b=0时结果b也为0
//  private static MyClassIS myClassIS = new MyClassIS();顺序调换时，都为1
    private MyClassIS(){
        a++;
        b++;
    }
    public static MyClassIS getInstance() {
        return myClassIS;
    }
    public int getA() {
        return a;
    }
    public int getB() {
        return b;
    }
}
-------------------类的初始化顺序问题--------------------
public class App {
    public static void main(String[] args) throws Exception {
        MyClassIS myClassIS=MyClassIS.getInstance();
        System.out.println(myClassIS.getA()+&quot; : &quot;+myClassIS.getB());
    }
}
</code></pre>
<ol>
<li>连结-准备阶段：对静态变量ab赋缺省值0</li>
<li>初始化阶段：初始化(静态)语句依次执行，第一行，构造方法时0++ ab=1</li>
<li>初始化阶段：初始化(静态)语句依次执行，二三行，a=0 b=1。即对静态变量赋初始值a=0，b没初始值还=1</li>
</ol>
<p>类加载<strong>初始化</strong>时除常量之外的初始化语句(静态字段/方法/代码块)会被 Java 编译器置于&lt; clinit &gt;方法中。基本类型或字符串类型的静态字段被 final 所修饰时，会被 Java 编译器标记成常量值（ConstantValue），其初始化直接由 Java 虚拟机完成。</p>
<p>类加载的初始化，便是为标记为常量值的字段赋值，以及执行 &lt; clinit &gt; 方法的过程。Java 虚拟机会通过加锁来确保类的 &lt; clinit &gt; 方法仅被执行一次。</p>
<table>
<thead>
<tr>
<th><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210704124551809.png" alt="image-20210704124551809" loading="lazy"><br /><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210704124613379.png" alt="image-20210704124613379" loading="lazy"></th>
<th><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210704124952132.png" alt="image-20210704124952132" loading="lazy"><br /><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210704125231430.png" alt="image-20210704125231430" loading="lazy"></th>
</tr>
</thead>
<tbody>
<tr>
<td><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210704130004781.png" alt="image-20210704130004781" loading="lazy"></td>
<td><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210704130028605.png" alt="image-20210704130028605" loading="lazy"><br />jdk8以后永久区改为元空间</td>
</tr>
<tr>
<td><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210704130646995.png" alt="image-20210704130646995" loading="lazy"></td>
<td><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210704131016908.png" alt="image-20210704131016908" loading="lazy"></td>
</tr>
</tbody>
</table>
<blockquote>
<p>栈内存线程私有，堆内存线程共享。但堆内存的分配是通常被很少讨论，但实际却很复杂的。</p>
<p>堆内存的分配通常用指针碰撞法、空闲列表法。但是堆是全局共享的，在同一时间可能会有多个线程并发地在堆上分配空间。解决并发问题用CAS、TLAB(hotspot用：给每个线程在堆里预分配一块区域，分配完成后便不再线程独享。因此hotspot中的TLAB可以在堆里”线程私有“)</p>
</blockquote>
<table>
<thead>
<tr>
<th><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210704141903971.png" alt="image-20210704141903971" loading="lazy"></th>
<th><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210704141934898.png" alt="image-20210704141934898" loading="lazy"></th>
</tr>
</thead>
<tbody></tbody>
</table>
<table>
<thead>
<tr>
<th><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210704142122235.png" alt="image-20210704142122235" loading="lazy"><br /><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210704142206299.png" alt="image-20210704142206299" loading="lazy"></th>
<th><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210704142318308.png" alt="image-20210704142318308" loading="lazy"></th>
</tr>
</thead>
<tbody></tbody>
</table>
<p>引用类型(reference)访问对象实例的方式：</p>
<table>
<thead>
<tr>
<th><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210704142407666.png" alt="image-20210704142407666" loading="lazy"></th>
<th><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210704142429226.png" alt="image-20210704142429226" loading="lazy"></th>
</tr>
</thead>
<tbody>
<tr>
<td><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210704142515397.png" alt="image-20210704142515397" loading="lazy"></td>
<td><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210704142627592.png" alt="image-20210704142627592" loading="lazy"></td>
</tr>
<tr>
<td>对象实例发生变化只影响句柄指向不影响reference</td>
<td></td>
</tr>
<tr>
<td>间接引用，两次指针定位速度慢</td>
<td>速度快</td>
</tr>
</tbody>
</table>
<p>Trace跟踪参数</p>
<table>
<thead>
<tr>
<th>-Xlog:gc/-Xlog:gc*</th>
<th>打印GC简要/详细信息</th>
</tr>
</thead>
<tbody>
<tr>
<td>-Xlog:gc:filename</td>
<td>GC文件输出</td>
</tr>
<tr>
<td>-Xlog:gc+heap=debug</td>
<td>每次GC后都打印堆信息</td>
</tr>
</tbody>
</table>
<p>GC日志格式：GC发生时间(jvm启动以来的秒数)、日志级别/类型、GC识别号(第几次GC)、GC类型/原因、GC容量:GC前-&gt;GC后(该区总容量)、GC持续时间秒：user/sys/real 应用/系统内核/真正耗时</p>
<p>Java栈的参数</p>
<table>
<thead>
<tr>
<th>-Xss</th>
<th>通常几百k，决定了函数的调用深度</th>
</tr>
</thead>
<tbody></tbody>
</table>
<p>Java堆的参数</p>
<table>
<thead>
<tr>
<th>-Xms</th>
<th>初始堆大小</th>
<th>默认：物理内存的1/64</th>
<th>XX:InitialHeapSize</th>
</tr>
</thead>
<tbody>
<tr>
<td>-Xmx</td>
<td>最大堆大小</td>
<td>默认：物理内存的1/4</td>
<td>XX:MaxHeapSize</td>
</tr>
<tr>
<td>-Xmn</td>
<td>新生代大小</td>
<td>默认：物理内存的3/8</td>
<td></td>
</tr>
<tr>
<td>XX:MinHeapSize</td>
<td>最小堆大小</td>
<td></td>
<td></td>
</tr>
<tr>
<td>-XX:+UseConcMarkSweepGC</td>
<td></td>
<td></td>
<td>CMS收集器</td>
</tr>
<tr>
<td>-XX:+HeapDumpOnOutOfMemoryError</td>
<td></td>
<td>不指定路径则运行路径</td>
<td>OOM时导出堆内存快照到文件</td>
</tr>
<tr>
<td>-XX:+HeapDumpPath</td>
<td></td>
<td></td>
<td>导出OOM的路经</td>
</tr>
<tr>
<td>-XX:NewRatio</td>
<td>老/新</td>
<td>默认2</td>
<td>老年代/新生代的比率</td>
</tr>
<tr>
<td>-XX:ServivorRatio</td>
<td>Eden/Survivor</td>
<td>Survivor:from/to</td>
<td>1个Eden/1个Survivor的比率</td>
</tr>
</tbody>
</table>
<blockquote>
<p>Survivor分成两份，From区和To区（两个区不同时存在，只做拷贝算法时区分）。-XX:ServivorRatio=8时，1eden/1Survivor=8/1 实际Survivor存在两份因此eden/2Survivor=8/2。每个Survivor占新生代的1/10</p>
</blockquote>
<p>在JDK新版本默认G1收集器之前，默认使用的是CMS收集器。</p>
<table>
<thead>
<tr>
<th><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210704221125426.png" alt="image-20210704221125426" loading="lazy"></th>
<th><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210704221153895.png" alt="image-20210704221153895" loading="lazy"></th>
</tr>
</thead>
<tbody>
<tr>
<td><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210704221248193.png" alt="image-20210704221248193" loading="lazy"><br />静态方法就没有this<img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210704221355962.png" alt="image-20210704221355962" loading="lazy"></td>
<td><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210705012342931.png" alt="image-20210705012342931" loading="lazy"><br /><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210705012436995.png" alt="image-20210705012436995" loading="lazy"><br /><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210705012846529.png" alt="image-20210705012846529" loading="lazy"></td>
</tr>
</tbody>
</table>
<p>实例方法：是区别与静态方法的叫法，即要初始化一个实例才能调用的方法。不同于静态方法[类名.方法名]的调用，多数都是实例方法。因此类外的才叫函数。</p>
<p>方法分派：</p>
<p>静态分派：根据方法名称、参数不同再编译器就决定的<strong>重载方法</strong>。</p>
<p>动态分派：多态下运行时才能决定到底是哪个实例调用的<strong>重写方法</strong>。</p>
<pre><code class="language-java">//局部变量表5:只有把bs包裹住，再用方案覆盖slot槽位/置空bs，剩余的内存才会变多
public static void main(String[] args) {
    {//用方法块包裹住局部变量
        byte[] bs = new byte[2 * 1024 * 1024];//局部变量bs的作用域为其所在方法块
    //  bs=null;//方案二：bs指向堆的空间置空
    }//bs出了作用域就可以被回收
    //  int a = 5;//方案一：覆盖bs槽位
    System.gc();//并不一定保证GC
    //slot槽位情况
    //0--args
    //1--bs-----指向堆空间放着2M数据   gc时本地变量表还在用bs
    //1--a将槽位1给局部变量a复用
    System.out.println(&quot;free:&quot; + Runtime.getRuntime().freeMemory() / 1024.0 / 1024.0);
}
</code></pre>
<pre><code class="language-java">public class Test3 {
    public void m1(Object a) {
        System.out.println(&quot;Object &quot; + a);
    }
    public void m1(Integer a) {
        System.out.println(&quot;Integer &quot; + a);
    }
    public void m1(int a) {
        System.out.println(&quot;int &quot; + a);
    }
    public void m1(String a) {//静态分派：重载
        System.out.println(&quot;string &quot; + a);
    }
    public static class Child extends Test3 {
//        public void m1(int a) {
//            System.out.println(&quot;child int &quot;+a);
//        }
        public void m1(int a,int b) {
            System.out.println(&quot;child a+b int &quot;+a+b);
        }
    }

    public static void main(String[] args) {
//        Test3 t = new Test3();
        Test3 t = new Child();//动态分派：重写。看实例是child还是parent
//        t.m1(&quot;str&quot;);
        t.m1(5);//当前实例有这个方法就调，没有就调父类的。父类方法可以重载，重载方法存在范围覆盖时：int方法没有则调用Integer再没有则Obj。从小范围到大范围。
//        t.m1(Integer.valueOf(5));
//        t.m1(new Object());重载方法存在参数范围覆盖时，优先调用精准的小范围。object是最大的范围，因此只能调用object这一个方法。
        //第一个维度先看动态分派是子类还是父类实例的方法
        //第二个维度再看静态分派匹配同名不同参数的方法
    }
}
</code></pre>
<pre><code class="language-java">public int add(int a, int b) {//栈帧-操作数栈
    int c = a + b;
    return a + b + c;
}
 0: iload_1     导入int 参数1 对应局部变量表的a
 1: iload_2
 2: iadd
 3: istore_3    存入int 参数3 对应c
 4: iload_1
 5: iload_2
 6: iadd        int相加 a+b
 7: iload_3
 8: iadd        a+b+c
 9: ireturn     返回int
 LineNumberTable:
 line 5: 0
 line 6: 4
 LocalVariableTable:
 Start  Length  Slot  Name   Signature
 0      10     0  this   Lcom/data/execute/Test2;
 0      10     1     a   I
 0      10     2     b   I
 4       6     3     c   I
</code></pre>
<p>可做为GC Roots对象包括：</p>
<ol>
<li>虚拟机栈中所引用到的对象（局部变量表引用的）</li>
<li>方法区中类的静态属性引用的对象</li>
<li>方法区中常量引用的对象</li>
<li>本地方法栈中jni引用的对象</li>
<li>所有被synchronized同步锁持有的对象</li>
</ol>
<p>SoftReference：GC后内存还不够就回收，WeakReference：GC时回收掉，PhantomReference发生GC就会被回收掉。</p>
<p>判断是否为垃圾的步骤：</p>
<p>首先根搜索算法判断，若对象没有引用链，然后看是否要执行finalize方法自救一次。最后又没引用链又不需要自救即为垃圾。</p>
<p>MinorGC/YoungGC：发生在新生代的GC</p>
<p>Major/OldGC：发生在老年代的GC。目前只有CMS收集器存在单独收集老年代垃圾的行为。</p>
<p>MixedGC：收集整个新生代和部分老年代的GC。目前只有G1收集器有这种行为。</p>
<p>FullGC：收集整个Java堆和方法区的GC。</p>
<p><strong>STW</strong>：stop-the-world 多半由GC引起的全局暂停。</p>
<p><strong>safe-point</strong>：HotSpot使用OopMap（描述对象之间引用关系的数据结构）达到准确的GC，而不必从root查找。JVM并不是为所有的指令都生成一个OopMap，线程只有执行到记录OopMap的特定位置，才允许暂停下来进行GC。这些&quot;特定位置&quot;即Safe-Point。</p>
<table>
<thead>
<tr>
<th><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210705132501413.png" alt="image-20210705132501413" loading="lazy"></th>
<th><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210705132550761.png" alt="image-20210705132550761" loading="lazy"><br />4无法再任何地方通过反射访问这个类<br /><br />没有用的类JVM就可以把它从内存卸载</th>
</tr>
</thead>
<tbody></tbody>
</table>
<table>
<thead>
<tr>
<th><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210705184127924.png" alt="image-20210705184127924" loading="lazy"></th>
<th><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210705184301530.png" alt="image-20210705184301530" loading="lazy"></th>
<th><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210705184228618.png" alt="image-20210705184228618" loading="lazy"></th>
</tr>
</thead>
<tbody>
<tr>
<td><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210705184407694.png" alt="image-20210705184407694" loading="lazy"></td>
<td><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210705184344602.png" alt="image-20210705184344602" loading="lazy"></td>
<td><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210705184445983.png" alt="image-20210705184445983" loading="lazy"></td>
</tr>
<tr>
<td><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210705190413920.png" alt="image-20210705190413920" loading="lazy"></td>
<td><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210705190518042.png" alt="image-20210705190518042" loading="lazy"></td>
<td></td>
</tr>
</tbody>
</table>
<p>HotSpot默认Eden和Survivor是8：1，即新生代90%空间可用。若新生代垃圾回收后，存活区放不下了，要依赖老年代(元空间)进行<strong>分配担保</strong>，来把放不下的对象直接进入老年代，流程如下：</p>
<ul>
<li>在新生代GC(MinorGC)前，JVM检查老年代的最大可用连续空间，看其是否大于新生代所有对象的总空间，</li>
<li>若大于则取保新生代GC是安全的；</li>
<li>若小于则检查是否设置了[允许担保失败]，若设置了则检查老年代的最大可用空间，看其是否大于历次晋升到老年代对象的平均值：大于则进行新生代GC(MinorGC);不大于则该做一次Full GC。</li>
</ul>
<table>
<thead>
<tr>
<th><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210705190637047.png" alt="image-20210705190637047" loading="lazy"></th>
<th><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210705194007855.png" alt="image-20210705194007855" loading="lazy"></th>
</tr>
</thead>
<tbody></tbody>
</table>
<blockquote>
<p>HotSpot中：新生代使用ParNew收集器时。老年代使用CMS收集器，同时把SerialOld作为备用。</p>
</blockquote>
<table>
<thead>
<tr>
<th><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210705191207939.png" alt="image-20210705191207939" loading="lazy"></th>
<th><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210705191131988.png" alt="image-20210705191131988" loading="lazy"></th>
</tr>
</thead>
<tbody>
<tr>
<td><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210705191420093.png" alt="image-20210705191420093" loading="lazy"></td>
<td><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210705191756628.png" alt="image-20210705191756628" loading="lazy"><br /><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210705191844011.png" alt="image-20210705191844011" loading="lazy"><br />-XX:ParallelGCThreads指定线程数最好和cpu核数一致</td>
</tr>
<tr>
<td><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210705191510815.png" alt="image-20210705191510815" loading="lazy"></td>
<td><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210705192110314.png" alt="image-20210705192110314" loading="lazy"><br /><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210705192425140.png" alt="image-20210705192425140" loading="lazy"><br />-XX:+UseParallelGC/-XX:+UseParallelOldGC开启<br /></td>
</tr>
<tr>
<td><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210705191602749.png" alt="image-20210705191602749" loading="lazy"></td>
<td><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210705192626044.png" alt="image-20210705192626044" loading="lazy"><br /><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210705192803209.png" alt="image-20210705192803209" loading="lazy"><br /><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210705192849309.png" alt="image-20210705192849309" loading="lazy"></td>
</tr>
<tr>
<td><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210705191641957.png" alt="image-20210705191641957" loading="lazy"></td>
<td><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210705193041560.png" alt="image-20210705193041560" loading="lazy"><br /><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210705193128793.png" alt="image-20210705193128793" loading="lazy"><br /><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210705193225337.png" alt="image-20210705193225337" loading="lazy"></td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210705191602749.png" alt="image-20210705191602749" loading="lazy"></th>
<th><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210705192626044.png" alt="image-20210705192626044" loading="lazy"><br /><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210705192803209.png" alt="image-20210705192803209" loading="lazy"></th>
<th><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210705192849309.png" alt="image-20210705192849309" loading="lazy"></th>
</tr>
</thead>
<tbody>
<tr>
<td><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210705191641957.png" alt="image-20210705191641957" loading="lazy"><br /><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210705193823497.png" alt="image-20210705193823497" loading="lazy"></td>
<td><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210705193041560.png" alt="image-20210705193041560" loading="lazy"><br /><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210705193128793.png" alt="image-20210705193128793" loading="lazy"><br /><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210705193225337.png" alt="image-20210705193225337" loading="lazy"></td>
<td><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210705193649657.png" alt="image-20210705193649657" loading="lazy"><br /><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210705193717877.png" alt="image-20210705193717877" loading="lazy"><br /></td>
</tr>
</tbody>
</table>
<p>GC性能指标：</p>
<ul>
<li>吞吐量：非GC执行的时间/运行总时间</li>
<li>GC负荷，与吞吐量相反 ：GC时间/运行总时间</li>
<li>暂停时间：STW的总时间</li>
<li>GC频率：一个时间段发生GC的次数</li>
<li>反应速度：对象成为垃圾到被回收的时间</li>
</ul>
<table>
<thead>
<tr>
<th><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210706004744232.png" alt="image-20210706004744232" loading="lazy"></th>
<th><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210706005149482.png" alt="image-20210706005149482" loading="lazy"></th>
</tr>
</thead>
<tbody>
<tr>
<td><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210706005641447.png" alt="image-20210706005641447" loading="lazy"><br /><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210706005728965.png" alt="image-20210706005728965" loading="lazy"><br /><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210706005819841.png" alt="image-20210706005819841" loading="lazy"></td>
<td><img src="/Users/joshuachang/Library/Application%20Support/typora-user-images/image-20210706004821761.png" alt="image-20210706004821761" loading="lazy"><br /><img src="file:///Users/joshuachang/Library/Application%20Support/typora-user-images/image-20210706004920244.png?lastModify=1625503879" alt="image-20210706004920244" loading="lazy"><br /><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210706005012823.png" alt="image-20210706005012823" loading="lazy"></td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210706005935649.png" alt="image-20210706005935649" loading="lazy"><br /><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210706010008067.png" alt="image-20210706010008067" loading="lazy"><br /><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210706010111759.png" alt="image-20210706010111759" loading="lazy"></th>
<th><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210706010136210.png" alt="image-20210706010136210" loading="lazy"><br /><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210706010212690.png" alt="image-20210706010212690" loading="lazy"><br /><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210706010245048.png" alt="image-20210706010245048" loading="lazy"></th>
<th><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210706004158281.png" alt="image-20210706004158281" loading="lazy"><br />上文的锁优化JVM内自动进行<img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210706010319025.png" alt="image-20210706010319025" loading="lazy"></th>
</tr>
</thead>
<tbody></tbody>
</table>
<pre><code class="language-java">Integer a=1;//字节码指令是invokeStatic Integer.valueOf()即把基本类型封装成Integer对象
if (x==2){}//字节码指令是invokeStatic Integer.intValue()即从Integer解封出基本类型
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[重学操作系统]]></title>
        <id>https://Joshua-Chang.github.io/post/chong-xue-cao-zuo-xi-tong/</id>
        <link href="https://Joshua-Chang.github.io/post/chong-xue-cao-zuo-xi-tong/">
        </link>
        <updated>2021-06-20T10:26:58.000Z</updated>
        <content type="html"><![CDATA[<h1 id="计算机组成原理">计算机组成原理</h1>
<p><strong>希尔伯特问题</strong>中的<strong>公理化体系问题</strong>（这个世界可以建立一套完善的公理体系，由少数几个公理出发，推导出所有的定理和推论）和<strong>哥德尔不完备性定理</strong>（即便在完善的公理体系中仍然可以找到不能被证明也不能被证伪的命题。）哥德尔的不完备性定理，让大家看到了世界上还有大量不可计算的问题。哪些问题可以被计算，哪些不可以被计算，这就是图灵的可计算理论。比如不可计算的停机问题。</p>
<p>我们今天有能力解决的问题，统称为多项式时间（ Polynomial time）问题记作P问题，反之问题如果不能在多项式时间内找到答案，我们记为 NP 问题，有一部分 NP 问题可以被转化为 P 问题。</p>
<p><img src="https://s0.lgstatic.com/i/image/M00/4C/CB/Ciqc1F9YoMSAa9_WAADEZsnCSoU226.png" alt="4.png" style="zoom:50%;" /><img src="https://s0.lgstatic.com/i/image/M00/4E/A2/CgqCHl9e5VaANB2BAAEVncqxxwI213.png" alt="1.png" style="zoom:50%;" /></p>
<p><strong>内存</strong></p>
<p>在冯诺依曼模型中，程序和数据被存储在一个被称作内存的线性排列存储区域。存储的数据单位是一个二进制位即bit。最小的存储单位字节为8 位即 byte，每一个字节都对应一个内存地址。内存地址由 0 开始编号然后自增排列。</p>
<p>我们通常说的内存都是随机存取器，也就是读取任何一个地址数据的速度是一样的，写入任何一个地址数据的速度也是一样的。</p>
<p><strong>CPU</strong></p>
<p>冯诺依曼模型中 CPU 负责控制和计算。</p>
<p>32和64位指的是CPU的位宽，即一次可运算的位(bit)数。32位(4 byte)/64位(8 byte)</p>
<p>线路位宽：一个 bit，低电压是 0，高电压是 1，1 条地址总线操作 2 个内存地址。32 位宽的 CPU最多只有 32 位的寄存器，对应32条总线，最多操作 23^2 个内存地址，也就是 4G 内存地址。</p>
<p>计算层面的话，64位CPU在计算大数据的时候比32位更高效，但是这种场景不多。</p>
<p>通信层面，64位可以操作更大的内存，以及和内存之间进行更高速的通信，因为支持的地址总线更大。</p>
<p><strong>控制单元和逻辑运算单元</strong></p>
<p>CPU 中有一个控制单元专门负责控制 CPU 工作；还有逻辑运算单元专门负责计算。</p>
<p><strong>寄存器</strong></p>
<p>CPU 要进行计算，比如最简单的加和两个数字时，因为 CPU 离内存太远，所以需要一种离自己近的存储来存储将要被计算的数字。这种存储就是寄存器。寄存器就在 CPU 里，控制单元和逻辑运算单元非常近，因此速度很快。</p>
<ol>
<li>
<p>寄存器中有一部分是可供用户编程用的，比如用来存加和指令的两个参数，是<strong>通用寄存器。</strong></p>
</li>
<li>
<p>还有一部分寄存器有特殊的用途，叫作<strong>特殊寄存器</strong>。比如程序指针，就是一个特殊寄存器。它存储了 CPU 要执行的下一条指令所在的内存地址。注意，程序指针不是存储了下一条要执行的指令，此时指令还在内存中，程序指针只是存储了下一条指令的地址。</p>
</li>
<li>
<p>下一条要执行的指令，会从内存读入到另一个特殊的寄存器中，这个寄存器叫作<strong>指令寄存器</strong>。指令被执行完成之前，指令都存储在这里。</p>
</li>
</ol>
<p><strong>总线</strong></p>
<p>CPU 和内存以及其他设备之间，也需要通信，因此我们用一种特殊的设备进行控制，就是总线。</p>
<p><strong>地址总线</strong>，专门用来指定 CPU 将要操作的内存地址。</p>
<p>**数据总线，**用来读写内存中的数据。</p>
<p>当 CPU 需要读写内存的时候，先要通过地址总线来指定内存地址，再通过数据总线来传输数据。</p>
<p><strong>控制总线</strong>，用来发送和接收关键信号，比如后面我们会学到的中断信号，还有设备复位、就绪等信号，都是通过控制总线传输。同样的，CPU 需要对这些信号进行响应，这也需要控制总线。</p>
<p><strong>程序的执行过程</strong></p>
<p>所有的计算机程序，也都可以抽象为从<strong>输入设备</strong>读取输入信息，通过<strong>运算器</strong>和<strong>控制器</strong>来执行存储在<strong>存储器</strong>里的程序，最终把结果输出到<strong>输出设备</strong>中。</p>
<img src="https://s0.lgstatic.com/i/image/M00/4E/C8/Ciqc1F9fGs2AEfeRAADnPPOm_gU294.png" alt="图片1 (1).png" style="zoom:50%;" />
<p>冯诺依曼模型中：</p>
<p><strong>处理器单元</strong>（Processing Unit）。用来完成各种算术和逻辑运算。由<strong>算术逻辑单元</strong>（Arithmetic Logic Unit，ALU）和<strong>处理器寄存器</strong>（Processor Register）组成。</p>
<p><strong>控制器单元</strong>（Control Unit/CU）用来控制程序的流程，通常就是不同条件下的分支和跳转。由<strong>指令寄存器（Instruction Reigster）<strong>和</strong>程序计数器</strong>（Program Counter PC）组成。</p>
<ol>
<li>
<p>CPU 读取 PC 指针指向的指令，将它从存储器导入指令寄存器。<br>
CPU 的控制单元操作地址总线指定需要访问的内存地址（简单理解，就是把 PC 指针中的值拷贝到地址总线中）。</p>
<p>CPU 通知内存设备准备数据（内存设备准备好了，就通过数据总线将数据传送给 CPU）。</p>
<p>CPU 收到内存传来的数据后，将这个数据存入指令寄存器。</p>
</li>
<li>
<p>CPU 分析指令寄存器中的指令，确定指令的类型和参数。计算类型的指令，交给逻辑运算单元计算；存储类型的指令，由控制单元执行。</p>
</li>
<li>
<p>PC 指针自增，并准备获取下一条指令。比如在 32 位的机器上，指令是 32 位 4 个字节，需要 4 个内存地址存储，因此 PC 指针会自增 4。</p>
</li>
</ol>
<p>构造指令的过程，叫作指令的编码，通常由编译器完成；解析指令的过程，叫作指令的解码，由 CPU 完成。 CPU 内部有一个循环也叫CPU 的指令周期</p>
<img src="https://s0.lgstatic.com/i/image/M00/4E/DF/Ciqc1F9fMKiAZhMVAABIVEePzcA916.png" alt="image (1).png" style="zoom:33%;" />
<ol>
<li>
<p>首先 CPU 通过 PC 指针读取对应内存地址的指令，我们将这个步骤叫作 Fetch，就是获取的意思。</p>
</li>
<li>
<p>CPU 对指令进行解码，我们将这个部分叫作 Decode。</p>
</li>
<li>
<p>CPU 执行指令，我们将这个部分叫作 Execution。</p>
</li>
<li>
<p>CPU 将结果存回寄存器或者将寄存器存入内存，我们将这个步骤叫作 Store。</p>
</li>
</ol>
<p>不同 CPU 的指令和寄存器名称都不一样，但比如 PC 指针、指令寄存器等通用。指令的执行速度为时钟周期，在 CPU 内部，和我们平时戴的电子石英表类似，有一个叫晶体振荡器（Oscillator Crystal）的东西，简称为晶振。我们把晶振当成 CPU 内部的电子表来使用。晶振带来的每一次“滴答”，就是时钟周期时间。在2.8GHz 的 CPU 上，这个时钟周期时间，就是 1/2.8G。</p>
<p>不同的机器助记符也不一样，汇编语言的指令也不同</p>
<p>for循环是通过标记,判断和跳转完成指令操作。if-else 是通过判断和跳转完成，需要最多n-1次判断。相对于if-else的自上而下的判断，switch 则更多是数学计算。</p>
<p><strong>函数</strong>的执行过程，调用前先把返回值(占位)和返回地址(调用前 PC 指针位置)提前压栈，然后载压入参数。</p>
<blockquote>
<p>调用函数其实就是跳转到函数体对应的指令所在的位置，因此函数名可以用一个标签，调用时，就用 <code>jump</code> 指令跟这个标签。</p>
</blockquote>
<p><strong>class</strong>分为两个部分属性和函数。构造函数是为class内的属性和方法分配内存地址，构造函数执行时扫描类型定义中所有的属性和方法，是属性则分配内存地址;（ 遇到方法时根据不同语言基于虚函数表、基于闭包、基于哈希表等的实现可能并不像成员变量一样占用class堆或栈的内存空间，而是直接放在代码区。）</p>
<p>this是构造函数创建的一个指向 class 实例的地址，一旦调用构造函数初始化，this关键字则最先压入栈，这样任何函数都可以访问实例中的属性和函数。</p>
<p>联想到：</p>
<p>1：函数调用，需要分配栈空间，如果递归调用太深，不停的压栈，很可能出现栈内存溢出</p>
<p>2.java中，每个方法被执行的时候，Java虚拟机都会为方法调用所在线程同步创建一个栈帧用于存储局部变量表、操作数栈、方法出口信息。每一个方法被调用直至执行完毕的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。</p>
<p><strong>存储器分级策略</strong></p>
<p>在时钟信号是 1GHz 的 CPU里，1G 代表 10 个亿，因此时钟信号的一个周期是 1/10 亿秒。而信号又是以光速传输的，光的速度是 3×10 的 8 次方米每秒，就是 3 亿米每秒。所以在一个周期内，光只能前进 30 厘米。</p>
<table>
<thead>
<tr>
<th><img src="https://s0.lgstatic.com/i/image/M00/51/2D/Ciqc1F9kgVGAD_IMAACXR1QKcDo779.png" alt="Lark20200918-174334.png"/></th>
<th><img src="https://s0.lgstatic.com/i/image/M00/51/2C/Ciqc1F9kgMWAAU1JAABxd6qpCo0763.png" alt="Lark20200918-173926.png" style="zoom75%;" /></th>
</tr>
</thead>
<tbody></tbody>
</table>
<p>寄存器紧挨着 CPU 的控制单元和逻辑计算单元，每个寄存器存储4/8个byte（32/64位），一条要在 4 个周期内完成的指令，除了读写寄存器，还需要解码指令、控制指令执行和计算。通常寄存机的访问速度一般要求在半个 CPU 时钟周期内完成读写。</p>
<ol>
<li>L1-Cache 大小在几十 Kb 到几百 Kb 不等，读写速度在 2~4 个 CPU 时钟周期。</li>
<li>L2- 缓存也在 CPU 中，位置比 L1- 缓存距离 CPU 核心更远。也比 L1-Cache 更大，速度在 10~20 个 CPU 周期。</li>
<li>L3- 缓存也在 CPU 中，位置比 L2- 缓存距离 CPU 核心更远。也比 L2-Cache 更大，速度在 20~60 个 CPU 周期。（如 i9 CPU 有 512KB L1 Cache；有 2MB L2 Cache； 有16MB L3 Cache。）</li>
<li>内存的主要材料是半导体硅，是插在主板上工作的。因为它的位置距离 CPU 有一段距离，所以需要用总线和 CPU 连接。</li>
<li>SSD 也叫固态硬盘，结构和内存类似，但是它的优点在于断电后数据还在。内存、寄存器、缓存断电后数据就消失了。内存的读写速度比 SSD 大概快 10~1000 倍。以前还有一种物理读写的磁盘，我们也叫作硬盘，它的速度比内存慢 100W 倍左右。</li>
</ol>
<p>l1 cache，l2 cache, l3 cache ，内存，SSD/磁盘。从云到右，距离CPU逐渐变远，读取速度逐渐减低，空间逐渐增大。</p>
<p>缓存条目: 缓存可比内存小多了。 因此只能存内存中一小部分。 因此需要设计算法。缓存可以看作是双列结构，分别存储着内存地址和对应的值。想要快速的定位缓存条目可以通过取余(类似hash算法)快速定位缓存条目位置。</p>
<p>指令预读: 通过对于指令的预读，使得读取指令的速度跟的上指令的执行速度。减少指令从内存中的读取次数(更耗时)。</p>
<p>缓存的命中: l1的缓存命中率约为80%，l1 l2 l3缓存加在一块命中率高达95%。</p>
<p>缓存置换: 当缓存满了之后，再读取数据到缓存将置换掉之前的缓存。</p>
<h2 id="linux">Linux</h2>
<p>文件类型</p>
<ol>
<li>
<p>普通文件（比如一个文本文件）；</p>
</li>
<li>
<p>目录文件（目录也是一个特殊的文件，它用来存储文件清单，比如/也是一个文件）；/ 结尾</p>
</li>
<li>
<p>可执行文件；* 结尾</p>
</li>
<li>
<p>管道文件；| 结尾</p>
</li>
<li>
<p>Socket 文件（我们会在模块七网络部分讨论 Socket 文件）；= 结尾</p>
</li>
<li>
<p>软链接文件（相当于指向另一个文件所在路径的符号）；@ 结尾</p>
</li>
<li>
<p>硬链接文件（相当于指向另一个文件的指针）。</p>
</li>
</ol>
<p>echo是一个在命令行打印字符串的指令。</p>
<p>which指令查找一个执行文件所在的路径。</p>
<p>find指令全局查找文件。</p>
<p>touch修改一个文件的时间戳，如果文件不存在会触发创建文件。</p>
<p>cat查看完成的文件适合小型文件。more``less查看一个文件但是只读取用户看到的内容到内存，因此消耗资源较少，适合在服务器上看日志。</p>
<p>head``tail可以用来看文件的头和尾。tail -n 1000 最后的 1000 行日志。tail -f 文件名（follow）实时日志</p>
<p>grep指令搜索文件内容 g 就是 global，全局；re 就是 regular expression，正则表达式；p 就是 pattern，模式。</p>
<p>进程是应用的执行副本；而不要回答进程是操作系统分配资源的最小单位。前者是定义，后者是作用</p>
<p>ps指令。p 代表 processes，也就是进程；s 代表 snapshot，</p>
<p>ps -ef/ps aux（ BSD 风格）进程详情</p>
<p>top 进程实时</p>
<p><strong><code>bash</code>和终端的命令一般都是进程。</strong></p>
<p>每个进程拥有自己的标准输入流、标准输出流、标准错误流，这几个标准流其实都是文件。</p>
<p>标准输入流（用 0 表示）可以作为进程执行的上下文（进程执行可以从输入流中获取数据）。</p>
<p>标准输出流（用 1 表示）中写入的结果会被打印到屏幕上。</p>
<p>如果进程在执行过程中发生异常，那么异常信息会被记录到标准错误流（用 2 表示）中。</p>
<p>重定向：<code>ls -l &gt; out</code> 说&gt;符号叫作覆盖重定向，每次都会把目标文件覆盖；&gt;&gt;叫作追加重定向，会在目标文件中追加。<code>ls1 &gt; out</code> ls1指令是不存在，结果会输出到标准错误流中，即仍在屏幕上并不会存入out文件，<code>ls1 &amp;&gt; out</code>引用关系错误也到out中。&amp;符号用在命令结尾：也代表指令在后台执行，不会阻塞用户继续输入。</p>
<p>管道（Pipeline）在进程间传递数据，将一个进程的输出流定向到另一个进程的输入流。管道是一个连接一个进行计算，重定向是将一个文件的内容定向到另一个文件，这二者经常会结合使用。管道也是文件，有匿名管道（在文件系统中但没有路径）、命名管道（有自己的路径的文件），管道具有 FIFO（First In First Out）。</p>
<ol>
<li>排序<code>ls | sort -r</code>：把ls进程的输出给sort进程做输入。</li>
<li>去重<code>sort a.txt uniq</code>:uniq指令能够找到文件中相邻的重复行，然后去重。</li>
<li>筛选<code>find ./ | grep Spring|grep -v MyBatis</code>：递归列出当前目录下所有目录中的文件;匹配出包含Spring关键字的;在匹配出同时不包含MyBatis的（grep -v是匹配不包含）。</li>
<li>行数<code>wc -l</code>文件行数，<code>ls | wc -l</code>目录下文件数（ls输出的文件行数）</li>
<li>中间结果<code>find ./ -i &quot;*.java&quot; | tee JavaList | grep Spring</code> <code>tee</code> 本身不影响指令的执行，但是 tee 会把 find 指令的结果保存到 JavaList 文件中。</li>
<li><strong>xargs</strong>从标准数据流中构造并执行一行行的指令。xargs从输入流获取字符串，然后利用空白、换行符等切割字符串，在这些字符串的基础上构造指令，最后一行行执行这些指令。<code>ls | xargs -I GG echo &quot;mv GG to prefix_GG&quot;</code>先把最终命令echo输出检验一下，没问题然后执行<code>ls | xargs -I GG mv GG to prefix_GG</code>。<code>-I</code>为查找替换符用<code>GG</code>替代<code>ls</code>找到的结果。</li>
<li>以上都是匿名管道（拥有一个自己的inode，但不属于任何一个文件夹）。命名管道要用<code>mkfifo</code>指令创建。</li>
</ol>
<p><strong>编译安装/包管理器安装</strong></p>
<p>自动依赖管理器,解决了很多依赖,一次性的装好。</p>
<p>tar：t代表tape（磁带）；ar是 archive（档案）</p>
<p>-x代表 extract（提取）。-z代表gzip</p>
<p>-v代表 verbose（显示细节）</p>
<p>-f代表 file，这里指的是要操作文件，而不是磁带。 tar解压通常带有x和f，打包通常是c就是 create 的意思。</p>
<p>autoconf是bash（Bourne Shell）下的安装程序，支持对configure可执行文件的很多配置（<code>./configure --help</code>如prefix是安装目录），执行./configure进行安装。存在交叉编译因此要编译安装。</p>
<table>
<thead>
<tr>
<th></th>
<th>Debian (ubuntu)</th>
<th>Redhat(Redhat/Fedora/Centos)</th>
</tr>
</thead>
<tbody>
<tr>
<td>包管理器</td>
<td>dpkg（debian package）</td>
<td>rpm（redhatpackage manager）</td>
</tr>
<tr>
<td>自动依赖管理器</td>
<td>apt（Advanced Packaging Tools）</td>
<td>yum（Yellodog Updator，Modified）</td>
</tr>
</tbody>
</table>
<h2 id="操作系统">操作系统</h2>
<p><strong>内核</strong>是操作系统中应用连接硬件设备的桥梁，对于一个现代的操作系统来说，它的内核至少应该提供以下 4 种基本能力：</p>
<ol>
<li>
<p>管理进程、线程（决定哪个进程、线程使用 CPU）；</p>
</li>
<li>
<p>管理内存（决定内存用来做什么）；</p>
</li>
<li>
<p>连接硬件设备（为进程、和设备间提供通信能力）；</p>
</li>
<li>
<p>提供系统调用（接收进程发送来的系统调用）。</p>
</li>
</ol>
<table>
<thead>
<tr>
<th><img src="https://s0.lgstatic.com/i/image/M00/61/89/CgqCHl-P5meAd3VdAAB1f7DWz-I273.png" alt="Lark20201021-153830.png" style="zoom:50%;" /></th>
<th><img src="https://s0.lgstatic.com/i/image/M00/61/8A/CgqCHl-P5naAc5fsAABuTlhIQkw555.png" alt="Lark20201021-153825.png" style="zoom:50%;" /></th>
</tr>
</thead>
<tbody></tbody>
</table>
<p>内核权限非常高，它可以管理进程、可以直接访问所有的内存，因此确实需要和进程之间有一定的隔离。这个隔离用类似请求/响应的模型，非常符合常理。</p>
<h3 id="linux-的设计">Linux 的设计</h3>
<ol>
<li><strong>Multitask and SMP</strong>（Symmetric multiprocessing）<br>
MultiTask 指多任务，Linux 是一个多任务的操作系统。多任务就是多个任务可以同时执行，这里的“同时”并不是要求并发，而是在一段时间内可以执行多个任务。当然 Linux 支持并发。<br>
SMP 指对称多处理。其实是说 Linux 下每个处理器的地位是相等的，内存对多个处理器来说是共享的，每个处理器都可以访问完整的内存和硬件资源。 这个特点决定了在 Linux 上不会存在一个特定的处理器处理用户程序或者内核程序，它们可以被分配到任何一个处理器上执行。</li>
<li><strong>ELF</strong>（Executable and Linkable Format）可执行文件链接格式： ELF 可执行文件的存储格式把文件分成了一个个分段（Segment），每个段都有自己的作用。</li>
<li>Linux 是<strong>宏内核</strong>架构，即Linux 的内核是一个完整的可执行程序，且内核用最高权限来运行。宏内核的特点就是有很多程序会打包在内核中，比如，文件系统、驱动、内存管理等。（并不是每次安装驱动都需要重新编译内核，现在 Linux 也可以动态加载内核模块。）</li>
</ol>
<blockquote>
<p>Monolithic Kernel宏内核/Microkernel微内核</p>
<img src="https://s0.lgstatic.com/i/image/M00/61/AA/CgqCHl-QEKSAYD22AAFXRfj1rsA581.png" alt="Lark20201021-183457.png" style="zoom:50%;" />
<p>微内核，内核只保留最基本的能力。比如进程调度、虚拟内存、中断。多数应用，甚至包括驱动程序、文件系统，是在用户空间管理的。微内核体积更小、可移植性更强。</p>
<p>混合类型内核：架构像微内核，但是用宏内核的方式实现，就是在宏内核之内有抽象出了一个微内核。</p>
</blockquote>
<h3 id="window-设计">Window 设计</h3>
<p>目前主流的 Windows 产品都是 NT 内核。NT 内核和 Linux 内核非常相似，没有太大的结构化差异。Windows 同样支持 Multitask 和 SMP（对称多处理）。Windows 下可执行文件格式叫作 Portable Executable（PE），也就是可移植执行文件，扩展名通常是.exe、.dll、.sys等。Windows 的NT（New Technology）内核设计属于混合类型。 Windows 有很多独特的能力如Hyper-V 虚拟化技术。</p>
<p>比较：Linux 内核是一个开源的内核、它们支持的可执行文件格式不同、它们用到的虚拟化技术不同</p>
<p>Kernel 运行在超级权限模式（Supervisor Mode）下，所以拥有很高的权限。按照权限管理的原则，多数应用程序应该运行在最小权限下。因此，很多操作系统，将内存分成了两个区域：</p>
<p>内核空间（Kernal Space），这个空间只有内核程序可以访问；内核空间中的代码可以访问所有内存，我们称这些程序在内核态（Kernal Mode） 执行。</p>
<p>用户空间（User Space），这部分内存专门给应用程序使用。用户空间中的代码被限制了只能使用一个局部的内存空间，我们说这些程序在用户态（User Mode） 执行。</p>
<p>系统调用过程：</p>
<img src="https://s0.lgstatic.com/i/image/M00/62/97/CgqCHl-Sm3mAG_x-AAC5MxhOcCc621.png" alt="Lark20201023-165439.png" style="zoom:50%;" />
<p>内核程序执行在内核态（Kernal Mode），用户程序执行在用户态（User Mode）。</p>
<ol>
<li>当发生系统调用时，用户态的程序发起系统调用。因为系统调用中牵扯特权指令，用户态程序权限不足，因此会中断执行，也就是 Trap（Trap 是一种中断）。</li>
<li>发生中断后，当前 CPU 执行的程序会中断，跳转到中断处理程序。内核程序开始执行，也就是开始处理系统调用。</li>
<li>内核处理完成后，主动触发 Trap，这样会再次发生中断，切换回用户态工作。</li>
</ol>
<p><strong>一个应用程序启动后会在内存中创建一个执行副本，这就是进程</strong>。Linux 的内核（是一个 Monolithic Kernel宏内核）可以看作一个进程。开机的时磁盘的内核镜像被导入内存作为一个执行副本，成为内核进程。用户态进程通常是应用程序的副本，内核态进程就是内核本身的进程。如果用户态进程需要申请资源，比如内存，可以通过系统调用向内核申请。</p>
<p>程序在现代操作系统中并不是以进程为单位在执行，而是以一种轻量级进程（Light Weighted Process），也称作线程（Thread）的形式执行。一个进程可以拥有多个线程。进程创建的时候，一般会有一个主线程随着进程创建而创建。进程可以通过 API 创建用户态的线程，也可以通过系统调用创建内核态的线程</p>
<p>用户态线程：操作系统内核并不知道它的存在，它完全是在用户空间中创建。</p>
<p>优点：</p>
<ol>
<li>管理开销小：创建、销毁不需要系统调用。</li>
<li>切换成本低：用户空间程序可以自己维护，不需要走操作系统调度。</li>
</ol>
<p>缺点：</p>
<ol>
<li>
<p>与内核协作成本高：比如这种线程完全是用户空间程序在管理，当它进行 I/O 的时候，需要频繁进行用户态到内核态的切换。</p>
</li>
<li>
<p>线程间协作成本高：设想两个线程需要通信，通信需要 I/O，I/O 需要系统调用，因此用户态线程需要支付额外的系统调用成本。</p>
</li>
<li>
<p>无法充分利用多核优势：比如操作系统调度的仍然是这个线程所属的进程，所以无论每次一个进程有多少用户态的线程，都只能并发执行一个线程，因此一个进程的多个线程无法利用多核的优势。</p>
</li>
<li>
<p>操作系统无法针对线程调度进行优化：当一个进程的一个用户态线程阻塞（Block）了，操作系统无法及时发现和处理阻塞问题，它不会更换执行其他线程，从而造成资源浪费。</p>
</li>
</ol>
<p>内核态线程：执行在内核态，可以通过系统调用创造一个内核级线程。</p>
<p>优点：</p>
<ol>
<li>
<p>可以利用多核 CPU 优势：内核拥有较高权限，因此可以在多个 CPU 核心上执行内核线程。</p>
</li>
<li>
<p>操作系统级优化：内核中的线程操作 I/O 不需要进行系统调用；一个内核线程阻塞了，可以立即让另一个执行。</p>
</li>
</ol>
<p>缺点：</p>
<ol>
<li>
<p>创建成本高：创建的时候需要系统调用，也就是切换到内核态。</p>
</li>
<li>
<p>扩展性差：由一个内核程序管理，不可能数量太多。</p>
</li>
<li>
<p>切换成本较高：切换的时候，也同样存在需要内核操作，需要切换内核态。</p>
</li>
</ol>
<p>**用户态线程创建成本低，问题明显，不可以利用多核。内核态线程，创建成本高，可以利用多核，切换速度慢。**因此通常我们会在内核中预先创建一些线程，并反复利用这些线程。用户态线程和内核态线程之间的映射关系：</p>
<p>多对一（Many to One）：用户态进程中的多线程复用一个内核态线程。线程不可以并发。</p>
<p>一对一（One to One）：每个用户态都需要通过系统调用创建一个绑定的内核线程，并附加在上面执行。允许所有线程并发执行，充分利用多核优势，（Windows NT 内核采取的就是这种模型）。但是因为线程较多，对内核调度的压力会明显增加。</p>
<p>多对多（Many To Many）：n 个用户态线程分配 m 个内核态线程，m 通常可以小于 n。一种可行的策略是将 m 设置为核数。这种多对多的关系，减少了内核线程，同时也保证了多核心并发。Linux 目前采用的就是该模型。</p>
<p>两层设计（Two Level）：多数用户态线程和内核线程是 n 对 m 的关系，少量用户线程可以指定成 1 对 1 的关系。</p>
<p>内核线程是真正的线程，它会分配到 CPU 的执行资源。用户态线程工作在用户空间，内核态线程工作在内核空间。用户态线程调度完全由进程负责，通常就是由进程的主线程负责。相当于进程主线程的延展，使用的是操作系统分配给进程主线程的时间片段。内核线程由内核维护，由操作系统调度。</p>
<p>用户态线程无法跨核心，一个进程的多个用户态线程不能并发，阻塞一个用户态线程会导致进程的主线程阻塞，直接交出执行权限。这些都是用户态线程的劣势。内核线程可以独立执行，操作系统会分配时间片段。因此内核态线程更完整，也称作轻量级进程。内核态线程创建成本高，切换成本高，创建太多还会给调度算法增加压力，因此不会太多。</p>
<p>操作系统分成 3 层：应用层、内核层、硬件层。内核是连接应用和硬件的桥梁。内核需要公平的对待每个 CPU，于是有了用户态和内核态的切换；为了实现切换，需要中断；为了保护内存资源，需要划分用户态和内核态；为了更好地使用计算资源，需要划分线程——而线程需要操作系统内核调度。</p>
<p>分时（Time Sharing）</p>
<h2 id="进程和线程">进程和线程</h2>
<p>进程（Process）：正在进行执行的应用程序，是软件的执行副本。而线程是轻量级的进程。设计进程和线程，操作系统需要思考分配资源。最重要的 3 种资源是：计算资源（CPU）、内存资源和文件资源。进程下面，需要一种程序的执行单位，仅仅被分配计算资源（CPU），这就是线程。被分配的方式，就是由操作系统调度线程。操作系统创建一个进程后，进程的入口程序被分配到了一个主线程执行，这样看上去操作系统是在调度进程，其实是调度进程中的线程。这种被操作系统直接调度的线程，我们也成为内核级线程。</p>
<p>分时和调度</p>
<p>通常机器中 CPU 核心数量少（从几个到几十个）、进程&amp;线程数量很多（从几十到几百甚至更多），因此进程们在操作系统中只能排着队一个个执行，每个进程在执行时都会获得操作系统分配的一个时间片段，如果超出这个时间，就会轮到下一个进程（内的线程）执行。</p>
<blockquote>
<p>分配时间片段：各个进程（线程）一次都只执行一个时间片段。</p>
<table>
<thead>
<tr>
<th><img src="https://s0.lgstatic.com/i/image/M00/67/CE/CgqCHl-iUNWARGseAACvXwFzOgM513.png" alt="Lark20201104-145535.png" style="zoom:50%;" /></th>
<th><img src="https://s0.lgstatic.com/i/image/M00/67/C2/Ciqc1F-iUOOAH_pCAAAxJPD4vZk085.png" alt="Lark20201104-145538.png" style="zoom:50%;" /></th>
</tr>
</thead>
<tbody></tbody>
</table>
</blockquote>
<p>进程和线程的状态：我这里一直用进程(线程）是因为旧的操作系统调度进程，没有线程；现代操作系统调度线程。</p>
<blockquote>
<table>
<thead>
<tr>
<th><img src="https://s0.lgstatic.com/i/image/M00/67/CE/CgqCHl-iUO-AUnnuAACQlYvu6B4917.png" alt="Lark20201104-145543.png" style="zoom:33%;" /></th>
<th><img src="https://s0.lgstatic.com/i/image/M00/67/C2/Ciqc1F-iUPuAcCoPAABsXQQRmUA149.png" alt="Lark20201104-145546.png" style="zoom:33%;" /></th>
</tr>
</thead>
<tbody></tbody>
</table>
<table>
<thead>
<tr>
<th><img src="https://s0.lgstatic.com/i/image/M00/67/C3/Ciqc1F-iURaABVqnAADDuMgPbV8806.png" alt="Lark20201104-145541.png" style="zoom:33%;" /></th>
<th><img src="https://s0.lgstatic.com/i/image/M00/67/CE/CgqCHl-iUSGAcoiLAAC6OKgt1vo694.png" alt="Lark20201104-145548.png" style="zoom:33%;" /></th>
</tr>
</thead>
<tbody></tbody>
</table>
<p>一旦一个进程（线程）进入阻塞状态，这个进程（线程）此时就没有事情做了，但又不能让它重新排队（因为需要等待中断），所以进程（线程）中需要增加一个“阻塞”（Block）状态。</p>
<p>处于“就绪”（Ready）的进程（线程）还在排队，所以进程（线程）内的程序无法执行，也就是不会触发读取磁盘数据的操作，“就绪”（Ready）状态无法直接变成阻塞的状态；处于“阻塞”（Block）状态的进程（线程）如果收到磁盘读取完的数据，它又需要重新排队，所以它也不能直接回到“运行”（Running）状态。</p>
</blockquote>
<p>进程（线程）创建后，开始排队即**“就绪”（Ready）**状态；</p>
<p>当轮到该进程（线程）执行时，变成**“运行”（Running）**状态；进程（线程）将操作系统分配的时间片段用完后，再回到“就绪”（Ready）状态。</p>
<p>当一个进程（线程）会等待磁盘读取数据/等待打印机响应，此时进程自己会进入**“阻塞”（Block）**状态。等待磁盘、打印机处理完成后，通过中断通知 CPU，然后 CPU 再执行一小段中断控制程序，将控制权转给操作系统，操作系统再将原来阻塞的进程（线程）置为“就绪”（Ready）状态重新排队。</p>
<p>1、进程和线程在内存中如何表示？需要哪些字段？</p>
<p>内存中设计两张表，一张是进程表、一张是线程表。</p>
<p>进程表需要这几类信息：</p>
<p>描述信息：这部分是描述进程的唯一识别号PID、进程的名称、所属的用户等。</p>
<p>资源信息：这部分用于记录进程拥有的资源，比如进程和虚拟内存如何映射、拥有哪些文件、在使用哪些 I/O 设备等，当然 I/O 设备也是文件。</p>
<p>内存布局：操作系统也约定了进程如何使用内存。通常一个进程大致内存分成堆、栈、数据段(全局变量/常数)、正文段(程序指令)等几个段。</p>
<p>线程表：ThreadID、执行状态（阻塞、运行、就绪）、优先级、程序计数器以及所有寄存器的值等等。（线程需要记录程序计数器和寄存器的值，是因为多个线程需要共用一个 CPU，线程经常会来回切换，因此需要在内存中保存寄存器和 PC 指针的值。)</p>
<p>用户级线程和内核级线程存在映射关系，因此可以考虑在内核中维护一张内核级线程的表，如果考虑到这种映射关系，比如 n-m 的多对多映射，可以将线程信息还是存在进程中，每次执行的时候才使用内核级线程。相当于内核中有个线程池，等待用户空间去使用。每次用户级线程把程序计数器等传递过去，执行结束后，内核线程不销毁，等待下一个任务。这里其实有很多灵活的实现，总体来说，创建进程开销大、成本高；创建线程开销小，成本低。</p>
<p>2、进程代表的是一个个应用，需要彼此隔离，这个隔离方案如何设计？</p>
<p>操作系统中运行了大量进程，为了不让它们互相干扰，可以考虑为它们分配彼此完全隔离的内存区域，即便进程内部程序读取了相同地址，而实际的物理地址也不会相同。对于一个进程的多个线程来说，可以考虑共享进程分配到的内存资源，这样线程就只需要被分配执行资源。</p>
<p>3、操作系统调度线程，线程间不断切换，这种情况如何实现？</p>
<p>进程（线程）在操作系统中是不断切换的，现代操作系统中只有线程的切换。 每次切换需要先保存当前寄存器的值的内存，注意 PC 指针也是一种寄存器。当恢复执行的时候，就需要从内存中读出所有的寄存器，恢复之前的状态，然后执行。</p>
<img src="https://s0.lgstatic.com/i/image/M00/67/CE/CgqCHl-iUY-AEqrUAAKnDhPzBcQ340.png" alt="Lark20201104-145523.png" style="zoom:25%;" />
<table>
<thead>
<tr>
<th><img src="https://s0.lgstatic.com/i/image/M00/67/C3/Ciqc1F-iUZ-Af-t9AAC3WjDjEM4772.png" alt="Lark20201104-145556.png" style="zoom:50%;" /></th>
<th><img src="https://s0.lgstatic.com/i/image/M00/67/C3/Ciqc1F-iUa-AdqG9AACMOQKJe2Q431.png" alt="Lark20201104-145530.png" style="zoom:100%;" /></th>
</tr>
</thead>
<tbody></tbody>
</table>
<ol>
<li>
<p>当操作系统发现一个进程（线程）需要被切换的时候，直接控制 PC 指针跳转是非常危险的事情，所以操作系统需要发送一个“中断”信号给 CPU，停下正在执行的进程（线程）。</p>
</li>
<li>
<p>当 CPU 收到中断信号后，正在执行的进程（线程）会立即停止。注意，因为进程（线程）马上被停止，它还来不及保存自己的状态，所以后续操作系统必须完成这件事情。</p>
</li>
<li>
<p>操作系统接管中断后，趁寄存器数据还没有被破坏，必须马上执行一小段非常底层的程序（通常是汇编编写），帮助寄存器保存之前进程（线程）的状态。</p>
</li>
<li>
<p>操作系统保存好进程状态后，执行调度程序，决定下一个要被执行的进程（线程）。</p>
</li>
<li>
<p>最后，操作系统执行下一个进程（线程）。</p>
</li>
</ol>
<p>一个进程（线程）被选择执行后，它会继续完成之前被中断时的任务，这需要操作系统来执行一小段底层的程序帮助进程（线程）恢复状态。通过类似栈这种数据结构。进程（线程）中断后，操作系统负责压栈关键数据（比如寄存器）。恢复执行时，操作系统负责出栈和恢复寄存器的值。</p>
<p>4、需要支持多 CPU 核心的环境，针对这种情况如何设计？</p>
<p>通常情况下，CPU 有几个核，就可以并行执行几个进程（线程）。并发(concurrent)指的在一段时间内几个任务看上去在同时执行（不要求多核）；并行(parallel)任务必须绝对的同时执行（要求多核）。操作系统提供了保存、恢复进程状态的能力，使得进程（线程）也可以在多个核心之间切换。</p>
<p>5、创建进程（线程）的 API？</p>
<img src="https://s0.lgstatic.com/i/image/M00/67/C3/Ciqc1F-iUcyAKsUkAADXFCtukIY084.png" alt="Lark20201104-145559.png" style="zoom:25%;" />
<p>每次 fork 会多创造一个克隆的进程，这个克隆的进程，所有状态都和原来的进程一样，但是会有自己的地址空间。如果要创造 2 个克隆进程，就要 fork 两次。</p>
<p>6、进程的开销比线程大在了哪里？</p>
<p>Linux 中创建一个进程自然会创建一个线程，也就是主线程。创建进程需要为进程划分出一块完整的内存空间，有大量的初始化操作，比如要把内存分段（堆栈、正文区等）。创建线程则简单得多，只需要确定 PC 指针和寄存器的值，并且给线程分配一个栈用于执行程序，同一个进程的多个线程间可以复用堆栈。因此，创建进程比创建线程慢，而且进程的内存开销更大。</p>
<p>线程也被称作轻量级进程，由操作系统直接调度的，是内核级线程。我们还学习了线程切换保存、恢复状态的过程。进程和线程是操作系统为了分配资源设计的两个概念，进程承接存储资源，线程承接计算资源。而进程包含线程，这样就可以做到进程间内存隔离。</p>
<p><strong>原子操作</strong>就是操作不可分，多线程环境，一个原子操作的执行过程无法被中断。</p>
<p><strong>竞争条件</strong>即多个线程对一个资源（内存地址）的读写存在竞争。这种条件下资源的值不可预测，取决于竞争时具体的执行顺序。</p>
<blockquote>
<p>i++就不是一个原子操作，由 3 个原子操作组合成的：读取 i 的值；计算 i+1；写入新的值。</p>
<p>假如两个线程并发执行i++，程序片访问共享资源时会造成竞争条件，共享资源的值最终取决于<strong>程序执行的时序</strong>，结果不确定。这种<strong>访问共享资源的程序片段称为临界区</strong>。</p>
</blockquote>
<p>解决竞争条件的方案：</p>
<ul>
<li>不要让程序同时进入临界区即<strong>互斥</strong></li>
<li>避免竞争条件</li>
</ul>
<p>1.利用 ThreadLocal，每个线程独有变量，线程间就不存在竞争关系。</p>
<p>2.利用 CPU 提供的 Compare And Swap 原子操作，让非原子操作(i++)成为一个原子操作。cas是更新一个内存地址的值，但前提必须明确知道该内存地址当前的值。</p>
<blockquote>
<p><code>cas(&amp;i, i,i+1)</code>在这个过程中，若有其他线程把i更新为i+1，这次调用会返回 false，否则返回 true。</p>
<table>
<thead>
<tr>
<th><img src="https://s0.lgstatic.com/i/image/M00/68/E8/CgqCHl-lBrSAKBmrAADNiS8bkAY490.png" alt="Lark20201106-161714.png" style="zoom:33%;" /></th>
<th><img src="https://s0.lgstatic.com/i/image/M00/68/DD/Ciqc1F-lBr2ATIabAADce4zrAOw887.png" alt="Lark20201106-161708.png" style="zoom:33%;" /></th>
</tr>
</thead>
<tbody>
<tr>
<td>普通：读取 i 的值；计算 i+1；写入新的值</td>
<td>cas：读取i ；计算i+1；cas操作</td>
</tr>
</tbody>
</table>
<p>少数CPU 没有提供 cas，提供一种 类似的Test-And-Set 指令（tas）。</p>
</blockquote>
<p>3.锁（lock）的目标是实现抢占（preempt）。即只让给定数量的线程进入临界区。锁可以用tas或者cas来实现。</p>
<pre><code class="language-c">enter();
i++;
leave();

//-----------用cas实现enter和leave函数----

int lock = 0;
enter(){//自旋锁:代码不断在 CPU 中执行指令，直到锁被其他线程释放
  while( !cas(&amp;lock, 0, 1) ) {
    // 什么也不做
  }
}
leave(){
  lock = 0;
}
</code></pre>
<p>多个线程竞争一个整数的 lock 变量，0 代表目前没有线程进入临界区，1 代表目前有线程进入临界区。利用cas原子指令我们可以对临界区进行管理。如果一个线程利用 cas 将 lock 设置为 1，那么另一个线程就会一直执行cas操作，直到锁被释放。</p>
<p>自旋锁优点不会主动 Context Switch（线程切换），因为线程切换比较消耗时。自旋锁缺点比较消耗 CPU 资源，如果自旋锁一直拿不到锁，会一直执行，比较消耗 CPU 资源。</p>
<pre><code class="language-java">enter(){
  while( !cas(&amp;lock, 0, 1) ) {
    // sleep(1000ms);休眠的时间不好控制
    wait();
  }
}
</code></pre>
<p>可以实现一个 wait 操作，主动触发线程切换，减轻cpu消耗问题。但线程切换也是消耗cpu资源的。wait方法，等待一个信号，直到另一个线程调用notify方法，通知这个线程结束休眠。</p>
<p>解决竞争条件时使用锁，进入临界区之前 lock，出去就 unlock定义锁，需要一个整型，语言级锁的实现如下：</p>
<pre><code class="language-java">enter(&amp;lock);
//临界区代码
leave(&amp;lock);
</code></pre>
<p>wait 和 notify 生产者消费者模型： wait 是一个生产者，将当前线程挂到一个等待队列上，并休眠。notify 是一个消费者，从等待队列中取出一个线程，并重新排队。</p>
<p>把<code>enter</code> <code>leave</code> <code>wait</code> <code>notify</code>的逻辑都封装起来，不让用户感知到它们的存在。Java 中每个对象增加了一个 Object Header 区域，里面一个锁的位（bit），锁并不需要一个 32 位整数，一个 bit 足够。</p>
<pre><code class="language-java">synchronized(obj){// enter
  // 临界区代码
} // leave
</code></pre>
<p>synchronized 关键字的内部实现，使用封装好的底层代码Monitor 对象。每个 Java 对象都关联了一个 Monitor 对象。Monitor 封装了对锁的操作，比如 enter、leave 的调用，这样简化了 Java 程序员的心智负担，你只需要调用 synchronized 关键字。</p>
<p>另外，Monitor 实现了生产者、消费者模型。</p>
<p>如果一个线程拿到锁，那么这个线程继续执行；</p>
<p>如果一个线程竞争锁失败，Montior 就调用 wait 方法触发生产者的逻辑，把线程加入等待集合；</p>
<p>如果一个线程执行完成，Monitor 就调用一次 notify 方法恢复一个等待的线程。</p>
<p>这样，Monitor 除了提供了互斥，还提供了线程间的通信，避免了使用自旋锁，还简化了程序设计。</p>
<p>互斥的广义版为<strong>信号量</strong>，同时允许 N 个线程进入临界区。当lock初始值为 1 的时候，这个模型就是实现互斥（mutex）。如果 lock 大于 1，那么就是同时允许多个线程进入临界区。这种方法，我们称为信号量（semaphore）。</p>
<p>信号量实现生产者消费者模型： wait 是生产者，notify 是消费者。 每次wait操作减少一个空位置数量，empty-1；增加一个等待的线程，full+1。每次notify操作增加一个空位置，empty+1，减少一个等待线程，full-1。</p>
<p>insert和remove方法是互斥的操作，需要用另一个 mutex 锁来保证。insert方法将当前线程加入等待队列，并且调用 yield 方法，交出当前线程的控制权，当前线程休眠。remove方法从等待队列中取出一个线程，并且调用resume进行恢复。以上， 就构成了一个简单的生产者消费者模型。</p>
<p>如果两个线程互相等待对方获得的锁，就会发生死锁。可以把死锁理解成一个环状的依赖关系。</p>
<p>分布式环境的锁：当用户并发的访问接口，是会发生竞争条件的。 因为程序已经不是在同一台机器上执行了，解决方案就是分布式锁。实现锁，我们需要原子操作。单机多线程并发的场景下，原子操作由 CPU 指令提供，比如 cas 和 tas 指令。分布式环境下很多工具都可以提供分布式的原子操作，比如 Redis 的 setnx 指令，Zookeeper 的节点操作等等。</p>
<p>并发场景，设计系统的目的往往是达到同步（Synchronized）的状态，同步就是大家最终对数据的理解达成了一致。同步的一种方式，就是让<strong>临界区互斥</strong>（对临界区上锁），具有强烈的排他性，对修改持保守态度，我们称为<strong>悲观锁</strong>（Pressimistic Lock）。像git同时写，先更新的人被采纳，后更新的人负责解决冲突。是一种典型的**乐观锁（Optimistic Lock）**的场景。</p>
<p>除了上锁还有哪些并发控制方法？</p>
<p>之所以害怕并发，是因为中心化。用分级缓存的策略（dns）、分布式处理（分布式锁）优化，不如更彻底的用去中心化的方案，双方不用通过中心系统，直接达到同步（Synchronized）的状态。处理并发还可以考虑 Lock-Free 数据结构。比如 Lock-Free 队列，是基于 cas 指令实现的，允许多个线程使用这个队列。再比如 ThreadLocal，让每个线程访问不同的资源，旨在用空间换时间，也是避免锁的一种方案。</p>
<p>双方签订<strong>电子合同</strong>，解决最基本的信用问题。</p>
<p>区块链构成了一个基于历史版本的事实链，前一个版本是后一个版本的历史，把双方的货币和库存记录在Block中，解决<strong>货币和库存</strong>的问题。</p>
<p><strong>发生购买转账的交易</strong>，在末端节点上再增加一个区块。（若有很多人同时在这个末端节点上写新的 Block。可以由一个可信任的中心服务帮助合并新增的区块数据）</p>
<p><strong>解决欺诈问题</strong>，正常情况下自己的余额/库存交易按顺序记录在区块中无法超额。擅自修改自己的余额/库存等欺诈问题：要新增一个假的末端的block，就和之前 Block 中记录的冲突了；想要修改之前的某个block的数据，这个节点的摘要签名就会发生变化了， 那么后面所有的节点就失效了。相当于修改了完整的一个链条，且修改了所有的签名，就会被其他参与者知道并抵制。区块链一旦写入就不能修改，这样可以防止很多欺诈行为。</p>
<img src="https://s0.lgstatic.com/i/image/M00/6C/E0/Ciqc1F-ryUiAQ5JUAAEC6zaXAKM772.png" alt="4.png" style="zoom:50%;" />
<p>区块链：每个 Block 下面可以存一些数据，每个 Block 知道上一个节点是谁。且每个 Block 有上一个节点的摘要签名，可以证明上一个block的数据 的数据没有被篡改过。（如果 Block 10 是 Block 11 的上一个节点，那么 Block 11 会知道 Block 10 的存在，且用 Block 11 中 Block 10 的摘要签名，可以证明 Block 10 的数据没有被篡改过。）</p>
<table>
<thead>
<tr>
<th><img src="https://s0.lgstatic.com/i/image/M00/6C/E0/Ciqc1F-ryVaAO-KFAADCyXfna24816.png" alt="2.png" style="zoom:50%;" /></th>
<th><img src="https://s0.lgstatic.com/i/image/M00/6C/E0/Ciqc1F-ryV-ATtpAAACJ4ZgkVtU059.png" alt="1.png" style="zoom:43%;" /></th>
</tr>
</thead>
<tbody></tbody>
</table>
<p>同时下单时，会导致最后面的 Block，开很多分支。</p>
<p><strong>解决并发问题</strong>：不用集中式的锁解决。维护自己的 Block-Chain，等待合适的时机，再去合并到主分支上，而不是每次都创建block。</p>
<p>线程调度都有哪些方法？</p>
<p>非抢占的<strong>先到先服务（First Come First Service，FCFS）<strong>模型(使用队列FIFO)是最朴素的，公平性和吞吐量可以保证。但是因为希望减少用户的</strong>平均等待时间（总等待时间/任务数）</strong>，操作系统往往需要实现<strong>抢占（Preemption）<strong>和</strong>优先级队列（PriorityQueue）</strong>，同时还要<strong>短作业优先（Shortest Job First，SJF）。<strong>操作系统无法预判每个任务的预估执行时间，还需要采用</strong>分级队列</strong>。最高优先级的任务可以考虑非抢占的优先级队列（每个任务执行完才执行下一个）。 其他任务放到分级队列模型中执行，从最高优先级时间片段最小向最低优先级时间片段最大逐渐沉淀。这样就同时保证了小任务先行和高优任务最先执行。</p>
<table>
<thead>
<tr>
<th><img src="https://s0.lgstatic.com/i/image/M00/6D/A7/CgqCHl-uUx2AZFakAACjU3Bi2eE649.png" alt="Lark20201113-173328.png" style="zoom:50%;" /></th>
<th><img src="https://s0.lgstatic.com/i/image/M00/6D/9C/Ciqc1F-uUyaAUVSDAAB3mZmSb3A937.png" alt="Lark20201113-173330.png" style="zoom:50%;" /></th>
</tr>
</thead>
<tbody></tbody>
</table>
<p><strong>抢占（Preemption）<strong>就是把</strong>执行能力分时</strong>，分成时间片段。 让每个任务都执行一个时间片段。如果在时间片段内，任务完成，那么就调度下一个任务。如果任务没有执行完成，则中断任务，让任务重新排队，调度下一个任务。</p>
<ol>
<li>线程相对于操作系统是排队到来的，操作系统为每个到来的线程分配一个优先级，然后把它们放入一个优先级队列中，优先级最高的线程下一个执行。</li>
<li>每个线程执行一个时间片段，每次线程执行满一个时间片，就执行一段调度程序(红色)。调度程序可以考虑实现为一个单线程模型，这样不需要考虑竞争条件。</li>
</ol>
<p><strong>多级队列模型</strong>:上层队列调度紧急任务，下层队列调度普通任务。只要上层队列有任务，下层队列就会让出执行权限。</p>
<ol>
<li>
<p>低优先级队列可以考虑抢占 + 优先级队列的方式实现，这样每次执行一个时间片段就可以判断一下高优先级的队列中是否有任务。</p>
</li>
<li>
<p>高优先级队列可以考虑用非抢占（每个任务执行完才执行下一个）+ 优先级队列实现，这样紧急任务优先级有个区分。如果遇到十万火急的情况，就可以优先处理这个任务。</p>
<table>
<thead>
<tr>
<th><img src="https://s0.lgstatic.com/i/image/M00/6D/A7/CgqCHl-uUzCAVhhzAAFSttJfDs4355.png" alt="Lark20201113-173333.png" style="zoom:50%;" /></th>
<th><img src="https://s0.lgstatic.com/i/image/M00/6D/9C/Ciqc1F-uUzqAMYY-AADMHX-2Dso456.png" alt="Lark20201113-173318.png" style="zoom:50%;" /></th>
</tr>
</thead>
<tbody></tbody>
</table>
</li>
</ol>
<p>优化：高优先级队列、普通优先级队列（实际操作中，可以有 n 层，一层层把大任务筛选出来。 最长的任务，放到最闲的时间去执行。）短任务会在更高优先级的队列中执行完成，长任务优先级会下调，也就类似实现了最短作业优先的问题。</p>
<ol>
<li>紧急任务仍然走高优队列，非抢占执行。</li>
<li>普通任务先放到优先级仅次于高优任务的队列中，并且只分配很小的时间片；如果没有执行完成，说明任务不是很短，就将任务下调一层。</li>
<li>最低优先级的队列中时间片很大，长任务就有更大的时间片可以用。</li>
</ol>
<p>什么情况下会触发饥饿和死锁？</p>
<p>线程需要资源没有拿到，无法进行下一步，就是饥饿。死锁（Deadlock）和活锁（Livelock）都是饥饿的一种形式。 非抢占的系统中，互斥的资源获取，线程间互相等待资源，形成循环依赖就会产生死锁。死锁发生后，如果利用抢占解决，导致资源频繁被转让，有一定概率触发活锁。死锁、活锁，都可以通过设计并发控制算法解决，比如哲学家就餐问题。</p>
<p>（要解决死锁的问题，可以考虑哲学家拿起 1 个叉子后，如果迟迟没有等到下一个叉子，就放弃这次操作。比如 Java 的 Lock Interface 中，提供的tryLock方法，就可以实现定时获取，拿不到锁，就报异常，并释放已获得资源。</p>
<p>按以上方案解决死锁：可能在某个时刻，所有哲学及都拿起了左手的叉子，然后发现右手的叉子拿不到，就放下了左手的叉子。如此周而复始，这就是一种活锁。所有线程都在工作，但是没有线程能够进一步解决问题）</p>
<p>我的服务应该开多少个进程、多少个线程？</p>
<p>【解析】 计算密集型一般接近核数，如果负载很高，建议留一个内核专门给操作系统。I/O 密集型一般都会开大于核数的线程和进程。 但是无论哪种模型，都需要实地压测，以压测结果分析为准；另一方面，还需要做好监控，观察服务在不同并发场景的情况，避免资源耗尽。</p>
<h2 id="内存管理">内存管理</h2>
<p>内存一致性：在同一时刻，多线程之间，对内存中某个地址的数据认知是否一致（简单理解，就是多个线程读取同一个内存地址能不能读到一致的值）。</p>
<p>对某个地址，和任意时刻，如果所有线程读取值，得到的结果都一样，就是强一致性，或称为线性一致性（Sequencial Consistency）。 如果只有部分时刻所有线程的理解是一致的，那么称为弱一致性（Weak Consistency）。为什么会有内存不一致问题呢? 这就是因为 CPU 缓存的存在。</p>
<img src="https://s0.lgstatic.com/i/image/M00/72/28/CgqCHl_A0uOACUBUAACRcLSCqUw476.png" alt="Lark20201127-181946.png" style="zoom:25%;" />
<p>假如在 CPU 架构中，Thread1,Thread2 在不同核心，因此它们的 L1\L2 缓存不共用， L3 缓存共享。</p>
<p>如果 Thread1 发生了写入 A=1，这个时候会按照 L1,L2,L3 的顺序写入缓存，最后写内存。结果会导致 print 出来的 A 和 B 结果不确定，取决于具体线程执行的时机。Java 提供了一个 volatile 关键字，避免从读取不到lock的写入内存的问题（还在 Thread 所在 CPU 的 L1、L2 中）。</p>
<p>虚拟化技术是为了解决内存不够用的问题。</p>
<p>**内存交换（Swap）**技术允许一部分进程使用内存，不使用内存的进程数据先保存在磁盘上。（此处的数据是指完整的进程数据，包括正文段（程序指令）、数据段、堆栈段等）轮到某个进程执行的时候，尝试为这个进程在内存中找到一块空闲的区域。如果空间不足，就考虑把没有在执行的进程交换（Swap）到磁盘上，把空间腾挪出来给需要的进程。</p>
<img src="https://s0.lgstatic.com/i/image/M00/75/44/Ciqc1F_Hb-GAermKAACje6hFwj4571.png" alt="Lark20201202-184240.png" style="zoom:50%;" />
<p>内存被拆分成多个区域。 内核作为一个程序也需要自己的内存。每个进程独立得到一个空间即地址空间（Address Space）。地址空间是一块连续分配的内存块。每个进程在不同地址空间中工作，这种原始的虚拟化技术存在：碎片问题、频繁切换问题。</p>
<table>
<thead>
<tr>
<th><img src="https://s0.lgstatic.com/i/image/M00/75/44/Ciqc1F_Hb_aALLF_AABvGKciFvQ002.png" alt="Lark20201202-184243.png" style="zoom:50%;" /></th>
<th><img src="https://s0.lgstatic.com/i/image/M00/75/4F/CgqCHl_HcAOAERr3AACsFab3D0g908.png" alt="Lark20201202-184247.png" style="zoom:50%;" /></th>
<th><img src="https://s0.lgstatic.com/i/image/M00/75/44/Ciqc1F_HcBGANfB6AABfKTW4B2g866.png" alt="Lark20201202-184250.png" style="zoom:50%;" /></th>
</tr>
</thead>
<tbody></tbody>
</table>
<p>操作系统设计了虚拟内存，操作系统管理<strong>虚拟内存和真实内存之间的映射</strong>。操作系统将<strong>虚拟内存分成整齐的页（Page）</strong>。减轻内存碎片问题，而且操作系统不必关系哪些进程被高频/低频使用，只关心哪些页被高/低频使用，将高频实用的页保留在真实内存，低频使用的页保留在硬盘上。</p>
<p><strong>真实内存也需要分块为一个个Frame</strong>。Page 到 Frame 通过<strong>页表</strong>的结构映射。页表维护了虚拟地址到真实地址的映射。</p>
<p>上面的过程发生在 CPU 中一个小型的设备：内存管理单元（Memory Management Unit， MMU）中。当 CPU 需要执行一条指令时，如果指令中涉及内存读写操作，CPU 会把虚拟地址给 MMU，MMU 自动完成虚拟地址到真实地址的计算；然后MMU 连接了地址总线，帮助 CPU 操作真实地址。</p>
<p>表中的每一项（页表条目）如下图所示</p>
<blockquote>
<img src="https://s0.lgstatic.com/i/image/M00/75/4F/CgqCHl_HcCiAXdDRAACAza-oxwo742.png" alt="Lark20201202-184252.png" style="zoom:50%;" />
<p>页表条目本身的编号page number可以不存在页表中，而是通过偏移量计算。 比如地址 100,000 的编号，可以用 100,000 除以页大小确定。</p>
<p>Absent（“在”）位，是一个 bit。0 表示页的数据在磁盘中（不再内存中），1 表示在内存中。如果读取页表发现 Absent = 0，那么会触发缺页中断，去磁盘读取数据。</p>
<p>Protection（保护）字段可以实现成 3 个 bit，它决定页表用于读、写、执行。比如 000 代表什么都不能做，100 代表只读等。</p>
<p>Reference（访问）位，代表这个页被读写过，这个记录对回收内存有帮助。</p>
<p>Dirty（“脏”）位，代表页的内容被修改过，如果 Dirty =1，那么意味着页面必须回写到磁盘上才能置换（Swap)。如果 Dirty = 0，如果需要回收这个页，可以考虑直接丢弃它（什么也不做，其他程序可以直接覆盖）。</p>
<p>Caching（缓存位），描述页可不可以被 CPU 缓存。CPU 缓存会造成内存不一致问题，在上个模块的加餐中我们讨论了内存一致性问题，具体你可以参考“模块四”的加餐内容。</p>
<p>Frame Number（Frame 编号），这个是真实内存的位置。用 Frame 编号乘以页大小，就可以得到 Frame 的基地址。</p>
</blockquote>
<img src="https://s0.lgstatic.com/i/image/M00/8C/20/CgqCHl_lnEqAGPEZAAC-Dsux5E8250.png" alt="1.png" style="zoom:50%;" />
<img src="https://s0.lgstatic.com/i/image/M00/75/50/CgqCHl_HcK2AGh63AABHzfHvTfg888.png" alt="Lark20201202-184238.png" style="zoom:50%;" />
<p>占据大空间的应用，大页面时页表时，为了减少条目的创建，可以考虑进程内部用一个更大的页表，操作系统继续用原来小的页表。按照这样的思想还有多级页表（40m、4m、4k）</p>
<p>MMU 根据 1 级编号找到 1 级页表条目，1 级页表条目中记录了对应 2 级页表的位置。依次递归查到末尾级别的页表，然后 MMU 再查询该页表找到 Frame。最后通过地址偏移量和 Frame 编号计算最终的物理地址。</p>
<table>
<thead>
<tr>
<th><img src="https://s0.lgstatic.com/i/image/M00/78/84/Ciqc1F_KEYiAGIk6AABN2sQtqqo988.png" alt="Lark20201204-183520.png" style="zoom:50%;" /></th>
<th><img src="https://s0.lgstatic.com/i/image/M00/78/90/CgqCHl_KEZGAB4tfAAA_7O1Ajlg766.png" alt="Lark20201204-183533.png" style="zoom:50%;" /></th>
</tr>
</thead>
<tbody></tbody>
</table>
<p>虚拟地址由页号和偏移量组成，物理地址由 Frame Number 和偏移量组成。在 CPU 中有一个虚拟地址到物理地址转换的小型设备，叫作内存管理单元（Memory Management Unit(MMU）。</p>
<p>程序执行时，指令中的地址都是虚拟地址，虚拟地址会通过 MMU，MMU 会查询页表，计算出对应的 Frame Number，然后偏移量不变，组装成真实地址。然后 MMU 通过地址总线直接去访问内存。所以 MMU 承担了<strong>虚拟地址到物理地址的转换</strong>以及 <strong>CPU 对内存的操作</strong>这两件事情。MMU 在 CPU 内部，并且直接和地址总线连接。因此 MMU 承担了 CPU 和内存之间的代理。</p>
<p>CPU 的指令周期中，fetch、execute 和 store 这 3 个环节中都有可能发生内存操作，地址换算增加le指令的 CPU 周期。因此在 MMU 中往往还有一个微型的设备，叫作**转置检测缓冲区（Translation Lookaside Buffer，TLB）**来提高转换速度。TLB 是一个二维表格，每一行是一个 Page Number 对应一个 Frame Number。我们把这样的每一行称为一个缓存行（Cache Line），或者缓存条目（Entry）。<strong>TLB 的作用就是根据输入的 Page Number，找到 Frame Number</strong>。TLB 是硬件实现的速度快。现代多核 CPU，每个核心有单独的 TLB，且采用类似 CPU 缓存的分级策略。通过这样的设计，绝大多数的页表查询就可以用 TLB 实现了。</p>
<p>TLB 失效（Miss）： Page Number 在 TLB 总没有找到。</p>
<ol>
<li>软失效（Soft Miss）：Frame 还在内存中，只不过 TLB 缓存中没有。刷新 TLB 缓存，如果 TLB 缓存已经满了，就需要选择一个已经存在的缓存条目进行覆盖。具体选择哪个条目进行覆盖，我们称为<strong>缓存置换</strong>（缓存不够用了，需要置换）。缓存置换时，通常希望高频使用的数据保留，低频使用的数据被替换。</li>
<li>硬失效（Hard Miss)：对应的 Frame 没有在内存中，需要从磁盘加载。首先操作系统要触发一个缺页中断（原有需要读取内存的线程被休眠），然后中断响应程序开始从磁盘读取对应的 Frame 到内存中，读取完成后，再次触发中断通知更新 TLB，并且唤醒被休眠的线程去排队。线程不可能从休眠态不排队就进入执行态，因此 Hard Miss 是相对耗时的。</li>
</ol>
<p>基于缓存行（Cache Line）的缓存有 3 种映射方案：</p>
<p>相联（Associative）即缓存条目和缓存数据之间的映射范围。如果是全相联，则数据可能在任何条目。如果是组相联（Set-Associative），则数据只能在一部分缓存条目中出现（比如前 4 个条目为一组）。</p>
<ol>
<li>
<p>全相联映射（Fully Associative Mapping）：条目过多，硬件查询速度下降。</p>
</li>
<li>
<p>直接映射（Direct Mapping）：通过类似哈希函数的计算映射</p>
</li>
<li>
<p>n 路组相联映射（n-way Set-Associative Mapping）：允许一个虚拟页号（Page Number）映射到固定数量的 n 个位置，每次新地址需要置换进来的时候，可以从 n 个位置中选择更新时间最早的条目置换出去。</p>
</li>
</ol>
<p>前两种方案被缓存的值都在固定位置，而n 路组相联映射可以被缓存于多个位置，才能在后续实现根据时间或频率而淘汰的置换算法。</p>
<p>大内存分页时采用多级页表也会给MMU 带来一定的负担。可以采用大内存分页（Large Page 或 Huge Page），让系统能够提供大小为 4M 的页而非4k，以减少页数，也提高了 TLB 的查询性能。</p>
<p><strong>缓存设计中有一个重要的环节：当缓存满了，新的缓存条目要写入时，哪个旧条目被置换出去呢？</strong></p>
<p>这就需要用到缓存置换算法（Cache Replacement Algorithm）。设计缓存置换算法的期望是：每次将未来使用<strong>频率最低</strong>的数据置换出去。但实际中不可能预知哪些内存地址在未来指令中使用频率高低。在缓存中找到数据叫作一次命中（Hit），没有找到叫作穿透（Miss）。</p>
<blockquote>
<p>缓存置换应用场景非常广如：发生缺页中断后，操作系统需要将磁盘的页导入内存，那么已经在内存中的页就需要置换出去。CDN 服务器为了提高访问速度，需要决定哪些 Web 资源在内存中，哪些在磁盘上。CPU 缓存每次写入一个条目，也就相当于一个旧的条目被覆盖。数据库要决定哪些数据在内存中，应用开发要决定哪些数据在 Redis 中，而空间是有限的，这些都关联着缓存的置换。</p>
</blockquote>
<p>缓存置换算法：</p>
<p>随机/FIFO(链表)/FILO(栈)具有非常朴素的公平，但穿透概率高。</p>
<p>最近未使用（NRU Not Recently Used)：一条页表条目中的访问位Reference，代表页表有被读取过。脏位Dirty，代表页表被写入过。每次置换的时候，操作系统尽量最近未使用的即选择读、写位都是 0 的页面置换。</p>
<p>（NRU与FIFO结合成第二次机会算法：每次 把FIFO 队列尾部条目置换出去前，检查条目的都位若为1，则设为0同时不置换出去而移到队首[循环链表改变头指针即可]）</p>
<p>最近使用最少（LRU Least Recently Used）：比 NRU 多出最少使用即频率这个条件。最近一段时间最少使用到的数据应该被淘汰，把空间让给最近频繁使用的数据。这样的设计，即便数据都被使用过，还是会根据使用频次多少进行淘汰。</p>
<p>LRU 的一种常见实现是双向链表维护缓存条目。如果链表中某个缓存条目被使用到，那么就将这个条目重新移动到表头。如果要置换缓存条目出去，就直接从双线链表尾部删除一个条目。</p>
<p>通常 LRU 缓存还要提供查询能力，这里我们可以考虑用类似 Java 中 LinkedHashMap 的数据结构，同时具备双向链表和根据 Key 查找值的能力。</p>
<p>设计 LRU 缓存第一个困难是描述<strong>最近使用次数</strong> “最近”是一个模糊概念，没有具体指出是多长时间？按照 CPU 周期计算还是按照时间计算？</p>
<p>页面置换算法中，<strong>累加计数页表的读位（访问位Reference）</strong>。这种单纯基于使用次数最少判断置换，我们称为<strong>最少使用（Least Frequently Used,，LFU）算法</strong>。</p>
<blockquote>
<p>例如：现在某个页表条目的累计值是 0， 接下来在多次计数中看到的读位是：1,0,0,1,1，那么累计值就会变成 3。这代表在某段时间内（5 个计数器 Tick 中）有 3 次访问操作。</p>
<p>LFU 的劣势在于它不会忘记数据，累计值不会减少。如果有内存数据过去常常被用到，但是现在已经有很长一段时间没有被用到了，在这种情况下它并不会置换出去。</p>
</blockquote>
<p>**”老化”（Aging）**的算法：解决累加计数只增不减的问题。</p>
<blockquote>
<p>比如用 8 位来描述累计数（A），那么每次当读位的值（R）到来的时候，我们都考虑将 A 的值右移，然后将 R 放到 A 的最高位。</p>
<p>例如 A 目前的值是00000000，在接下来的 5 个 Tick 中 R 来临的序列是11100，那么 A 的值变更顺序为：</p>
<p>10000000</p>
<p>11000000</p>
<p>11100000</p>
<p>01110000</p>
<p>00111000</p>
<p>随着 Aging 算法的执行，有访问操作的时候 A 的值上升，没有访问操作的时候，A的值逐渐减少。如果一直没有访问操作，A 的值会回到 0。</p>
</blockquote>
<p>巧妙地用数学描述了“最近”。操作系统每次页面置换的时候，都从 A 值最小的集合中取出一个页面放入磁盘。这个算法是对 LRU 的一种模拟，也被称作 LFUDA（动态老化最少使用，其中 D 是 Dynamic,，A 是 Aging）。</p>
<p>LRU 用什么数据结构实现更合理？</p>
<p>【解析】 最原始的方式是用数组，数组的每一项中有数据最近的使用频次。数据的使用频次可以用计时器计算。每次置换的时候查询整个数组实现。</p>
<p>另一种更好的做法是利用双向链表实现。将使用到的数据移动到链表头部，每次置换时从链表尾部拿走数据。链表头部是最近使用的，链表尾部是最近没有被使用到的数据。</p>
<p>但是在应对实际的场景的时候，有时候不允许我们建立专门用于维护缓存的数据结构（内存大小限制、CPU 使用限制等），往往需要模拟 LRU。比如在内存置换场景有用“老化”技术模拟 LRU 计算的方式。</p>
<p>通常意义上我们说的垃圾回收器（Garbage Collector，GC），不只是内存回收用的模块，而事实上程序语言提供的 GC 往往是应用的实际内存管理者。</p>
<p>GC 的“工作”有 4 种：</p>
<ol>
<li>
<p>GC 要和操作系统进行交互，负责申请内存；并把不用的内存还给操作系统（释放内存）。</p>
</li>
<li>
<p>应用会向 GC 申请内存。</p>
</li>
<li>
<p>GC 要承担我们通常意义上说的垃圾回收能力，标记不用的对象，并回收他们。</p>
</li>
<li>
<p>GC 还需要针对应用特性进行动态的优化。</p>
</li>
</ol>
<p>在程序语言实现 GC 内存管理的时候，会关注下面这几个指标：</p>
<p>吞吐量（Throughput）：执行程序（不包括 GC 执行的时间）和总是间的占比。只要不在 GC，就认为是吞吐量的一部分。</p>
<p>足迹（FootPrint）： 一个程序使用了多少硬件的资源，也称作程序在硬件上的足迹。GC 里面说的足迹，通常就是应用对内存的占用情况。比如说应用运行需要 2G 内存，但是好的 GC 算法能够帮助我们减少 500MB 的内存使用，满足足迹这个指标。</p>
<p>暂停时间（Pause Time）： GC 执行的时候，通常需要停下应用（避免同步问题），这称为 Stop The World，或者暂停。（不同应用对某次内存回收可以暂停的时间需求是不同的，比如说一个游戏应用，暂停了几毫秒用户都可能有很大意见；而看网页的用户，稍微慢了几毫秒是没有感觉的。GC 往往不能拥有太长的暂停时间（Pause Time），因为 <strong>GC 和应用是并发的执行</strong>。如果 GC 导致应用暂停（Stop The World，STL）太久，那么对有的应用来说是灾难性的。但如果暂停时间只允许很短，那么 GC 和应用的交替就需要非常频繁。）</p>
<p>吞吐量高，不代表暂停时间少，也不代表空间使用（FootPrint）小。 同样的，使用空间小的 GC 算法，吞吐量反而也会下降。三者之间存在类似相同成本代价下不可兼得的关系，往往编程语言会提供参数让你选择根据自己的应用特性决定 GC 行为。</p>
<table>
<thead>
<tr>
<th><img src="https://s0.lgstatic.com/i/image2/M01/03/6E/CgpVE1_cGkiAQg5eAACZco3DsVw877.png" alt="图片1.png" style="zoom:50%;" /></th>
<th><img src="https://s0.lgstatic.com/i/image/M00/84/6B/Ciqc1F_TUQ6AGct7AACd_pMg8rA373.png" alt="图片3.png" style="zoom:50%;" /></th>
</tr>
</thead>
<tbody></tbody>
</table>
<p>实现 GC 最简单的方案叫作<strong>引用计数</strong>：如果一个节点的引用计数是 0，就意味着没有任何一个节点引用它，理论上这个节点应该被回收。GC 不断扫描引用计数为 0 的节点进行回收，就构成了最简单的一个内存回收算法。</p>
<p>缺点：</p>
<p>循环引用：如图三者互相引用，虽然引用计数是 1。但即使这 3 个对象不会再使用了，GC 不会回收它们。</p>
<p>引用计数法容错能力差，多线程环境下引用计数的算法一旦算错 1 次，就会导致内存永久无法被回收。</p>
<img src="https://s0.lgstatic.com/i/image/M00/8B/9A/CgqCHl_cGjOAErigAAE9Hos_mIo707.png" alt="图片2.png" style="zoom:50%;" />
<p>Root Tracing 类算法：标记-清除算法和 3 色标记-清除算法都属于这一类。</p>
<p>从引用路径上，如果一个对象的引用链中包括一个根对象（Root Object），那么这个对象就是活动的。如果一个对象从根对象不可达，那么这个对象就应该被回收(即便这个对象存在循环引用。)</p>
<p>（根对象是所有引用关系的源头，比如用户在栈中创建的对象指针；程序启动之初导入数据区的全局对象等。在 Java 中根对象就包括在栈上创建指向堆的对象；JVM 的一些元数据，包括 Method Area 中的对象等。)</p>
<p>标记-清除（Mark Sweep）算法:用白色代表一种不确定的状态：可能被回收。 黑色代表一种确定的状态：不会被回收。算法的实现，就是为所有的对象染色。算法执行结束后，所有是白色的对象就需要被回收。</p>
<p>假设有两个全局变量是已知的：</p>
<ul>
<li>
<p>heapSet 中拥有所有对象</p>
</li>
<li>
<p>rootSet 中拥有所有 Root Object</p>
</li>
<li>
<p>标记函数mark：它会递归地将一个对象的所有子对象染成黑色(DFS深度优先搜索)</p>
</li>
</ul>
<ol>
<li>将所有的对象染成白色</li>
<li>mark：从所有Root Object开始执行标记函数mark</li>
<li>Sweep：上一步程序执行结束后，所有和 Root Object 连通的对象都已经被染成了黑色。然后我们遍历整个 heapSet 找到白色的对象进行回收清除（Sweep）</li>
</ol>
<p>如果上面的 GC 程序在某个时刻暂停了下来，然后开始执行用户程序。如果用户程序删除了对某个已经标记为黑色对象的所有引用，用户程序没办法通知 GC 程序。这个节点就会变成<strong>浮动垃圾（Floating Garbage）</strong>，需要等待下一个 GC 程序执行。假设用户程序和 GC 交替执行，用户程序不断进行<strong>修改（Mutation）</strong>，而 GC 不断执行标记-清除算法。那么这中间会产生大量浮动垃圾影响 GC 的效果。</p>
<table>
<thead>
<tr>
<th><img src="https://s0.lgstatic.com/i/image2/M01/02/27/Cip5yF_Z2CCAZ4MFAABZx6AzarA983.png" alt="Drawing 0.png" style="zoom:50%;" /></th>
<th><img src="https://s0.lgstatic.com/i/image2/M01/02/27/Cip5yF_Z2CiASF0QAACL55G2CDE848.png" alt="Drawing 1.png" style="zoom:50%;" /></th>
</tr>
</thead>
<tbody></tbody>
</table>
<p>GC 的过程是标记、清除及程序不断对内存进行修改的过程。标记（Mark）就是找到不用的内存，清除（Sweep）就是回收不用的资源，而修改（Muation）则是指用户程序对内存进行了修改。</p>
<blockquote>
<p>对于 Mark、Sweep、Mutation 来说内存是共享的。如果并行执行相当于需要同时处理大量竞争条件的手段，这会增加非常多的开销。因此在 GC 的设计中，上述 3 种程序不允许并行执行（Simultaneously）。当然你可以开多个线程去 Mark、Mutation 或者 Sweep，但前提是每个过程都是独立的。</p>
</blockquote>
<p>对于双色标记-清除算法，如果 Mark 和 Sweep 之间存在 Mutation，那么 Mutation 的伤害是比较大的。</p>
<p>三色标记-清除算法（Tri-Color Mark Sweep）：</p>
<ul>
<li>
<p>白色代表需要 GC 的对象；</p>
</li>
<li>
<p>黑色代表确定不需要 GC 的对象；</p>
</li>
<li>
<p>灰色代表可能不需要 GC 的对象，但是还未完成标记的任务，也可以认为是增量任务。</p>
</li>
</ul>
<p>一开始所有对象都染成白色。初始化完成后，会启动标记程序。在标记的过程中，是可以暂停标记程序执行 Mutation。算法需要维护 3 个集合，白色集合、黑色集合、灰色集合。3 个集合是互斥的，对象只能在一个集合中。</p>
<table>
<thead>
<tr>
<th><img src="https://s0.lgstatic.com/i/image2/M01/02/2C/Cip5yF_Z4eWAc6oqAAFWo21QkuY797.png" alt="图片36.png" style="zoom:50%;" /></th>
<th><img src="https://s0.lgstatic.com/i/image2/M01/02/2D/CgpVE1_Z4h2AKNQnAAFJ-m6TgJw012.png" alt="图片33.png" style="zoom:50%;" /></th>
</tr>
</thead>
<tbody></tbody>
</table>
<p>类似双色标记-清除算法的<strong>全量 GC 程序</strong>，我们从 Root 集合开始遍历，完成了对所有元素的标记（将它们放入对应的集合）。</p>
<p>执行之初，所有对象都放入白色集合。</p>
<p>第一次执行，算法将 Root 集合能直接引用的对象加入灰色集合。</p>
<p>不断从灰色集合中取出元素进行标记：这是DFS的过程，保证 3 个集合都是线程安全的，可以考虑利用 ConcurrentSet（这样性能更好）</p>
<ol>
<li>
<p>如果对象在白色集合中，那么先将对象放入灰色集合；</p>
</li>
<li>
<p>然后遍历节点的所有的引用对象，并递归所有引用对象；</p>
</li>
<li>
<p>当一个对象的所有引用对象都在灰色集合中，就把这个节点放入为黑色集合。</p>
</li>
</ol>
<p>标记算法完成后，白色集合内就是需要回收的对象。</p>
<p>**增量 GC（Incremental GC）**的实现。</p>
<p>首先对用户的修改（Mutation）分 3 类：创建新对象、删除已有对象、调整已有引用</p>
<p>如果用户程序创建了新对象，可以考虑把新对象直接标记为灰色。（虽然也可以考虑标记为黑色，但是标记为灰色可以让 GC 意识到新增了未完成的任务）</p>
<p>如果用户删除了已有的对象，通常做法是等待下一次全量 Mark 算法处理。但实际中暂时不处理。</p>
<p>在调整已有的引用关系时，调整过的都加入灰色集合</p>
<p>内存回收就好比有人在随手扔垃圾，清洁工需要不停打扫。如果清洁工能够跟上人们扔垃圾的速度，那么就不需要太多的 STL（Stop The World）。如果清洁工跟不上扔垃圾的速度，最终环境就会被全部弄乱，这个时候清洁工就会要求“Stop The World”。<strong>三色算法通过对用户修改（Mutation）（创建新对象、删除已有对象、调整已有引用）的增量灰色标记，提高“垃圾”被并发回收的概率。</strong></p>
<p>目前的 <strong>GC 主要都是基于三色标记算法。 至于清除算法，有原地回收算法，也有把存活下来的对象（黑色对象）全部拷贝到一个新的区域的算法。</strong></p>
<table>
<thead>
<tr>
<th><img src="https://s0.lgstatic.com/i/image2/M01/02/28/CgpVE1_Z2OuAXxFjAABfInodsKw867.png" alt="Drawing 15.png" style="zoom:50%;" /></th>
<th><img src="https://s0.lgstatic.com/i/image2/M01/02/28/Cip5yF_Z2POASXuMAACh7n5TBi8380.png" alt="Drawing 17.png" style="zoom:50%;" /></th>
</tr>
</thead>
<tbody></tbody>
</table>
<p>三色标记-清除算法，还没有解决内存回收产生碎片的问题。通常，我们会在三色标记-清除算法之上，再构建一个<strong>整理内存（Compact）的算法。</strong></p>
<p>根据新创建出来的对象，死亡（被回收）概率会更高，而那些已经存在了一段时间的对象，往往更不容易死亡：</p>
<p>把新创建的对象，都先放到一个统一的区域，在 Java 中称为伊甸园（Eden）。这个区域因为频繁有新对象死亡，因此需要经常 GC。将存活下来的对象拷贝到另一个区域，Java 中称为存活区（Survior）。存活区生存下来的对象再进入下一个区域，Java 中称为老生代。Eden、Survior 及老生代之间的关系是对象的死亡概率逐级递减，对象的存活周期逐级增加。三个区域都采用三色标记-清除算法。</p>
<p>Eden 可以考虑和 Survivor 用 1:1 的空间，老生代则可以用更大的空间。Eden 中全量 GC 可以频繁执行，也可以增量 GC 混合全量 GC 执行。老生代中的 GC 频率可以更低，偶尔执行一次全量的 GC。</p>
<p>通常选择 GC 会有实时性要求（最大容忍的暂停时间），需要从是否为高并发场景、内存实际需求等维度去思考。在选择 GC 的时候，复杂的算法并不一定更有效。<img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210702114136599.png" alt="image-20210702114136599" style="zoom:50%;" /></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[计算机网路]]></title>
        <id>https://Joshua-Chang.github.io/post/ji-suan-ji-wang-lu/</id>
        <link href="https://Joshua-Chang.github.io/post/ji-suan-ji-wang-lu/">
        </link>
        <updated>2021-06-07T05:40:09.000Z</updated>
        <content type="html"><![CDATA[<p>公司内网中每个路由器、交换机构成一级子网。最高级的路由器在公司网络的边缘，它可以将网络内部节点连接到其他的网络（网络外部）。本地网络提供商（ISP）提供的互联网先到达边缘的路由器，然后再渗透到内部的网络节点。公司内部的若干服务器可以通过交换机形成一个局域网络；公司内部的办公设备，比如电脑和笔记本，也可以通过无线路由器或者交换机形成局域网络。局域网络之间，可以通过路由器、交换机进行连接，从而构成一个更大的局域网。</p>
<table>
<thead>
<tr>
<th><img src="https://s0.lgstatic.com/i/image6/M01/38/64/Cgp9HWB5O5KAFGFAAAD-82hpYWc483.png" alt="Drawing 2.png" style="zoom: 50%;" /></th>
<th><img src="https://s0.lgstatic.com/i/image6/M00/38/6D/CioPOWB5O7uAUZ7qAAB_rmbTigw120.png" alt="Drawing 4.png" style="zoom:50%;" /></th>
</tr>
</thead>
<tbody></tbody>
</table>
<p>通信<strong>链路</strong>（Communication Link），用于传输网络信号。公司<strong>内网</strong>从<strong>本地网络服务提供商</strong> （Internet Service Provider） 接入，然后内部再分成一个个<strong>子网</strong>。路径分叉时需要进行<strong>交换</strong>（Switch），数据从一条链路进入交换设备，然后缓存下来，再转发（切换）到另一条路径，常见的交换设备是链路层交换机（Link-Layer Switch）和路由器（Router），交换机连接多台设备，路由器连接两个网络，但是路由器通常也具有交换机的功能。</p>
<img src="https://s0.lgstatic.com/i/image6/M00/38/6D/Cgp9HWB5RAmAZRwzAACtAP-CPWs242.png" alt="Drawing 1.png" style="zoom: 25%;" />
<p>TCP（Transport Control Protocol）是一个传输层协议：提供主机到主机的（Host-To-Host）数据的可靠传输，支持全双工，是一个连接导向的协议。</p>
<p>TCP 上层应用层：不同应用要使用TCP的能力，通过端口号区分应用。</p>
<p>TCP 下层网络层：提供地址到地址的通信（Address-To-Address），IP 协议解决地址到地址的通信。</p>
<p>网络层只负责ip地址到地址的通讯，再往下层通过路由/交换的链路传输网络信号，再通过下层物理层的具体传输介质作为载体。</p>
<table>
<thead>
<tr>
<th>应用层http/ssh</th>
<th>传输层tcp/udp</th>
<th>网络层ip</th>
</tr>
</thead>
<tbody>
<tr>
<td>Port-To-Port</td>
<td>Host-To-Host</td>
<td>Address-To-Address</td>
</tr>
<tr>
<td>Session</td>
<td>Connection</td>
<td></td>
</tr>
</tbody>
</table>
<p>TCP 是一个连接导向的协议，设计有建立连接（握手）和断开连接（挥手）的过程。TCP 没有设计会话（Session），因为会话通常是一个应用的行为。</p>
<img src="https://s0.lgstatic.com/i/image6/M00/3A/20/CioPOWB-RYSASfPkAAEen4ZR3gw297.png" alt="619.png" style="zoom:25%;" />
<p>如果一个 Host 主动向另一个 Host 发起连接，称为 SYN（Synchronization），请求同步；</p>
<p>如果一个 Host 主动断开请求，称为 FIN（Finish），请求完成；</p>
<p>如果一个 Host 给另一个 Host 发送数据，称为 PSH（Push），数据推送。</p>
<p>以上 3 种情况，接收方收到数据后，都需要给发送方一个 ACK（Acknowledgement）响应。</p>
<table>
<thead>
<tr>
<th><img src="https://s0.lgstatic.com/i/image6/M00/38/6D/Cgp9HWB5RCqAVfhiAADJmfGn2O0616.png" alt="Drawing 4.png" style="zoom:33%;" /></th>
<th><img src="https://s0.lgstatic.com/i/image6/M00/3D/55/CioPOWCTwu-AD9PgAABp1yJqsPI439.png" alt="图片2.png" style="zoom:33%;" /></th>
</tr>
</thead>
<tbody></tbody>
</table>
<p>TCP 是一个双工协议，为了让双方都保证，建立连接的时候，连接双方都需要向对方发送 SYC（同步请求）和 ACK（响应）</p>
<p>握手阶段双方都没有烦琐的工作，因此一方向另一方发起同步（SYN）之后，另一方可以将自己的 ACK 和 SYN 打包作为一条消息回复。</p>
<p>到了挥手阶段，双方都可能有未完成的工作。收到挥手请求的一方，必须马上响应（ACK），等所有工作结束，再发送请求中断连接（FIN）。</p>
<img src="https://s0.lgstatic.com/i/image6/M01/3A/3C/Cgp9HWB-mz2ALAO6AAFJNuQ9-SU088.png" alt="Drawing 5.png" style="zoom:50%;" />
<p>TCP 拆包的作用是将任务拆分处理，减小底层网络处理的压力，降低整体任务出错的概率。</p>
<p>在内存中开辟的一块缓冲区供TCP 段排队，将数据拆分成不超过缓冲区大小的部分，即 TCP 段（<strong>TCP Segment</strong>）进行发送。</p>
<p>拆包：一个数据太大，经过拆分多个 TCP 段发送，然后在目的地重组。</p>
<p>粘包：多个数据太小，合并成一个 TCP 段发送，在目的地再还原成多个数据。</p>
<p>TCP 利用Seq、ACK（发送字节数、接收字节数）的唯一性来确定封包之间的顺序关系。</p>
<p>MSS（Maximun Segment Size）是 TCP Header 中的可选项，双方协商控制TCP 段的大小。</p>
<p>MSS 太小，每一份数据都要增加一个头部，那头部的数据占比会上升，吞吐量下降。</p>
<p>MSS 太大，会降低性能，比如缓冲区变大造成的内存性能/服务器资源的占用等硬件和计算资源、支持 TCP 协议工作的 IP 协议（TCP 协议不肯拆包，IP 协议就需要拆出大量的包），工作效率会下降。</p>
<blockquote>
<p>TCP Header</p>
<figure data-type="image" tabindex="1"><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/tcpsegment.png" alt="" loading="lazy"></figure>
</blockquote>
<p>TCP 中每个发送的请求都需要响应。如果一个请求没有收到响应，发送方就会认为这次发送出现了故障，会触发重发。</p>
<p>但是每一个请求收到响应之后，再发送下一个请求，吞吐量会很低，浪费带宽。改进方式，就是让发送方有请求就发送出去，而不是等待响应。发送的数据连在了一起，响应的数据也连在了一起，吞吐量就提升了。</p>
<p>为了提高传输速率，TCP 协议选择将多个段同时发送，为了让这些段不至于被接收方拒绝服务，在发送前，双方要协商好发送的速率。但是我们不可能完全确定网速，所以协商的方式，就变成确定窗口大小。</p>
<p>有了窗口，发送方利用滑动窗口算法发送消息；接收方构造缓冲区接收消息，并给发送方 ACK。滑动窗口的实现只需要数组和少量的指针即可。（其他用途：求一个数组中最大的连续 k 项和）。</p>
<table>
<thead>
<tr>
<th>队列</th>
<th>滑动窗口</th>
</tr>
</thead>
<tbody>
<tr>
<td><img src="https://s0.lgstatic.com/i/image6/M00/3A/FA/CioPOWCCKwuAfBn5AABKdgtX54w997.png" alt="image (3).png" style="zoom:33%;" /></td>
<td><img src="https://s0.lgstatic.com/i/image6/M00/3A/F2/Cgp9HWCCKxSAROSpAAA_zThgiBA669.png" alt="image (4).png" style="zoom:33%;" /></td>
</tr>
</tbody>
</table>
<p>实现这样的模型，用队列要用多个队列。用滑动窗口才是最合适的数据结构，将已发送的数据放到最左边，发送中的数据放到中间，未发送的数据放到右边。假设我们最多同时发送 5 个封包，也就是窗口大小 = 5。窗口中的数据被同时发送出去，然后等待 ACK（浅绿色）。如果一个封包 ACK 到达，我们就将它标记为已接收（深绿色）。</p>
<p>RTT 表示 Round Trip Time，就是消息一去一回的时间。</p>
<p><strong>确认与重发的机制</strong></p>
<p>自适应重传算法**（<strong>Adaptive Retransmission Algorithm</strong>）**</p>
<p>快速重传：接收方可以发送多次某段的 ACK，如果发送方收到多个该段ACK，就会重发该段。</p>
<p><strong>Selective Acknowledgment</strong> （<strong>SACK</strong>）</p>
<p>发送方将数据拆包，变成多个段。然后将数据放入一个拥有滑动窗口的数组，依次发出，仍然遵循先入先出（FIFO）的顺序，但是窗口中的段会一次性发送。窗口中序号最小的段如果收到 ACK，窗口就会发生滑动；如果最小序号的分组长时间没有收到 ACK，就会触发整个窗口的数据重新发送。在多次传输中，网络的平均延迟往往是相对固定的，这样 TCP 协议可以通过双方协商窗口大小控制流速。</p>
<p>UDP（User Datagram Protocol），目标是在传输层提供直接发送报文（Datagram）的能力。UDP 协议不会拆分数据，Datagram 就是数据传输的最小单位。</p>
<img src="https://s0.lgstatic.com/i/image6/M01/3B/0F/Cgp9HWCCfQeAGOF3AACK2Gf5t6I606.png" alt="图片1.png" style="zoom:50%;" />
<p>Length 是Datagram长度。</p>
<p>Data octets 就是一个字节一个字节的数据，Octet 是 8 位。</p>
<p>IP（Internet Protocol）协议接收 IP 协议上方的 Host-To-Host 协议传来的数据，然后进行分片Fragmentation。然后 IP 协议为每个片段（Fragment）增加一个 IP 头（Header），组成一个IP 封包（Datagram）之后，通过寻址和路由目的地和路径确认，最后调用底层的数据链路层传送数据。</p>
<img src="https://s0.lgstatic.com/i/image6/M00/3C/0B/CioPOWCH4u-AWVEAAAH_xR5D6lU716.png" alt="Drawing 1.png" style="zoom: 33%;" />
<blockquote>
<p>主机到主机（Host-to-Host）协议传递来的数据，比如一个 TCP 段（Segment），然后将 TCP 段再次切片做成一个个的 IPv4/v6 封包（Datagram or Packet），寻址路由，再调用数据链路层传输数据。</p>
</blockquote>
<p>可靠性保证数据无损地到达目的地。可靠性是 IP 协议上方的 Host-To-Host 协议保证的，比如 TCP 协议通过应答机制、窗口等保证数据的可靠性。 IP 协议自身不能保证可靠性。IP 协议可能会有如下问题：</p>
<ol>
<li>
<p>封包损坏（数据传输过程中被损坏）；</p>
</li>
<li>
<p>丢包（数据发送过程中丢失）；</p>
</li>
<li>
<p>重发（数据被重发，比如中间设备通过 2 个路径传递数据）；</p>
</li>
<li>
<p>乱序（到达目的地时数据和发送数据不一致）。</p>
</li>
</ol>
<p>网络层主要有 3 个问题要解决：</p>
<ol>
<li>
<p>延迟</p>
</li>
<li>
<p>吞吐量</p>
</li>
<li>
<p>丢包率</p>
</li>
</ol>
<p>IP Header</p>
<img src="https://s0.lgstatic.com/i/image6/M00/3C/7D/Cgp9HWCKhJaAKKEhAABhmC7udP0409.png" alt="image (1).png" style="zoom:50%;" />
<p>IHL（Internet Header Length）用来描述 IP 协议头的大小。所以 IP 协议头的大小是可变的。IHL 只有 4 位，最大值 1111 = 15。最大是 15 个双字（15*4 字节 = 60 字节）。</p>
<p>Type Of Service 服务的类型，三个波段（band）的优先级也不相同。被分配到三个波段（band）里面的，band 0 的优先级最高，band 2 的最低，用来平衡延迟、吞吐量和丢包率之间的关系。</p>
<p>Total Length 定义报文（封包 Datagram）的长度。</p>
<p>Identification（报文的 ID），发送方分配，代表顺序。</p>
<p>Fragment offset 描述要不要分包（拆分），以及如何拆分。</p>
<p>Time To Live 描述封包存活的时间。因此每个 IP 封包发送出去后，就开始销毁倒计时。</p>
<p>Protocol 是描述上层的协议，比如 TCP = 6，UDP = 17。</p>
<p>Header Checksum 用来检验封包的正确性，如果 Checksum 对不上，就需要选择丢弃这个封包。</p>
<p>原地址和目标地址。IPv4 的地址是 4 组 8 位的数字，共是 32 位。</p>
<p>Options 代表可选项。</p>
<p>延迟（latency）</p>
<p>延迟指的是 1 bit 的数据从网络的一个终端传送到另一个终端需要的时间。这个时间包括在发送端准备发送的时间、排队发送的时间、发送数据的时间、数据传输的时间等。</p>
<p>吞吐量（Throughput）</p>
<p>吞吐量指单位时间内可以传输的平均数据量。比如用 bit/s 作为单位，就是 bps。</p>
<p>丢包率（Packet loss）</p>
<p>丢表率指发送出去的封包没有到达目的地的比例。 在最大流速确定的网络中，丢包率会直接影响吞吐量。</p>
<p>寻址Addressing：地址高位到低位和255.0.0.0（子网掩码）做位与运算依次得到子网地址。子网掩码的作用就是帮助根据 IP 地址找到对应子网。</p>
<p>路由Routing：由于网络和网络间是网关在连接，因此如果目的地 IP 不在局域网中，就需要为 IP 封包选择通往下一个网络的路径，其实就是选择其中一个网关Gateway。</p>
<p>IPv4 的地址是 4 个 8 位（octet），总共 32 位。 IPv6 的地址是 8 个 16 位（hextet），总共 128 位。</p>
<img src="https://s0.lgstatic.com/i/image6/M01/3C/0B/CioPOWCH4wGAT3bUAALH_YQ0Q-U502.png" alt="Drawing 3.png" style="zoom:33%;" />
<p>省略表示</p>
<pre><code class="language-jade">0123:4567:0000:0000:0123:4567:0000:cdef
0123:4567::0123:4567:0000:cdef //::省略了若干组0000
123:4567::123:4567:0:cdef //省略开头的0
3c4d::/16 //只有前16位有数据
</code></pre>
<p><strong>IPv6 地址太多，因此不再需要子网掩码，而是直接将 IPv6 的地址分区即可</strong>。</p>
<p>IPv6 的寻址分成了几种类型：</p>
<ul>
<li>全局单播寻址（和 IPv4 地址作用差不多，在互联网中通过地址查找一个设备，简单来说，单播就是 1 对 1）；</li>
<li>本地单播（类似 IPv4 里的一个内部网络，要求地址必须以<code>fe80</code>开头，类似我们 IPv4 中<code>127</code>开头的地址）；</li>
<li>分组多播（Group Multicast），类似今天我们说的广播，将消息发送给多个接收者；</li>
<li>任意播（Anycast），这个方式比较特殊，接下来我们会详细讲解。</li>
</ul>
<blockquote>
<p>全局单播时，IPv6 地址通常分成 3 个部分</p>
<ul>
<li>站点前缀（Site Prefix）48bit，一般是由 ISP（Internet Service Providor，运营商）或者RIR（Regional Internet Registry， 地区性互联网注册机构），RIR 将 IP 地址分配给运营商；</li>
<li>子网号（Subnet ID），16bit，用于站点内部区分子网；</li>
<li>接口号（Interface ID）， 64bit，用于站点内部区分设备。</li>
</ul>
<p>IPv6 也是一个树状结构，站点前缀需要一定资质，子网号和接口号内部定义。IPv6 的寻址过程就是先通过站点前缀找到站点，然后追踪子网，再找到接口（即设备的网卡）。</p>
</blockquote>
<img src="https://s0.lgstatic.com/i/image6/M01/3C/03/Cgp9HWCH4w-AEinAAAHIfeF4_II848.png" alt="Drawing 5.png" style="zoom:25%;" />
<blockquote>
<p>本地单播 虽然理论上 IPv6 可以将所有的设备都连入一个网络。但实际中还是需要一个内部网络。在局域网络中，实现设备到设备的通信，就是本地单播。本地单播地址必须以<code>fe80</code>开头，后面 64 位的 0，然后接上 54 位的设备编号。类似于127.0.0.。上图中的 Interface 可以理解成网络接口，其实就是网卡。</p>
<img src="https://s0.lgstatic.com/i/image6/M01/3C/03/Cgp9HWCH4x6AJJxNAAEMhuOKNmY768.png" alt="Drawing 7.png" style="zoom:25%;" />
</blockquote>
<blockquote>
<p>IPv6 中设计了分组多播，来实现广播的能力。当 IP 地址以 8 个 1 开头，也就是<code>ff00</code>开头，后面会跟上一个分组的编号时，就是在进行分组多播。</p>
</blockquote>
<blockquote>
<p>任意播，本质是将消息发送给多个接收方，并选择一条最优的路径。比如说在一个网络中有多个授时服务，这些授时服务都共享了一个任播地址。客户端想要获取时间，就将请求发送到这个任播地址。会找到授时服务中的一个或者多个，但是距离最近的往往会先被发现。</p>
</blockquote>
<p>IPv6 和 IPv4 的兼容</p>
<p><strong>IPv4 网络和 IPv6 网络通信</strong>时通过DNS64 查询服务把 IPv4 地址和 IPv6 地址同时返回。再通过NAT64 路由器将 IPv6 地址转换为 IPv4 地址。</p>
<p><strong>两个 IPv6 网络被 IPv4 隔离</strong>时通过Tunnel，<strong>隧道的本质就是在两个 IPv6 的网络出口网关处，实现一段地址转换的程序</strong>。</p>
<p><strong>IPv6 解决的是地址耗尽的问题</strong>。因为解决了地址耗尽的问题，所以很多其他问题也得到了解决，比如说减少了子网，更小的封包头部体积，最终提升了性能等。</p>
<p>链路层发送数据靠的是 MAC 地址，不同于IP地址（住址），MAC 地址就好像人的身份证一样。</p>
<p>数据的发送方，将自己的 MAC 地址、目的地 MAC 地址，以及数据作为一个分组（Packet），也称作 <strong>Frame</strong> 或者封包，发送给交换机。交换机再根据目的地 MAC 地址，将数据转发到目的地的网络接口（网卡）。</p>
<blockquote>
<p>TCP 协议滑动窗口中的MSS（Maximun Segment Size）是 TCP 段最大值，是传输层概念。</p>
<p>IP层 封包（Datagram）</p>
<p>如果 IP 协议要传输数据，就要将数据转换成为链路层的Frame，然后才可以在链路层传输。IP 协议要根据 MTU 拆分封包。</p>
<p><strong>MTU</strong>（Maximun Transmission Unit）链路层网络允许的最大传输数据分组的大小，是链路层概念。<strong>IP 协议要根据 MTU 拆分封包</strong></p>
<p>交换机的作用更侧重局域网内各主机交换，路由器的作用更侧重从局域网内主机到另一个局域网内主机路经的路由。</p>
<p>数据从一条链路进入交换设备，然后缓存下来，再转发（切换）到另一条路径叫做Switch，链路层交换机（Link-Layer Switch）和路由器（Router）都是能起这一作用设备。局域网边界与另一局域网边界即为网关，因为路由器也起到连结两个局域网的作用，因此网关一般理解为就是路由器的IP。</p>
</blockquote>
<p>已知 IP 地址，找到 MAC 地址的协议，叫作地址解析协议（ARP Address Resolution Protoco）。<strong>ARP</strong>和 <strong>DNS 非常相似，采用的是逐级缓存的设计减少 ARP 请求</strong>。发送接口先查询本地的 ARP 表，如果本地没有数据，然后广播 ARP 查询。这个时候如果交换机中有数据，那么查询交换机的 ARP 表；如果交换机中没有数据，才去广播消息给其他接口。</p>
<p>局域网内主机数据交换根据MAC 地址，将自己的 MAC 地址、目的地 MAC 地址，以及数据作为一个 Frame 封包，发送给交换机。交换机再根据目的地 MAC 地址，将数据转发到目的地的网络接口（网卡）。当然13/26交叉网线连结两主机的特殊局域网另算。</p>
<p>发到外网要先发到网关这一特殊主机Mac地址，在由网关往外发。</p>
<p>网络地址解析协议（<strong>NAT</strong> Network Address Translation）解决的是内外网通信的问题。NAT 通常发生在内网和外网衔接的路由器中，NAT将内网中某个 IP 地址映射到外网 IP，然后再把数据发送给外网的服务器。</p>
<p><strong>127.0.0.1, localhost, 0.0.0.0 有什么不同</strong></p>
<p><code>127.0.0.1</code>是本地回环<strong>地址</strong>（loopback），发送到 loopback 的数据会被转发到本地应用。</p>
<p>localhost 是<strong>主机</strong>名，指代的本地计算机，用于访问绑定在 loopback 上的服务。</p>
<p><code>0.0.0.0</code>是不可路由 IP 地址，当把一个服务绑定到<code>0.0.0.0</code>，相当于把服务绑定到任意的 IP 地址。</p>
<p>客户端将数据发送给在客户端侧的Socket 对象，然后客户端侧的 Socket 对象将数据发送给服务端侧的 Socket 对象。Socket 对象负责提供通信能力，并处理底层的 TCP 连接/UDP 连接。对服务端而言，每一个客户端接入，就会形成一个和客户端对应的 Socket 对象，如果服务器要读取客户端发送的信息，或者向客户端发送信息，就需要通过这个客户端 Socket 对象。</p>
<p>对于一个服务端 Socket 文件，我们要设置它监听的端口。比如 Nginx 监听 80 端口、Node 监听 3000 端口、SSH 监听 22 端口、Tomcat 监听 8080 端口。端口监听不能冲突，不然客户端连接进来创建客户端 Socket 文件，文件描述符就不知道写入哪个服务端 Socket 文件了。</p>
<p>服务端监听端口的本质，是将服务端 Socket 文件和端口绑定，这个操作也称为 bind。</p>
<img src="https://s0.lgstatic.com/i/image6/M01/3E/7B/Cgp9HWCZ8deAY_UqAAFeGtcsKIg099.png" style="zoom:25%;" />
<p>从另一个角度去分析，Socket 还是一种双向管道文件，也是文件描述符。</p>
<p>在服务端有两种 Socket 文件，每个客户端接入之后会形成一个客户端的 Socket 文件，客户端 Socket 文件的文件描述符会存入服务端 Socket 文件。通过这种方式，一个线程可以通过读取服务端 Socket 文件中的内容拿到所有的客户端 Socket。这样一个线程就可以负责响应所有客户端的 I/O，这个技术称为 I/O 多路复用。</p>
<p>主动式的 I/O 多路复用（select poll），对负责 I/O 的线程压力过大，因此通常会设计一个高效的中间数据结构作为 I/O 事件的观察者，线程通过订阅 I/O 事件被动响应，这就是响应式模型。在 Socket 编程中，最适合提供这种中间数据结构的就是操作系统的内核，事实上 epoll 模型也是在操作系统的内核中提供了红黑树结构。</p>
<p>扫描和监听：对于一个服务端程序，可以定期扫描服务端 Socket 文件的变更，来了解有哪些客户端想要连接进来。如果在服务端 Socket 文件中读取到一个客户端的文件描述符，就可以将这个文件描述符实例化成一个 Socket 对象。</p>
<p>之后，服务端可以将这个 Socket 对象加入一个容器（集合），通过定期遍历所有的客户端 Socket 对象，查看背后 Socket 文件的状态，从而确定是否有新的数据从客户端传输过来。</p>
<p>上述的过程，我们通过一个线程就可以响应多个客户端的连接，也被称作I/O 多路复用技术</p>
<table>
<thead>
<tr>
<th><img src="https://s0.lgstatic.com/i/image6/M01/3E/83/CioPOWCZ8fOAaVwEAAJ4CITeHSs003.png" alt="" loading="lazy"></th>
<th><img src="https://s0.lgstatic.com/i/image6/M01/3E/7B/Cgp9HWCZ8fyAJIK7AAFzaGqyFsw603.png" alt="" loading="lazy"></th>
</tr>
</thead>
<tbody></tbody>
</table>
<p>如果接入的客户端 Socket 较多，每次轮询的开销都会很大。从程序设计的角度来看，像这样主动遍历，比如遍历一个 Socket 集合看看有没有发生写入（有数据从网卡传过来），称为命令式的程序。</p>
<p>响应式（Reactive）epoll：响应式的角度去看 Socket 编程，应该是有某个观察者会观察到 Socket 文件状态的变化，从而通知处理线程响应。线程不再需要遍历 Socket 集合，而是等待观察程序的通知。 Socket 文件的读写都要经过操作系统，所以最合适的观察者其实是操作系统本身。</p>
<ol>
<li>线程需要告诉中间的观察者自己要观察什么：即注册</li>
<li>中间的观察者服务于很多的线程，需要实现一个高效的数据结构：通常是基于红黑树的二叉搜索树</li>
</ol>
<blockquote>
<p>响应式为什么用红黑树？</p>
<p>中间观察者核心诉求：第一是让线程可以注册自己关心的消息类型。第二能够快速地判断是哪个线程需要知道这个消息。因此需要一个快速能插入（注册过程）、查询（通知过程）一个整数的数据结构，这个整数就是 Socket 的文件描述符。能够解决这个问题的数据结构中，跳表和二叉搜索树都是不错的选择。</p>
<p>epoll 为什么用红黑树？</p>
<p>【解析】在 Linux 的设计中有三种典型的 I/O 多路复用模型 select、poll、epoll。</p>
<p>select 是一个主动模型，需要线程自己通过一个fdset集合存放所有的 Socket，然后发生 I/O 变化的时候遍历。在 select 模型下，操作系统不知道哪个线程应该响应哪个事件，而是由线程自己去操作系统看有没有发生网络 I/O 事件，然后再遍历自己管理的所有 Socket，看看这些 Socket 有没有发生变化。</p>
<p>poll 提供了更优质的编程接口，但是本质和 select 模型相同。因此千级并发以下的 I/O，你可以考虑 select 和 poll，但是如果出现更大的并发量，就需要用 epoll 模型。</p>
<p>epoll 模型在操作系统内核中提供了一个中间数据结构，这个中间数据结构会提供事件监听注册，以及快速判断消息关联到哪个线程的能力（红黑树实现）。因此在高并发 I/O 下，可以考虑 epoll 模型，它的速度更快，开销更小。</p>
</blockquote>
<img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210610220052461.png" alt="image-20210610220052461" style="zoom:67%;" />
<img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210610215833870.png" alt="image-20210610215833870" style="zoom:67%;" />
<img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210610220128299.png" alt="image-20210610220128299" style="zoom:67%;" />
<img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210611113050387.png" alt="image-20210611113050387" style="zoom:50%;" />
<p><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210611113309558.png" alt="image-20210611113309558" style="zoom:50%;" /><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210611113510282.png" alt="image-20210611113510282" style="zoom:50%;" /></p>
<img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210611103433126.png" alt="image-20210611103433126" style="zoom:67%;" />
<img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210611115050524.png" alt="image-20210611115050524" style="zoom:50%;" />
<p>幂等方法：提交一次和多次效果一样。</p>
<p>服务端相应码</p>
<p>1XX 请求已接收到，还需进一步处理。</p>
<p>2XX OK成功返回响应</p>
<p>3xx 重定向 301永久 302临时</p>
<p>4xx 客户端错误 401认证错误 407认证代理错误 403权限错误 404临时没找到资源 406语言/编码资源不存在</p>
<p>408请求超时</p>
<p>5XX服务器错误 501功能尚未实现 502代理服务器错误 504代理服务器超时</p>
<p>Connection 头部 Keep-Alive:长连接</p>
<p>客户端请求长连接Connection: Keep-Alive</p>
<p>服务器表示支持长连接Connection: Keep-Alive</p>
<p>客户端复用连接</p>
<blockquote>
<p>HTTP/1.1 默认支持长连接Connection: Keep-Alive 无意义， Connection：Close关闭</p>
<p>Connection只对当前连接有效，层层代理服务器，每层单独处理。</p>
</blockquote>
<p>典型的REST（Representational state transfer表现状态转换） 讲的是一套前端无状态、服务端管理状态，中间设计转化途径（请求、函数等）的架构方法。按照HTTP 协议中方法的约定就是最好的使用。</p>
<p>Restful 中的 State是服务端状态，可以理解为业务的状态。</p>
<p>前端（浏览器、应用等）没有业务状态，却又要展示内容，因此前端拥有的是状态的表示，也就是 Representation。</p>
<p>用户通过前端向服务端做状态的变化请求即为转换。</p>
<img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210611145334304.png" alt="image-20210611145334304" style="zoom:50%;" />
<img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210611145251103.png" alt="image-20210611145251103" style="zoom:50%;" />
<blockquote>
<p>X-Real-Ip非RFC官方规定的头，nignix里的。</p>
<p>Max-Forwards 代理服务器最大转发次数，Via指名经过的代理服务器名称及版本，Cache-Control：no-transform禁止代理服务器修改响应包体</p>
</blockquote>
<img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210611151227487.png" alt="image-20210611151227487" style="zoom:50%;" />
<img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210611152015637.png" alt="image-20210611152015637" style="zoom:50%;" />
<p>请求的上下文</p>
<p>User-Agent ：指名客户端类型</p>
<p>Referer:来自某一页面的请求自动添加的头部，服务器端常用于统计分析、缓存优化、防盗链等功能</p>
<p>From：告诉服务器如何通过邮件联系到爬虫的负责人</p>
<p>响应上下文</p>
<p>Server：指明服务器上所用软件的信息,用于帮助客户端定位问题或者统计数</p>
<p>Allow:告诉客户端,服务器上该 URI 对应的资源允许哪些方法的执行 Allow: GET, HEAD, PUT</p>
<p>Accept-Ranges:告诉客户端服务器上该资源是否允许 range 请求 Accept-Ranges = bytes接收range请求  none相反</p>
<p>内容协商</p>
<p>每个 URI 指向的资源可以是任何事物,可以有多种不同的表述,例如一份文档可以有不同语言的翻译、不同的媒体格式、可以针对不同的浏览器提供不同的压缩编码等。</p>
<img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210611153755910.png" alt="image-20210611153755910" style="zoom:50%;" />
<p>协商要素</p>
<p>质量因子 q:内容的质量、可接受类型的优先级</p>
<p>媒体资源的 MIME 类型及质量因子（Accept: text/html,application/xhtml+xml）</p>
<p>字符编码:由于 UTF-8 格式广为使用, Accept-Charset 已被废弃 （Accept-Charset: ISO-8859-1,utf-8;q=0.7,*;q=0.7）</p>
<p>内容编码:主要指压缩算法（Accept-Encoding: gzip, deflate）</p>
<p>表述语言（Accept-Language: zh-CN,zh;q=0.9,en-US;q=0.8,en;q=0.7）</p>
<p>internationalization(i18n,i  和  n  间有  18  个字符) 指设计软件时,在不同的国家、地区可以不做逻辑实现层面的修改便能够以不同的语言显示</p>
<p>localization(l10n,l  和  n  间有  10  个字符) 指内容协商时,根据请求中的语言及区域信息,选择特定的语言作为资源表述</p>
<p>资源表述的元数据头部</p>
<p>媒体类型、编码content-type: text/html; charset=utf-8</p>
<p>内容编码• content-encoding: gzip</p>
<p>语言Content-Language: de-DE, en-CA</p>
<p>HTTP 包体:承载的消息内容• 请求或者响应都可以携带包体• HTTP-message = start-line *( header-field CRLF ) CRLF [ message-body ] • message-body = *OCTET:二进制字节流• 以下消息不能含有包体• HEAD 方法请求对应的响应• 1xx、204、304 对应的响应• CONNECT 方法对应的 2xx 响应</p>
<p>发送 HTTP 消息时两种传输 HTTP 包体的方式</p>
<p>已确定包体的全部长度，使用 Content-Length 头部明确指明包体长度（10进制），不能写错</p>
<p>不能确定包体的全部长度，使用 Transfer-Encoding 头部指明使用 Chunk 传输方式。Content-Length 头部应被忽略</p>
<img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210611160524934.png" alt="image-20210611160524934" style="zoom:50%;" />
<p>multipart(RFC1521):一个包体中多个资源表述</p>
<p>Content-type 头部指明这是一个多表述包体，Content-type: multipart/form-data; boundary=----WebKitFormBoundaryRRJKeWfHPGrS4LKe</p>
<p>Boundary 分隔符的格式boundary := 0*69<bchars> bcharsnospace • bchars := bcharsnospace / &quot; &quot; • bcharsnospace := DIGIT / ALPHA / &quot;'&quot; / &quot;(&quot; / &quot;)&quot; / &quot;+&quot; / &quot;_&quot; / &quot;,&quot; / &quot;-&quot; / &quot;.&quot; / &quot;/&quot; / &quot;:&quot; / &quot;=&quot; / &quot;?&quot;</p>
<img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210611205116993.png" alt="image-20210611205116993" style="zoom:50%;" />
<img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210611211036459.png" alt="image-20210611211036459" style="zoom:50%;" />
<p>拿之前的Etag做指纹去请求，未失效/修改则继续返回数据，否则返回412错误（服务端的数据发生变化）。</p>
<p>服务器响应range请求：</p>
<p>服务器不支持range请求时返回200 ok，支持时返回状态码 206 Partial Content   Content-Range：bytes 300-500/1000  Content-Range: bytes 500-600/* （a-b/完整大小 未知用*）</p>
<p>范围错误时返回416 Range Not Satisfiable</p>
<img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210611212825096.png" alt="image-20210611212825096" style="zoom:50%;" />
<p>boundary 分隔符和表单提交一样，分割时 前-- ，结尾时 --前后--</p>
<p>Cookie 是保存在客户端、由浏览器维护、表示应用状态的  HTTP 头部</p>
<p>存放在内存或者磁盘中，服务器端生成 Cookie 在响应中通过Set-Cookie 头部告知客户端(允许多个 Set-Cookie 头部传递多个值) ，客户端得到 Cookie 后,后续请求都会自动将 Cookie 头部携带至请求中</p>
<img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210619183506361.png" alt="image-20210619183506361" style="zoom:50%;" />
<p>Cookie 头部中可以存放多个 name/value 名值对，Set-Cookie  头部一次只能传递  1  个  name/value  名值对,响应中可以含多个头部</p>
<p>Cookie 在协议设计上的问题？</p>
<ol>
<li>Cookie 会被附加在每个 HTTP 请求中,所以无形中增加了流量</li>
<li>由于在 HTTP 请求中的 Cookie 是明文传递的,所以安全性成问题(除非用 HTTPS)</li>
<li>Cookie 的大小不应超过 4KB,故对于复杂的存储需求来说是不够用的</li>
</ol>
<img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210619184311413.png" alt="image-20210619184311413" style="zoom:50%;" />
<p>支持双向通讯的 WebSocket</p>
<img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210619184642156.png" alt="image-20210619184642156" style="zoom:50%;" />
<p>长连接的心跳保持</p>
<p>HTTP 长连接只能基于简单的超时(常见为 65 秒)</p>
<p>WebSocket 连接基于 ping/pong 心跳机制维持</p>
<p>兼容 HTTP 协议，默认使用 80 或者 443 端口，协议升级，代理服务器可以简单支持。基于帧:不是基于流(HTTP、TCP)  每一帧要么承载字符数据,要么承载二进制数据。</p>
<p>URI格式：</p>
<p>默认 port 端口 80 ws-URI = &quot;ws:&quot; &quot;//&quot; host [ &quot;:&quot; port ] path [ &quot;?&quot; query ]</p>
<p>默认 port 端口 443 wss-URI = &quot;wss:&quot; &quot;//&quot; host [ &quot;:&quot; port ] path [ &quot;?&quot; query ]</p>
<p>客户端提供信息：host 与 port:主机名与端口• shema:是否基于 SSL • 访问资源:URI • 握手随机数:Sec-WebSocket-Key • 选择子协议: Sec-WebSocket-Protocol • 扩展协议: Sec-WebSocket-Extensions • CORS 跨域:Origin</p>
<p>1 条消息由 1 个或者多个帧组成,frame头有opcode =8关闭帧</p>
<p>心跳帧：可以插在数据帧中传输：ping 帧 opcode=9  可以含有数据； pong 帧 opcode=A  必须与 ping 帧数据相同</p>
<img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210619185513649.png" alt="image-20210619185513649" style="zoom:50%;" />
<figure data-type="image" tabindex="2"><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210610221234379.png" alt="image-20210610221234379" loading="lazy"></figure>
<p>每一层都可以添加头部，物理层是比特流，link链路层是frame，网络层packet加ip头，连接层sequence/datagram加tcp头，应用层http加头部</p>
<p>隐藏data urls：隐藏（ css/base64图片等小文件嵌入到html中以减少http请求数的）data urls。</p>
<p>domain: (*)按域名，is:running websocket资源 is:from-cache缓存的资源 larger-than:大于bit的资源</p>
<p>method:http方法的资源 mine-type:mime类型的资源 多过滤条件加空格并列</p>
<p>连接的上下游：按住shift红色下游，绿色上游</p>
<p>DNS：把可读的域名与IP地址进行映射的数据库，递归查询先根域名服务器com 后权威域名服务器baidu</p>
<img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210613144056200.png" alt="image-20210613144056200" style="zoom:50%;" />
<p>DNS报文：查寻与响应 query查寻域名 response返回IP地址 DNS请求与响应用的是UDP</p>
<p>HTTP1.1重复传输的体积巨大的 HTTP 头部</p>
<p>HTTP/2 (借鉴了SPDY)主要特性</p>
<ol>
<li>传输数据量的大幅减少：以二进制方式传输、HPACK 头部压缩压缩算法:Huffman 编码</li>
<li>多路复用：消息优先级</li>
<li>服务器消息推送：并行推送</li>
<li>应用层下的TLS层</li>
</ol>
<p>HTTP2.0的TCP+TLS 建链握手过多、多路复用与 TCP 的队头阻塞问题</p>
<p>HTTP3/QUIC协议，UDP 报文:先天没有队列概念，解决了握手过多、队头阻塞问题</p>
<p>HTTP3在1RTT 完全握手，在0RTT 恢复会话握手。</p>
<img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210619191802310.png" alt="image-20210619191802310" style="zoom:50%;" />
<p><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210619190739776.png" alt="image-20210619190739776" style="zoom:50%;" /><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210619190829293.png" alt="image-20210619190829293" style="zoom:50%;" /></p>
<img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210619190914482.png" alt="image-20210619190914482" style="zoom:50%;" />
<img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210613204537171.png" alt="image-20210613204537171" style="zoom:50%;" />
<img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210613222750330.png" alt="image-20210613222750330" style="zoom:50%;" />
<img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210613222840024.png" alt="image-20210613222840024" style="zoom:50%;" />
<p>TLS设计目的：身份验证、保密性、完整性</p>
<img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210613222623395.png" alt="image-20210613222623395" style="zoom:50%;" />
<img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210613225106463.png" alt="image-20210613225106463" style="zoom:50%;" />
<p>拿到公钥有两种方式：通过PKI（Public Key Infrastrucure公钥基础设施）第三方、建立连结后先进行一次握手，把公钥给过来</p>
<p>RSA算法早期用在tsl握手中传递对称密钥，先在常用做生成ca证书</p>
<img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210613231139689.png" alt="image-20210613231139689" style="zoom:50%;" />
<img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/image-20210615153258583.png" alt="image-20210615153258583" style="zoom:50%;" />
<p>IP 地址是一个网卡在网络世界的通讯地址，相当于我们现实世界的门牌号码。被点分隔为四个部分，每个部分 8 个 bit，共 32 位。</p>
<img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/IP%E5%88%86%E7%B1%BB.jpg" alt="IP分类" style="zoom:75%;" />
<p><strong>无类型域间选路</strong>，简称<strong>CIDR</strong>将 32 位的 IP 地址一分为二，前面是<strong>网络号</strong>，后面是<strong>主机号</strong>。如10.100.122.2/24，这种地址表示形式，就是 CIDR。斜杠后面数字 24指：32 位中，前 24 位是网络号，后 8 位是主机号。</p>
<p>伴随着 CIDR 存在的，一个是<strong>广播地址</strong>，10.100.122.255。如果发送这个地址，所有 10.100.122 网络里面的机器都可以收到。另一个是<strong>子网掩码</strong>，255.255.255.0。</p>
<p><strong>子网掩码</strong></p>
<p>IP地址与子网掩码通过二进制的与运算（AND：非同时为1皆为0）</p>
<p>1.用来判断出IP地址的网络号和主机号位数</p>
<p>2.用来判断两台机器是否在同一子网，不在同一个子网的两个机器需要通信必须借助路由器。</p>
<ul>
<li>A类IP的子网掩码默认为：255.0.0.0</li>
<li>B类IP的子网掩码默认为：255.255.0.0</li>
<li>C类IP的子网掩码默认为：255.255.255.0</li>
</ul>
<p>人为指定子网掩码为：225.225.255.240（11111111.11111111.11111111.11110000）时，00000000-00001111间的主机才在同一子网如200.67.83.3(0011)和200.67.83.14(1110) 分别与上225.225.255.240（11111111.11111111.11111111.11110000）在同一子网，200.67.83.13(00001101)和200.67.83.77(00101101)不在同一子网。</p>
<p><strong>广播地址</strong></p>
<p>广播的覆盖范围就是其所在网络号下的所有主机号，把主机号所在的二进制位全部变为1即可得到广播地址，如192.168.211.32/24的广播地址为：192.168.211.255</p>
<figure data-type="image" tabindex="3"><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/%E7%A7%81%E6%9C%89%E5%9C%B0%E5%9D%80.jpg" alt="私有地址" loading="lazy"></figure>
<p>IP 分公有的 IP 和私有的 IP。公有 IP 地址通过组织统一分配。 192.168.0.x 是最常用的私有 IP 地址，一般你家里地上网设备不会超过 256 个，所以 /24 的CIDR基本就够了，明显看出 192.168.0 是网络号，后面是主机号。而整个网络里面的第一个地址 192.168.0.1就是你这个私有网络的出口地址，私有网络路由器的地址就是 192.168.0.1，而 192.168.0.255 就是广播地址。</p>
<p>当CIDR斜杠后不是 8 的整数倍时，如16.158.165.91/22</p>
<p>变成二进制来看，22位网络号，16.158不变占16位，165转换二进制为&lt;10100101&gt;，取前6位和之前的16位凑齐22位网络号即16.158.&lt;101001&gt;，后边的&lt;01&gt;和 .91组成10位机器号。</p>
<p>第一个地址是 16.158.&lt;101001&gt;&lt;00&gt;.1，即 16.158.164.1（网络号.1）</p>
<p>子网掩码是 255.255.&lt;111111&gt;&lt;00&gt;.0，即 255.255.252.0。</p>
<p>广播地址为 16.158.&lt;101001&gt;&lt;11&gt;.255，即 16.158.167.255。</p>
<p>lo 全称是<strong>loopback</strong>，又称<strong>环回接口</strong>，往往会被分配到 127.0.0.1 这个地址。这个地址用于本机通信，经过内核处理后直接返回，不会在任何网络中出现。</p>
<p>**一个网络包要从一个地方传到另一个地方，要有确定的地址（ip），还需要有定位功能。**MAC 地址更像是身份证，是一个唯一的标识，MAC 地址的通信范围比较小，局限在一个子网里面。如从 192.168.0.2/24 访问 192.168.0.3/24 是可以用 MAC 地址的。一旦跨子网，即从 192.168.0.2/24 到 192.168.1.2/24，MAC 地址就不行了，需要 IP 地址起作用。CIDR 可以用来判断是不是本地人。</p>
<p>MTU  最大传输单元MAC 层的概念。MAC 层有 MAC 的头，以太网规定连 MAC 头带正文合起来，不允许超过 1500 个字节。正文里面有 IP 的头、TCP 的头、HTTP 的头。如果放不下，就需要分片来传输。</p>
<p><strong>Linux 默认的逻辑是，如果这是一个跨网段的调用，它便不会直接将包发送到网络上，而是企图将包发送到网关。要去的这个地址和我是一个网段的，它才会发送 ARP 请求</strong>如果配置了网关的话，Linux 会获取网关的 MAC 地址，然后将包发出去。网关要和当前的网络至少一个网卡是同一个网段。</p>
<p><strong>动态主机配置协议（Dynamic Host Configuration Protocol）</strong>，简称<strong>DHCP</strong>。**如果是数据中心里面的服务器，IP 一旦配置好，基本不会变，这就相当于买房自己装修。DHCP 的方式就相当于租房。你不用装修，都是帮你配置好的。你暂时用一下，用完退租就可以了。**DHCP 协议主要是用来给客户租用 IP 地址，要通过广播商谈、签约、续租。</p>
<p><strong>Hub集线器</strong>采取的是广播的模式连结主机，临如下问题</p>
<ol>
<li>这个包是发给谁的？谁应该接收？Mac地址</li>
<li>大家都在发，会不会产生混乱？有没有谁先发、谁后发的规则？Mac媒体访问控制</li>
<li>如果发送的时候出现了错误，怎么办？crc</li>
</ol>
<p><strong>MAC</strong>的全称是<strong>Medium Access Control</strong>，即**媒体访问控制，<strong>其实就是控制在往媒体上发数据的时候，谁先发、谁后发的问题。防止发生混乱。即多路访问</strong></p>
<ul>
<li>分多个车道。作<strong>信道划分；</strong></li>
<li>今天单号出行，明天双号出行，作<strong>轮流协议；</strong></li>
<li>有事就出门，发现特堵，就回去。错过高峰再出。我们叫作**随机接入协议。**以太网，用的就是这个方式</li>
</ul>
<p><strong>链路层地址</strong>主要解决媒体接入控制的问题，所以称为<strong>MAC 地址</strong></p>
<p>IP 数据包，开始就是目标的 MAC 地址和源的 MAC 地址。接下来是<strong>类型</strong>。然后IP 里面层层封装 TCP/UDP、HTTP 等。发送时IP数据包在链路上广播，然后目标 MAC 地址发现<img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/IP%20%E6%95%B0%E6%8D%AE%E5%8C%85.jpg" alt="IP 数据包" loading="lazy"></p>
<p>当不知道目标 MAC 地址时目标 MAC 地时，通过<strong>ARP 协议</strong>，即已知目标 IP 地址，求目标MAC 地址的协议，当知道了 目标IP 地址，不知道 MAC 地址，发出广播，谁是这个 IP 谁来应答。为了避免每次都用 ARP 请求，机器本地也会进行 ARP 缓存。</p>
<p><strong>交换机switch</strong>是局域网内主机交换数据的设备，有 MAC 地址学习能力的，维持一个记录目的地址Mac地址的 <strong>转发表</strong> ，新的ARP 请求后，转发表有了记录，下次再去目标Mac地址，便不需APR广播。</p>
<p><strong>CRC</strong>，也就是<strong>循环冗余检测</strong>。通过 XOR 异或的算法，来计算整个包是否在发送的过程中出现了错误。</p>
<p>当交换机数目肯定越来越多，整个拓扑结构复杂，出现<strong>环路问题</strong> 。数据结构中，有一个方法叫作<strong>最小生成树</strong>。有环的我们常称为<strong>图</strong>。将图中的环破了，就生成了<strong>树</strong>。在计算机网络中，生成树的算法叫作<strong>STP</strong>，全称<strong>Spanning Tree Protocol</strong>。</p>
<ul>
<li>当交换机的数目越来越多的时候，会遭遇环路问题，让网络包迷路，这就需要使用 STP 协议，通过华山论剑比武的方式，将有环路的图变成没有环路的树，从而解决环路问题。</li>
<li>交换机数目多会面临隔离问题，可以通过 VLAN 形成虚拟局域网，从而解决广播问题和安全问题。</li>
</ul>
<p>ping 是基于 ICMP 协议工作的。<strong>ICMP</strong>全称<strong>Internet Control Message Protocol</strong>，就是<strong>互联网控制报文协议</strong>,ping 命令执行的时候，源主机首先会构建一个 ICMP 请求数据包，ICMP 数据包内包含多个字段。<strong>类型字段</strong>，请求为8响应为0；<strong>顺序号</strong>，区分连续 ping 的时候发出的多个数据包；为了能够计算往返时间 RTT，它会在报文的数据部分插入发送时间。</p>
<img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/ping.jpg" alt="ping" style="zoom:50%;" />
<p>ICMP 相当于网络世界的侦察兵。我讲了两种类型的 ICMP 报文，一种是主动探查的查询报文，一种异常报告的差错报文；ping 使用查询报文，Traceroute 使用差错报文。</p>
<p><strong>Traceroute 的第一个作用就是故意设置特殊的 TTL（time to live），来追踪去往目的地时沿途经过的路由器</strong>，<strong>还有一个作用是故意设置不分片，从而确定路径的 MTU</strong></p>
<img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/MAC%20%E5%A4%B4%E5%92%8C%20IP%20%E5%A4%B4.jpg" alt="MAC 头和 IP 头" style="zoom:50%;" />
<p>当要访问另一个 IP 地址的时候，先判断目标 IP 地址和当前机器的 IP 地址，是否在同一个网段（需要 CIDR 和子网掩码)。</p>
<p><strong>如果是同一个网段</strong> ，那就没网关什么事情，直接将源地址和目标地址放入 IP 头中，然后通过 ARP 获得 MAC 地址，将源 MAC 和目的 MAC 放入 MAC 头中，发出去就可以了。</p>
<p><strong>如果不是同一网段</strong>，就需要发往默认网关 Gateway(<strong>将源地址和目标 IP 地址放入 IP 头中，通过 ARP 获得网关的 MAC 地址，将源 MAC 和网关的 MAC 放入 MAC 头中，发送出去</strong>)。Gateway 的地址一定是和源 IP 地址是一个网段的。往往不是第一个，就是第二个(如 192.168.1.0/24 这个网段，Gateway 往往会是 192.168.1.1/24 或者 192.168.1.2/24)。</p>
<p><strong>网关往往是一个路由器</strong> <strong>是一个转发的设备</strong>把 MAC 头和 IP 头都取下来，根据里面的内容，看看接下来把包往哪里转发。一个路由器往往有多个网口，如果是一台服务器做这个事情，则就有多个网卡，其中一个网卡是和源 IP 同网段的。网关也是一个处在跨局域网处的特殊主机（路由嵌入式系统软路由），也有IP和Mac地址。</p>
<p>**路由器是一台设备，它有五个网口或者网卡，相当于有五只手，分别连着五个局域网。每只手的 IP 地址都和局域网的 IP 地址相同的网段，每只手都是它握住的那个局域网的网关。**任何一个想发往其他局域网的包，都会到达其中一只手，被拿进来，拿下 MAC 头和 IP 头，看看，根据自己的路由算法，选择另一只手，加上 IP 头和 MAC 头，然后扔出去。</p>
<p>**静态路由，其实就是在路由器上，配置一条一条规则。**每当要选择从哪只手抛出去的时候，就一条一条的匹配规则，找到符合的规则，就按规则中设置的那样，从某个口抛出去，找下一跳 IPX。</p>
<p><strong>MAC 地址是一个局域网内才有效的地址。<strong>MAC 地址只要过网关，就必定会改变，因为已经换了局域网。同时不改变 IP 地址的网关，我们称为</strong>转发网关；<strong>改变 IP 地址的网关，我们称为</strong>NAT 网关（Network Address Translation）</strong>。</p>
<p>转发网关，嵌套header里的IP和目标IP不变，只有Mac和目标Mac随每次从一个网关ip到另一个网关IP而变化（目标Mac依次为下一个网关的Mac地址）</p>
<p>每家都有家用路由器都是 192.168.1.x，当我们家里的包发出去的时候，都被家用路由器 NAT 成为了运营商的地址。一般就是整个办公室共用一个到两个出口 IP 地址。</p>
<ul>
<li>
<p>如果离开本局域网，就需要经过网关，网关是路由器的一个网口；</p>
</li>
<li>
<p>路由器是一个三层设备，里面有如何寻找下一跳的规则；</p>
</li>
<li>
<p>经过路由器之后 MAC 头要变，如果 IP 不变，相当于不换护照的欧洲旅游，如果 IP 变，相当于换护照的玄奘西行。</p>
</li>
<li>
<p>路由分静态路由和动态路由，静态路由可以配置复杂的策略路由，控制转发策略；</p>
</li>
</ul>
<p>动态路由根据路由协议算法生成动态路由表，随网络运行状况的变化而变化。</p>
<ul>
<li>动态路由主流算法有两种，<strong>距离矢量路由</strong>（<strong>distance vector routing</strong>）算法基于 Bellman-Ford 算法产生外网路由协议**（<strong>Border Gateway Protocol</strong>，简称<strong>BGP</strong>）和链<strong>链路状态路由</strong>（<strong>link state routing</strong>）基于 Dijkstra 算法，产生OSPF （<strong>Open Shortest Path First</strong>，<strong>开放式最短路径优先</strong>）动态路由协议   即内部网关协议**（<strong>Interior Gateway Protocol</strong>，简称<strong>IGP</strong>）。</li>
</ul>
<p><strong>TCP 是面向字节流的</strong>。发送的时候发的是一个流，没头没尾。IP 包可不是一个流，而是一个个的 IP 包。之所以变成了流，这也是 TCP 自己的状态维护做的事情。而<strong>UDP 继承了 IP 的特性，基于数据报的，一个一个地发，一个一个地收</strong>不保证不丢失，不保证按顺序到达**</p>
<img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/udp.jpg" alt="udp" style="zoom:50%;" />
<p>无论是 TCP 还是 UDP 包头里面应该有源端口号和目标端口号，根据端口号，将数据交给相应的应用程序。</p>
<ul>
<li>UDP 虽然简单，但它有简单的用法。它可以用在环境简单、需要多播、应用层自己控制传输的地方。例如 DHCP、VXLAN、QUIC 等。</li>
</ul>
<p>链路层Mac叫帧，网络层IP叫包，传输层tcp叫段。</p>
<img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/tcp.jpg" alt="tcp" style="zoom:50%;" />
<p>TCP 双方都要维护各自的状态机。</p>
<table>
<thead>
<tr>
<th><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/tcp%E8%BF%9E%E7%BB%93.jpg" alt="tcp连结" style="zoom:50%;" /></th>
<th><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/tcp%E6%96%AD%E5%BC%80.jpg" alt="tcp断开" style="zoom:50%;" /></th>
</tr>
</thead>
<tbody></tbody>
</table>
<img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/tcp%E7%8A%B6%E6%80%81%E6%9C%BA.jpg" alt="tcp状态机" style="zoom:50%;" />
<p>TCP为了保证顺序性,按照 ID 一个个发送,采用<strong>累计确认</strong>或者<strong>累计应答</strong>（<strong>cumulative acknowledgment</strong>）。</p>
<p>TCP 里，接收端会给发送端报一个窗口的大小，叫<strong>Advertised window</strong>，超过这个窗口的，接收端做不过来，发送端就不能发送了。</p>
<p>Socket 编程进行的是端到端的通信</p>
<p>在网络层，Socket函数需要指定到底是 IPv4 还是 IPv6，分别对应设置为 AF_INET 和 AF_INET6。<br>
在传输层，还要指定到底是 TCP 还是 UDP。TCP 协议是基于数据流的，所以设置为 SOCK_STREAM，而 UDP 是基于数据报的，因而设置为 SOCK_DGRAM。</p>
<p>TCP 的 Socket 就是一个文件流，在 Linux 中就是以文件的形式存在的，写读通过文件描述符。在内核中，Socket 是一个文件，那对应就有文件描述符。每一个进程都有一个数据结构 task_struct，里面指向一个文件描述符数组，来列出这个进程打开的所有文件的文件描述符。文件描述符是一个整数，是这个数组的下标。</p>
<p>两端创建了 Socket 之后，接下来的过程中，TCP 和 UDP 稍有不同。</p>
<table>
<thead>
<tr>
<th><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/sockettcp.jpg" alt="sockettcp" style="zoom:50%;" /></th>
<th><img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/socketudp.jpg" alt="socketudp" style="zoom:50%;" /></th>
</tr>
</thead>
<tbody></tbody>
</table>
<ol>
<li>
<p>TCP 的服务端要先监听一个端口，一般是先调用 bind 函数，给这个 Socket 赋予一个 IP 地址和端口。</p>
</li>
<li>
<p>当服务端有了 IP 和端口号，就可以调用 listen 函数进行监听，这个时候客户端就可以发起连接了。</p>
<p>在内核中，为每个 Socket 维护两个队列。一个是已经建立了连接的队列，这时候连接三次握手已经完毕，处于 established 状态；一个是还没有完全建立连接的队列，这个时候三次握手还没完成，处于 syn_rcvd 的状态。</p>
</li>
<li>
<p>接下来，服务端调用 accept 函数，拿出一个已经完成的连接进行处理。如果还没有完成，就要等着。</p>
</li>
<li>
<p>在服务端等待的时候，客户端可以通过 connect 函数发起连接。先在参数中指明要连接的 IP 地址和端口号，然后开始发起三次握手。内核会给客户端分配一个临时的端口。一旦握手成功，服务端的 accept 就会返回另一个 Socket。</p>
<p>监听的 Socket 和真正用来传数据的 Socket 是两个，一个叫作<strong>监听 Socket</strong>，一个叫作<strong>已连接 Socket</strong>。连接建立成功之后，双方开始通过 read 和 write 函数来读写数据。</p>
</li>
</ol>
<p>UDP 是没有连接的，所以不需要三次握手，也就不需要调用 listen 和 connect，但是，UDP 的的交互仍然需要 IP 和端口号，因而也需要 bind。UDP 是没有维护连接状态的，因而不需要每对连接建立一组 Socket，而是只要有一个 Socket，就能够和多个客户端通信。也正是因为没有连接状态，每次通信的时候，都调用 sendto 和 recvfrom，都可以传入 IP 地址和端口。</p>
<p><strong>socket最大连接数</strong>:系统会用一个四元组来标识一个 TCP 连接<code>{本机 IP, 本机端口, 对端 IP, 对端端口}</code>只有客户端的 IP 和客户端的端口是可变的。</p>
<p>1.多进程方式：在 Linux 下，创建子进程使用 fork 函数。这是在父进程的基础上完全拷贝一个子进程（在 Linux 内核中，会复制文件描述符的列表，也会复制内存空间，还会复制一条记录当前执行到了哪一行程序的进程，根据 fork 的返回值来区分到底是父进程（其他整数即子进程id），还是子进程（0））</p>
<p>2.多线程方式：在 Linux 下，通过 pthread_create 创建一个线程，也是调用 do_fork。不同的是，虽然新的线程在 task 列表会新创建一项，但是很多资源，例如文件描述符列表、进程空间，还是共享的，只不过多了一个引用而已。比多进程更轻量，但一直创建很多进程或者线程操作系统是无法承受的。</p>
<p>3.IO 多路复用，一个线程维护多个 Socket：<strong>一个线程盯的所有的 Socket，都放在一个文件描述符集合 fd_set 中，调用 select 函数来监听文件描述符集合是否有变化</strong>。数量由 FD_SETSIZE 限制,一旦有变化，就会依次查看每个文件描述符。那些发生变化的文件描述符在 fd_set 对应的位都设为 1，表示 Socket 可读或者可写，从而可以进行读写操作，然后再调用 select，接着盯着下一轮的变化。每次 Socket 所在的fd_set中有 Socket 发生变化的时候，都需要通过轮询的方式。</p>
<p>4.IO 多路复用,事件通知:epoll，它在内核中的实现不是通过轮询的方式，而是通过注册 callback 函数的方式，当某个文件描述符发送变化的时候，就会主动通知。 epoll_create 创建一个 epoll 对象，也是一个文件，也对应一个文件描述符，同样也对应着打开文件列表中的一项。在这项里面有一个红黑树，在红黑树里，要保存这个 epoll 要监听的所有 Socket。</p>
<p>当 epoll_ctl 添加一个 Socket 的时候，其实是加入这个红黑树，同时红黑树里面的节点指向一个结构，将这个结构挂在被监听的 Socket 的事件列表中。当一个 Socket 来了一个事件的时候，可以从这个列表中得到 epoll 对象，并调用 call back 通知它。</p>
<p>这种通知方式使得监听的 Socket 数据增加的时候，效率不会大幅度降低，能够同时监听的 Socket 的数目也非常的多了。上限就为系统定义的、进程打开的最大文件描述符个数。因而，<strong>epoll 被称为解决 C10K 问题(（即单机1万个并发连接问题）)的利器</strong>。</p>
<p>目前使用的 HTTP 协议大部分都是 1.1。在 1.1 的协议里面，默认是开启了 Keep-Alive 的，这样建立的 TCP 连接，就可以在多次请求中复用。</p>
<p>HTTP 协议是基于 TCP 协议的，所以它使用面向连接的方式发送请求，通过 stream 二进制流的方式传给对方。HTTP 1.1 在应用层以纯文本的形式进行通信。每次通信都要带完整的 HTTP 的头。HTTP 2.0 通过头压缩、分帧、二进制编码、多路复用等技术提升性能；QUIC 协议通过基于 UDP 自定义的类似 TCP 的连接、重试、多路复用、流量控制技术，进一步提升性能。</p>
<p>对称加密：加密和解密使用的是同一个密钥。</p>
<p>非对称加密：客户端给外卖网站发送的时候，用外卖网站的公钥加密。而外卖网站给客户端发送消息的时候，使用客户端的公钥。这样就算有黑客企图模拟客户端获取一些信息，或者半路截获回复信息，但是由于它没有私钥，这些信息它还是打不开。</p>
<p>数字证书：如何将非对称加密的公钥给对方？由<strong>CA</strong>（ <strong>Certificate Authority</strong>）颁发的称为<strong>证书</strong>（<strong>Certificate</strong>）：里面有<strong>公钥</strong>，证书的**所有者、发布机构、证书有效期、签名算法，CA 用自己的私钥给外卖网站的公钥签名，就相当于给外卖网站背书，形成了外卖网站的证书。**root CA层层授信背书，CA 证书的作用，是保证服务器的公钥的来历。</p>
<p>你不会从外卖网站上得到一个公钥，而是会得到一个证书，这个证书有个发布机构 CA，你只要得到这个发布机构 CA 的公钥，去解密外卖网站证书的签名，如果解密成功了，Hash 也对的上，就说明这个外卖网站的公钥没有啥问题。不是伪装钓鱼的公钥。</p>
<p>无论是客户端还是服务器，都有了三个随机数，分别是：自己的、对端的，以及刚生成的 Pre-Master 随机数。通过这三个随机数，可以在客户端和服务器产生相同的对称密钥。</p>
<img src="https://gitee.com/joshua_chang/pic/raw/master/uPic/https.jpg" alt="https" style="zoom:50%;" />
<ul>
<li>
<p>加密分对称加密和非对称加密。对称加密效率高，但是解决不了密钥传输问题；非对称加密可以解决这个问题，但是效率不高。</p>
</li>
<li>
<p>非对称加密需要通过证书和权威机构来验证公钥的合法性。</p>
</li>
<li>
<p>HTTPS 是综合了对称加密和非对称加密算法的 HTTP 协议。既保证传输安全，也保证传输效率。</p>
</li>
<li>
<p>视频名词比较多，编码两大流派达成了一致，都是通过时间、空间的各种算法来压缩数据；</p>
</li>
<li>
<p>压缩好的数据，为了传输组成一系列 NALU<strong>网络提取层单元</strong>（<strong>NALU</strong>，<strong>Network Abstraction Layer Unit</strong>），按照帧和片依次排列；</p>
</li>
<li>
<p>排列好的 NALU，在网络传输的时候，要按照 RTMP 包的格式进行包装，RTMP 的包会拆分成 Chunk 进行传输；</p>
</li>
<li>
<p>推送到流媒体集群的视频流经过转码和分发，可以被客户端通过 RTMP 协议拉取，然后组合为 NALU，解码成视频格式进行播放。</p>
</li>
</ul>
<p><code>www.example.com. IN A 139.18.28.5;</code>DNS记录：</p>
<p>IN 代表记录用于互联网，是 Intenet 的缩写</p>
<p>A 代表IPv4地址 AAAA IPv6地址</p>
<p>CNAME用于定义域名的别名：将一个域名映射到另一个域名。</p>
<ul>
<li>DNS 是网络世界的地址簿，可以通过域名查地址，因为域名服务器是按照树状结构组织的，因而域名查找是使用递归的方法，并通过缓存的方式增强性能；</li>
<li>在域名和 IP 的映射过程中，给了应用基于域名做负载均衡的机会，可以是简单的负载均衡，也可以根据地址和运营商做全局的负载均衡。</li>
<li><strong>HTTPNDS 其实就是，不走传统的 DNS 解析，而是自己搭建基于 HTTP 协议的 DNS 服务器集群，分布在多个地点和多个运营商。当客户端需要 DNS 解析的时候，直接通过 HTTP 协议进行请求这个服务器集群，得到就近的地址。</strong></li>
<li>传统的 DNS 有很多问题，例如解析慢、更新不及时。因为缓存、转发、NAT 问题导致客户端误会自己所在的位置和运营商，从而影响流量的调度。</li>
<li>HTTPDNS 通过客户端 SDK 和服务端，通过 HTTP 直接调用解析 DNS 的方式，绕过了传统 DNS 的这些缺点，实现了智能的调度。</li>
</ul>
<p>内容分发网络（Content Dilivery Network，CDN）是一个专门用来分发内容的分布式应用，CDN 构建在现有的互联网之上，通过在各地部署数据中心，让不同地域的用户可以就近获取内容。内容通常指的是文件、图片、视频、声音、应用程序安装包等静态资源。很多大型的应用，会把 DNS 解析作为一种负载均衡的手段。</p>
<p>能集中提供这些静态资源呢？这和域名系统的 DNS 记录不能集中提供是一个道理，需要考虑到流量、单点故障、延迟等因素。在离用户更近的地理位置提供资源，可以减少延迟。按照地理位置分散地提供资源，也可以降低中心化带来的服务压力。</p>
<p>当用户请求一个静态资源的时候，首先会触发域名系统的解析。域名系统会将解析的责任交由 CDN 提供商来处理，CDN 的智能 DNS 服务会帮助用户选择离自己距离最近的节点，返回这个节点的 A（或 AAAA）记录。然后客户端会向 CDN 的资源节点发起请求，最终获得资源。</p>
<ul>
<li><strong>有了 CDN 之后，情况发生了变化</strong>。在 web.com 这个权威 DNS 服务器上，会设置一个 CNAME 别名，指向另外一个域名 <a href="http://www.web.cdn.com">www.web.cdn.com</a>，返回给本地 DNS 服务器。</li>
</ul>
<p>CDN 回源就是 CDN 节点到源站请求资源，重新设置缓存。通常服务提供方在使用 CDN 的时候，会在自己的某个域名发布静态资源，然后将这个域名交给 CDN。</p>
<blockquote>
<p>比如源站在 s.example.com 中发布静态资源，然后在 CDN 管理后台配置了这个源站。在使用 CDN 时，服务提供方会使用另一个域名，比如说 b.example.com。然后配置将 b.example.com 用 CNAME 记录指向 CDN 的智能 DNS。这个时候，如果用户下载b.example.com/a.jpg，CDN 的智能 DNS 会帮用户选择一个最优的 IP 地址（最优的 CDN 节点）响应这次资源的请求。如果这个 CDN 节点没有 a.jpg，CDN 就会到 s.example.com 源站去下载，缓存到 CDN 节点，然后再返回给用户。</p>
<p>CDN 回源有 3 种情况，一种是 CDN 节点没有对应资源时主动到源站获取资源；另一种是缓存失效后，CDN 节点到源站获取资源；还有一种情况是在 CDN 管理后台或者使用开放接口主动刷新触发回源。</p>
</blockquote>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Activity启动模式]]></title>
        <id>https://Joshua-Chang.github.io/post/activity-qi-dong-mo-shi/</id>
        <link href="https://Joshua-Chang.github.io/post/activity-qi-dong-mo-shi/">
        </link>
        <updated>2021-06-06T09:51:42.000Z</updated>
        <content type="html"><![CDATA[<p>按下RecentTask键时，显示出一个个的Task。我们可以在最近的Task间切换。<br>
当我们在某个app内，不停按返回键，直到Task里最后一个Activity被关闭，Task的生命结束。但作为最近的Task，他在RecentTask里并不会消失，仍保留一个残影等待重新打开app。（RecentTask里看到的task未必是存活的）</p>
<p>不仅activity在Task内可以叠成栈，不同task也可以叠成栈。但task的叠加只在前台；一旦进入后台task就不再叠加，并拆开成不同Task。进入后台的场景有按home回到桌面、按recentTask查看最近Task。</p>
<ol>
<li>
<p>standard：Activity与启动它的Task相关。在不同Task中打开同一个Activity，Activity会被创建多个实例，分别放进每一个Task顶，互不干扰。<br>
从A app中打开B app里的Activity时，该Activity会直接放到A的task顶。对于B的task没影响。</p>
<p>短信app里点击号码添加联系人，通讯录app的添加联系人Activity被打开，放到短信app所在栈的栈顶，对通讯录app没影响。</p>
</li>
<li>
<p>singleTop：和standard一样，只有会复用Task顶的Activity并<code>onNewIntent</code>，而不必创建新的实例。<br>
从A app中打开B app里的Activity时，只有当A Task顶的Activity的刚好是准备要打开的activity时，才不在栈顶创建该Activity，而是复用之前打开的并<code>onNewIntent</code></p>
</li>
</ol>
<blockquote>
<p>假设主界面为 MainActivity，显示新闻的界面是 DetailActivity，显然显示任何一条新闻都会使用 DetailActivity，即把新闻内容通过 Intent 传给 DetailActivity 就可以了。 假设你正在看新闻1(即在 DetailActivity)，此时手机收到服务器的推送：收到一条通知(新闻2)，点击通知就会跳转到 DetailActivity 并显示新闻2，当你点击通知时，因为目前栈顶的 Activity 就是 DetailActivity，因此这里就是使用 SingleTop 的地方，即点击通知后以 SingleTop 加载模式打开 DetailActivity 并显示新闻2，因此新闻1的 DetailActivity 就被覆盖掉了。 此后你点击返回键会回到主界面。</p>
<p>OnNewIntent</p>
<p>针对网易新闻这个案例来看，DetailActivity一般是一个webView,然后 根据上一个页面（新闻列表）传过来的url展示对应的网页，“通知“也是一样的。都是通过intent把url传到DetailActivity。以下一段代码简单的模拟DetailActivity 接收数据的过程。</p>
</blockquote>
<p>standard、singleTop都是直接在原Task上新建或复用，而singleTask、singleInstance是跨Task打开Activity(过渡时原生有应用间切换动画)。</p>
<ol start="3">
<li>
<p>singleTask：Activity被其他的Task启动的时候：不会直接放到启动他的Task栈顶，而是在自己的Task的栈顶；同时把自己的Task叠加到启动它的Task上(不同task过渡时原生有应用间切换动画)。连按返回键时，退出完自己的task，再退(过渡动画)启动它的task。</p>
<p>第一步：<strong>将被启动Activity放到被启动Task顶部</strong>：没有原Task(外部app未启动)则新开一个；有task但其内没有要启动的Activity(要启动的外部Activity所在的app已启动，但该Activity不在栈内，即没被启动过)则将被启动的Activity放到所在Task栈顶；有task且task内有要启动的Activity时推到栈顶，上边的被推出。</p>
<table>
<thead>
<tr>
<th>没有将被启动的Task(所在app未启动)</th>
<th>有将被启动的Task</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>被启动的activity放入新的task？</td>
<td>将被启动的Activity不在task内(activity未被启动)</td>
<td>在task内</td>
</tr>
<tr>
<td>被启动的activity再启动其他Activity</td>
<td>将被启动的Activity放到Task栈顶 (其他Activity在下)</td>
<td>把顶部推出</td>
</tr>
<tr>
<td>要看被启动者具体的启动模式</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>第二步：<strong>将被启动的task移动到当前task顶</strong>。</p>
<p>被启动的Activity原本的Task里，把Activity推到栈顶并<code>onNewIntent</code>刷新数据，<strong>Activity原来上边的会被推出</strong>。原来还没有task，新开一个Task。<br>
特殊情况：Activity被其他的Task启动后，Activity原task叠加在启动它的task上，此时按下home/recentTask从前台切后台，两个task不再叠加，都出现在recentTask里，在Activity原本的Task栈顶回退不会退到启动他的Task。</p>
<p>短信app里点击邮箱发送邮件，邮箱app的编写邮件Activity被打开。此时回退：会先回退邮箱app打开的页面，再回退短信app的页面。若先按recentTask则发现两个app都出现在最近Task里，再在邮箱里回退不会到短信里。</p>
<p>设置<code>android:allowTaskReparenting=&quot;true&quot;</code> 能回到其原来的父Task，的Activity也有类似效果。Activity被其他的Task启动的时候，会把Activity从原来的Task，移到当前Task栈顶（但不像standard到处创建）。直接回退时不会有切换task动画，切后台再回退也不会。若不回退而是打开原来Task，Activity又回移动回原来Task的额栈顶，再切回启动他的Task时Activity不在里边。</p>
<p>singleTask：只有一个Task里有这个Activity（不同于standard）<strong>唯一性</strong>。</p>
</li>
<li>
<p>singleInstance：比singleTask更严厉，Task里只有一个Activity，要求<strong>独占性</strong>。当Activity被其他的Task启动的时候，把Activity单独放进一个Task（没Task新建后可复用触发<code>onNewIntent</code>），并叠加到启动它的Task上（切换动画）。连续退出也是task切换，若切后台也拆成俩Task。<br>
Home切后台后。若从桌面进入Activity所在的app，原来task的Activity消失（在同TaskAffinity被隐藏的单Activity的task里。此时在recentTask看不见的Task未必被杀死，可能同TaskAffinity被隐藏）。<br>
recentTask切后台后。若进入只有一个Activity的task退一次就回到桌面。</p>
<p>若Activity被其他的Task启动，（没切后台）成为一个单Activity的Task叠加到启动他的Task上，（没切后台）再从单Activity的Task启动另一个Activity，新启动的Activity所在的Task（可以是最初Activity的原Task也无所谓，真是这样原task成了俩task叠在一起），会在单Activity的Task上继续叠加。</p>
</li>
<li>
<p>TaskAffinity：Task相关性。默认情况下一个app只有一个Task在recentTask显示。recentTask根据不同的TaskAffinity列出不同的任务，当多个task有相同TaskAffinity时recentTask显示最近前台展示的一个recent的。</p>
<p>每个Activity有TaskAffinity<code>&lt;activity&gt;默认取&lt;application&gt;的，默认取包名</code>所以默认一个task在recentTask里；<br>
每个Task也有TaskAffinity取自栈底的Activity的TaskAffinity（第一个启动的Activity的TaskAffinity）。</p>
<p>若新打开的Activity设置了singleTask，则系统要比较Activity和当前Task的TaskAffinity是否相同，相同则在当前task入栈；不同则去寻找TaskAffinity相同的task入栈，没有则新建一个Task。</p>
<p>所以在打开一个配置了singleTask的Activity时。若是外部app的，TaskAffinity不同，发送task切换；若是app自己的，TaskAffinity相同，则进入栈顶，前面被推出。若给这个Activity设置一个独立的TaskAffinity，哪怕是在同一个app内也会被拆到另一个task里，若这个独立的TaskAffinity恰好与其他app的一样，这个Activity甚至会被放到别人的app的task里。</p>
</li>
</ol>
<p><code>adb shell dumpsys activity</code>可查看task与activity关系。<code>getRunningTasks</code>等方法早被屏蔽</p>
<pre><code class="language-kotlin">val ams = getSystemService(ActivityManager::class.java)
for (task in ams.appTasks) {
    Log.e(TAG, &quot;${task.taskInfo.numActivities}:[${task.taskInfo.baseActivity?.className}-&gt;${task.taskInfo.topActivity?.className}]&quot;)
}
</code></pre>
<figure data-type="image" tabindex="1"><img src="https://Joshua-Chang.github.io/post-images/1622973147070.png" alt="" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[从MessageQueue视角理解Handler]]></title>
        <id>https://Joshua-Chang.github.io/post/cong-messagequeue-shi-jiao-li-jie-handler/</id>
        <link href="https://Joshua-Chang.github.io/post/cong-messagequeue-shi-jiao-li-jie-handler/">
        </link>
        <updated>2021-04-23T12:09:57.000Z</updated>
        <content type="html"><![CDATA[<p><em>本文适合对Handler有过了解，~~即使又忘了。~~但对网上的&lt;&lt;loop轮询转圈图&gt;&gt;有点印象的玩家。</em></p>
<p><strong>前置概念</strong></p>
<hr>
<p><strong>同步屏障消息</strong></p>
<ol>
<li>作用：系统使用的特殊的消息，可以看作优先处理异步消息的标识，当MessageQueue的队首是<strong>同步屏障消息时</strong>，忽略同步消息，一直执行最近的异步消息。通过<code>postSyncBarrier</code>/<code>removeSyncBarrier</code>增删同步屏障消息，非手动移除不会自动移除。</li>
<li>特点：<code>target</code>属性为空的<code>Message</code>就是同步屏障消息</li>
<li>事例：<code>ViewRootImpl.scheduleTraversals</code> 优先处理异步消息</li>
</ol>
<p><strong>IdleHandler</strong></p>
<ol>
<li>作用：闲时<code>Handler</code>，在没有消息或消息未到触发时机这样的闲时，执行的操作。</li>
<li>特点：是<code>MessageQueue</code>的静态接口，使用时复写<code>boolean queueIdle()</code>的方法执行闲时操作，返回值表示执行后是否保持存活状态。<br>
<strong>epoll</strong></li>
</ol>
<p><a href="https://segmentfault.com/a/1190000003063859">Linux IO模式及 select、poll、epoll详解</a></p>
<p><strong>正文</strong></p>
<hr>
<p><em>废话一下基本原理先</em></p>
<p>使用者通过<code>Handler</code>外部暴露的方法，向处于目标线程<code>TLS</code>的<code>Looper</code>内的消息队列输入消息；</p>
<p>消息队列及时/延时地取出消息，并分发处理。以达到调度或延时地操作。</p>
<p><code>Handler</code>通过<code>MessageQueue.enqueueMessage(msg,when)</code>入队消息</p>
<p><code>Looper.loop</code>通过<code>MessageQueue.next()</code>出队消息</p>
<h2 id="messagequeue">MessageQueue</h2>
<p>MessageQueue的关键变量<code>mMessages</code>：</p>
<p>消息队列实例，把消息根据触发时机早晚排列。具体代码表现为单链表的节点，代指队首（链表头）消息。</p>
<pre><code class="language-mermaid">graph LR
1[A 延迟:1s]--next--&gt;2[B 延迟:2s]--next--&gt;3[C 延迟:3s]--next--&gt;5[D 延迟:5s]
</code></pre>
<p><strong>入队出对</strong></p>
<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/9898b6b674c646eb9b9fa60b69be3714~tplv-k3u1fbpfcp-watermark.image" alt="截屏2021-04-23 上午2.10.15.png" style="zoom:50%;" />
<ol>
<li>入队方法<code>enqueueMessage()</code>，往队列存延迟触发的消息，并根据触发时间排好队。</li>
<li>出队方法<code>next()</code>一直死循环遍历队列，有到达触发时机的消息就取出消息。</li>
</ol>
<p><strong>阻塞/休眠</strong>：</p>
<p>怎么能让入队消息的延迟触发呢？</p>
<pre><code>先阻塞住next()方法，让其无法取消息。时间到了，在把阻塞恢复，取出消息即可。
</code></pre>
<p>队列内根本没消息，出队方法还一直死循环取消息，怎么办？</p>
<pre><code>没消息也阻塞住next()方法，让其无法取消息。有新消息插入时，再通知他去取。
</code></pre>
<table>
<thead>
<tr>
<th>队内的下条消息还有很久才到触发时机：先阻塞。</th>
<th>队内的根本没有消息：一直休眠到有消息。</th>
</tr>
</thead>
<tbody>
<tr>
<td><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1a84eb0ae8f54979815597c85ec0db50~tplv-k3u1fbpfcp-watermark.image" alt="截屏2021-04-23 上午2.21.31.png" style="zoom: 33%;" /></td>
<td><img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/426a3ab271e54dcaa5c8a6df04dcdab5~tplv-k3u1fbpfcp-watermark.image" alt="截屏2021-04-23 上午2.22.27.png" style="zoom: 33%;" /></td>
</tr>
</tbody>
</table>
<p><strong>具体做法</strong></p>
<p><code>next()</code>的取消息死循环中用<code>nativePollOnce(ptr, nextPollTimeoutMillis)</code>阻塞/休眠。</p>
<ul>
<li>消息的触发时机未到时，阻塞到触发时机到为止；</li>
<li>队列内一直没消息时，休眠直到有新消息入队，再用<code>enqueueMessage()</code>内的<code>nativeWake(mPtr)</code>唤醒。</li>
</ul>
<blockquote>
<p>本文中分别用<strong>阻塞</strong>和<strong>休眠</strong>只是做语义区分：是自己超时返回，还是被动触发唤醒。</p>
<p><code>nativePollOnce</code>传入的参数<code>timeout</code>通过JNI到Native层<code>Looper::pollOnce</code>-&gt;<code>Looper::pollInner</code> -&gt;<code>epoll_wait</code>方法。</p>
<p><code>epoll_wait</code>用 <code>epoll_create</code>创建的文件描述符A，去监听管道读取端文件描述符B的事件(使用<code>epoll_ctl</code>添加)。</p>
<ul>
<li>timeout&gt;0时，监听时长超过这个<code>timeout</code>仍没有事件就返回，中断阻塞。</li>
<li>timeout=-1，<code>epoll_wait</code>一直等待，直到新消息入队<code>enqueueMessage()</code>内<code>nativeWake(mPtr)</code>在Native层向管道写入端写入“W”，触发监听中断阻塞。同时清空管道数据。</li>
</ul>
<p>上边两种情形，都会给返回一种result，而<code>pollOnce</code>收到任何一种result都会退出。</p>
<p>epoll I/O复用机制是用一个文件描述符监听多个文件描述符的事件。</p>
<p>Looper.prepare -&gt; new Looper -&gt; new MessageQueue-&gt;nativeInit-&gt;native层NativeMessageQueue构造方法中实例化Looper的构造方法中初始化管道和<code>epoll_create</code>    <code>nativeWake</code>最终也是<code>Looper.wake</code></p>
</blockquote>
<h2 id="出队">出队</h2>
<p><code>nativePollOnce(ptr, nextPollTimeoutMillis)</code>方法参数<strong>nextPollTimeoutMillis</strong> (即下个消息的延迟时间的)取值情况。</p>
<table>
<thead>
<tr>
<th style="text-align:left">下个消息的延迟时间</th>
<th>消息队列内</th>
<th>阻塞情况</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">&gt;0</td>
<td>延迟最近的消息，触发时机未到</td>
<td>阻塞到触发时机</td>
<td>释放cpu资源</td>
</tr>
<tr>
<td style="text-align:left">=0</td>
<td>延迟最近的消息，触发时机到了</td>
<td>不阻塞</td>
<td></td>
</tr>
<tr>
<td style="text-align:left">=-1</td>
<td>根本没消息</td>
<td>休眠到有消息</td>
<td>释放cpu资源</td>
</tr>
</tbody>
</table>
<h3 id="流程解读">流程解读</h3>
<p><code>next()</code>出队方法，需要一个<code>Message</code>返回值。当<code>nativePollOnce</code>不再阻塞时，因为队列是按触发时机早晚排序的：</p>
<ol>
<li>
<p>通常应该取队首消息；</p>
</li>
<li>
<p>但是队首是同步屏障消息时【Barrier1】，应该取触发时机最近的异步消息。</p>
</li>
</ol>
<p>因此我们先取该msg，不管是队首还是最近异步，再判断是否应该将其返回和其他后续操作。</p>
<ul>
<li>
<p>当msg非空时【2】</p>
<ol>
<li>如果msg触发时机到达【3`】，则返回msg。（当然返回前要整理一下队列）</li>
<li>如果msg触发时机未到【3】，则重新计算触发时间，然后将 <strong>nextPollTimeoutMillis</strong> 设为新时间，然后像下文&quot;当msg为空时&quot;一样，进行是否有IdleHandler及对其处理的操作。【4】/【5，6】</li>
</ol>
</li>
<li>
<p>当msg为空时【2`】，先将 <strong>nextPollTimeoutMillis</strong> 设为-1</p>
<ol>
<li>如果也没有待处理的IdleHandler【4】：则跳出本次循环又回到<code>nativePollOnce</code>，此时<code>nextPollTimeoutMillis=-1</code>,阻塞至有新消息将其唤醒。</li>
<li>如果有待处理的IdleHandler：则遍历执行这些IdleHandler【5】（每次最多四个，执行其<code>queueIdle</code>回调），然后重置IdleHandler计数和<code>nextPollTimeoutMillis=0</code>完成本次循环【6】（<code>nextPollTimeoutMillis=0</code>让下次循环不再阻塞，以检查处理IdleHandler时是否又有新消息入队）。</li>
</ol>
</li>
</ul>
<pre><code class="language-java">Message next() {
    final long ptr = mPtr;/*MessageQueue 的native层地址*/
    if (ptr == 0) {//当消息循环已经退出,则直接返回
        return null;
    }
    int pendingIdleHandlerCount = -1; //待处理闲时handler数量
    int nextPollTimeoutMillis = 0;
    for (;;) {
        nativePollOnce(ptr, nextPollTimeoutMillis);//【1】阻塞：作用类似Java的 object.wait()
        synchronized (this) {
            final long now = SystemClock.uptimeMillis();
            Message prevMsg = null;
            Message msg = mMessages;/*next()的返回值：此时为队头消息，即最近消息*/
            if (msg != null &amp;&amp; msg.target == null) {//【Barrier1】如果队首是同步屏障消息，msg取最近的异步消息
		do {
                   prevMsg = msg;
                   msg = msg.next;
                } while (msg != null &amp;&amp; !msg.isAsynchronous());//msg不是异步消息时，从队头至队尾遍历每个消息，直到msg为异步消息才推出遍历
            }            
            if (msg != null) {//【2】取到待处理的msg
                if (now &lt; msg.when) {/*【3】时机未到：更新延迟时间*/
                    nextPollTimeoutMillis = (int) Math.min(msg.when - now, Integer.MAX_VALUE);
                } else {/*【3`】处理msg的时机已到：取出msg，并整理队列*/
                    mBlocked = false;/*是否被阻塞：设为false供存消息时用*/
                    if (prevMsg != null) {/*【Barrier1`】若msg是因同步屏障循，而取出的最近的异步消息，改变指针指向跳过msg*/
                        prevMsg.next = msg.next;
                    } else {/* 取出msg，更新下一条消息为队首*/
                        mMessages = msg.next;
                    }
                    msg.next = null;//即将作为返回值，next变得没意义，置空。
                    return msg;/* 返回next消息*/
                }
            } else {/*【2`】消息为空，即没有消息了*/
                nextPollTimeoutMillis = -1;/*没有消息了，nextPollTimeoutMillis设为-1。线程阻塞*/
            }
            
            /*------------------------------空闲handler处理----------------------------------*/
            /* Idlehandles仅在队列为空或队首消息时机未到时才运行*/
            if (pendingIdleHandlerCount &lt; 0
                    &amp;&amp; (mMessages == null || now &lt; mMessages.when)) {
                pendingIdleHandlerCount = mIdleHandlers.size();/*计算闲时任务量*/
            }
            if (pendingIdleHandlerCount &lt;= 0) {
                mBlocked = true;/*【4】若经过计算上个if计算，连闲时Handler都没有，跳出本次循环*/
                continue;
            }
            if (mPendingIdleHandlers == null) {/*必有闲时任务待处理，否则上个if就continue出去了*/
                mPendingIdleHandlers = new IdleHandler[Math.max(pendingIdleHandlerCount, 4)];
            }
            mPendingIdleHandlers = mIdleHandlers.toArray(mPendingIdleHandlers);
        }
        /*【5】必有闲时Handler需要遍历执行。连闲时Handler都没有的情况，在上文的if中continue出去。*/
        for (int i = 0; i &lt; pendingIdleHandlerCount; i++) {
            final IdleHandler idler = mPendingIdleHandlers[i];
                //【5.1】执行IdleHandler的queueIdle方法，运行IdelHandler，例如处理日志上报 Gc等通过返回值由自己决定是否保持存活状态
               idler.queueIdle();
        }
	/*【6】执行完闲时Handler重置闲时计数和下次延迟时间*/
        pendingIdleHandlerCount = 0;
        // 因为执行闲时Handler(步骤【5】不在synchronized中)过程中，可能有新消息enqueue，需要重新检查。
        // 下次延迟时间置0，下次循环到步骤【1】时不阻塞。
        nextPollTimeoutMillis = 0;
    }
}
</code></pre>
<h3 id="时序图">时序图</h3>
<figure data-type="image" tabindex="1"><img src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d7364839512144d3aecb9f4cd54ea3d4~tplv-k3u1fbpfcp-watermark.image" alt="截屏2021-04-23 下午1.41.54.png" loading="lazy"></figure>
<h2 id="入队">入队</h2>
<p><strong>关键变量</strong><code>mBlocked</code>：源码上的注释翻译过来：出队方法<code>next()</code>是否被阻塞在<code>pollOnce()</code>处（<code>nextPollTimeoutMillis≠0</code>）。记录<code>pollonce</code>是否被阻塞的目的就是：<strong>是否需要唤醒</strong></p>
<p>外部暴露操作方法的<code>Handler</code>类下，<code>send(empty)Message/post</code> +<code>atTime/delay/AtFrontOfQueue</code>等操作的最终归宿。<br>
<code>enqueueMessage(Message msg, long when)</code>：插入<code>msg</code>入队，<code>when</code>是自系统启动以来的非休眠运行时间（毫秒）。</p>
<blockquote>
<p>拓展： 插入msg一个到队首。</p>
<pre><code class="language-java">public final boolean sendMessageAtFrontOfQueue(Message msg) {//同理post也有类似方法
 MessageQueue queue = mQueue;
 return enqueueMessage(queue, msg, 0);
}
private boolean enqueueMessage(MessagdsieQueue queue, Message msg,
     long uptimeMillis) {
 return queue.enqueueMessage(msg, uptimeMillis);
}
</code></pre>
</blockquote>
<p><code>enqueueMessage(Message msg, long when)</code>：插入<code>msg</code>入队，<code>when</code>是自系统启动以来的非休眠运行时间（毫秒）。</p>
<h3 id="流程解读-2">流程解读</h3>
<p>入队一个消息，流程参考存消息的情况图，并对照下边的代码。</p>
<h4 id="情况一">情况【一】</h4>
<p>队列为空、新消息是即时消息、新消息是延时最短消息时</p>
<p>入队的新消息插入到队头的情况：都需要<code>nativeWake</code>唤醒 出队的<code>pollonce</code></p>
<table>
<thead>
<tr>
<th><strong>a.队列内没消息</strong></th>
<th><strong>b.新入队的消息延时为0</strong></th>
<th>c.新入队的消息比队首的触发时机还早，与b类似</th>
</tr>
</thead>
<tbody>
<tr>
<td><img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b1d1b60d3dcd4231b7dc9f00bf54704d~tplv-k3u1fbpfcp-watermark.image" alt="截屏2021-04-23 上午4.42.24.png" style="zoom:33%;" /></td>
<td><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5754fd2fe0ca4f1d88c26625ce245c27~tplv-k3u1fbpfcp-watermark.image" alt="截屏2021-04-23 上午4.43.42.png" style="zoom:33%;" /></td>
<td></td>
</tr>
</tbody>
</table>
<ol>
<li>通过改变队首消息和新消息的next指针指向，把消息插入。</li>
<li>是否需要唤醒<code>needWake = mBlocked</code>, 这时候出队<code>pollonce</code>处<strong>队列还没消息</strong>或<strong>最近消息时机未到</strong>，还被<strong>阻塞</strong>，<strong>mBlocked=true</strong>是必然的。然后<code>nativeWake</code>去唤醒<code>pollonce</code>去取刚存入的消息。</li>
</ol>
<h4 id="情况二">情况【二】</h4>
<p>新消息不是上述的情况，不插入到队首，而是插入到队列中部。先查找位置再插入。</p>
<table>
<thead>
<tr>
<th>队头是同步屏障消息</th>
<th>且插入的消息是最近的异步消息</th>
<th>插入的消息不是最近的异步消息</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td><img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/751b07ecd9094d3192904c99ffdcada2~tplv-k3u1fbpfcp-watermark.image" alt="截屏2021-04-23 上午5.03.37.png" style="zoom:33%;" /></td>
<td><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/15bbb1919f144d41a8082677781ded3d~tplv-k3u1fbpfcp-watermark.image" alt="截屏2021-04-23 上午5.04.16.png" style="zoom:33%;" /></td>
</tr>
<tr>
<td>是否需要唤醒</td>
<td>需要唤醒</td>
<td>不需要唤醒</td>
</tr>
</tbody>
</table>
<p><strong>除非队头是同步屏障消息，插入的消息是最近的异步消息</strong>，其他多数插入到队列中部的情况都不需唤醒</p>
<p>是否需要唤醒的条件<code>needWake = mBlocked &amp;&amp; p.target == null &amp;&amp; msg.isAsynchronous();</code></p>
<ol>
<li>出队<code>pollonce</code>处最近消息时机未到（经过上个if，队列现在非空），还被阻塞，<strong>mBlocked=true</strong>还是必然的。</li>
<li><code>p.target == null</code>队首p的target为空符合同步屏障消息特点。</li>
<li><code>msg.isAsynchronous()</code> 新插入队列中部的消息是异步消息。</li>
</ol>
<p>合起来<strong>唤醒条件</strong>就是：“<strong>队列内最近的消息触发时机未到，且队首消息是同步屏障消息时，新插入了一条异步消息</strong>”（还可能改变）。</p>
<p>然后再通过改变<code>next</code>指针指向，从队首至队尾遍历，查找合适的插入位置：</p>
<figure data-type="image" tabindex="2"><img src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ceb947d8d2954f5898eb54b66680b854~tplv-k3u1fbpfcp-watermark.image" alt="截屏2021-04-23 下午6.08.53.png" loading="lazy"></figure>
<ol>
<li><code>（when &lt; p.when）</code>即新消息触发时机早于该位置的触发时机，插入位置找到，跳出遍历。</li>
<li><code>p == null</code>遍历到末尾，新消息的触发时机比队内的消息都晚，插入位置为队尾，跳出遍历。</li>
<li>查找插入位置的过程中。如果发现异步消息，则新消息虽异步，但不是离触发最近的，无需唤醒。因此<strong>唤醒条件</strong>更新为：队首是同步屏障消息时，新插入的消息为<strong>离触发最近的异步消息</strong>。</li>
</ol>
<p>最后改变指针指向，把消息插入到对应位置。</p>
<pre><code class="language-java">boolean enqueueMessage(Message msg, long when) {    
    synchronized (this) {/*可能有多个不同线程发消息*/
        msg.when = when;
        Message p = mMessages;// p 赋值为队首。根据触发时机when 来排序
        boolean needWake;
        if (p == null || when == 0 || when &lt; p.when) {
          //【一】插入头部并唤醒：1、队列为空时 2、新消息延时为0是即时消息 3、新消息延时比队首的更短
            msg.next = p;
            mMessages = msg;
            needWake = mBlocked;/*出队方法next是否被阻塞在pollOnce()处（nextPollTimeoutMillis≠0）*/
        } else {//【二】消息插入MessageQueue中间，一般不需唤醒线程。除非队首同步屏障，且msg为!最近的!异步消息
            //【二a】队首是同步屏障消息，且插入的msg是异步消息。
            needWake = mBlocked &amp;&amp; p.target == null &amp;&amp; msg.isAsynchronous();
            Message prev;
            for (;;) {
                prev = p;
                p = p.next;
                /*prev、p 从队列的0、1 一直增至 last、null，来寻找msg合适的插入位置*/
                if (p == null /*last.next=null 插入到末尾*/|| when &lt; p.when/*（队列的p.when越来越大1235，when=4）*/
                    break;
                }
                if (needWake &amp;&amp; p.isAsynchronous()) {//【二b】插入的msg是异步消息是最近的
                    //在寻找msg插入位置过程中发现异步消息。说明msg前还有更早的异步消息。msg虽异步、但非最近。不需唤醒
                     needWake = false;
                }
            }
            /*经过循环确定插入位置，将入队的msg插入到prev与p中间 （3-5之间）*/
            msg.next = p; 
            prev.next = msg;
        }
        if (needWake) {
            nativeWake(mPtr);//【三】唤醒线程，nativePollOnce不在阻塞
        }
    }
    return true;
}
</code></pre>
<h3 id="流程图">流程图</h3>
<figure data-type="image" tabindex="3"><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2adc6671993c4434b420e4f5d4e21811~tplv-k3u1fbpfcp-watermark.image" alt="截屏2021-04-23 下午8.15.15.png" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[数据结构与算法01复杂度分析]]></title>
        <id>https://Joshua-Chang.github.io/post/shu-ju-jie-gou-yu-suan-fa-01-fu-za-du-fen-xi/</id>
        <link href="https://Joshua-Chang.github.io/post/shu-ju-jie-gou-yu-suan-fa-01-fu-za-du-fen-xi/">
        </link>
        <updated>2021-03-13T06:46:49.000Z</updated>
        <summary type="html"><![CDATA[<p>10 个数据结构：数组、链表、栈、队列、散列表、二叉树、堆、跳表、图、Trie 树；<br>
10 个算法：递归、排序、二分查找、搜索、哈希算法、贪心算法、分治算法、回溯算法、动态规划、字符串匹配算法。</p>
]]></summary>
        <content type="html"><![CDATA[<p>10 个数据结构：数组、链表、栈、队列、散列表、二叉树、堆、跳表、图、Trie 树；<br>
10 个算法：递归、排序、二分查找、搜索、哈希算法、贪心算法、分治算法、回溯算法、动态规划、字符串匹配算法。</p>
<!-- more -->
<p>通过统计、监控，就能得到算法执行的时间和占用的内存大小<strong>事后统计法</strong>有缺陷</p>
<ol>
<li>测试结果非常依赖测试环境</li>
<li>测试结果受数据规模的影响很大</li>
</ol>
<p>因此需要一个不用具体的测试数据来测试，就可以粗略地估计算法的执行效率的方法。即<strong>时间、空间复杂度分析方法</strong>。</p>
<h2 id="大-o-复杂度表示法">大 O 复杂度表示法</h2>
<pre><code class="language-java"> int cal(int n) {
   int sum = 0;//1
   int i = 1;//1
   int j = 1;//1
   for (; i &lt;= n; ++i) {//执行n次
     j = 1;//执行n次
     for (; j &lt;= n; ++j) {//执行n^2次
       sum = sum +  i * j;//执行n^2次
     }
   }
 }
</code></pre>
<p>假设每行代码执行的时间都一样，为 unit_time。</p>
<p>总的执行时间 T(n) = (2n^2+2n+3)*unit_time。</p>
<p><strong>代码总的执行时间 T(n) 与每行代码的执行次数n成正比</strong>，总结成公式为</p>
<blockquote>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>T</mi><mo>(</mo><mi>n</mi><mo>)</mo><mo>=</mo><mi>O</mi><mo>(</mo><mi>f</mi><mo>(</mo><mi>n</mi><mo>)</mo><mo>)</mo></mrow><annotation encoding="application/x-tex">T(n)=O(f(n))
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mopen">(</span><span class="mord mathdefault">n</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathdefault">n</span><span class="mclose">)</span><span class="mclose">)</span></span></span></span></span></p>
<p>n表示数据的规模大小</p>
<p>T(n)总代码执行的时间</p>
<p>f(n) 表示每行代码执行的次数总和是一个表达式。</p>
<p>O：表示代码的执行时间 T(n) 与 f(n)代码执行总次数表达式成正比。</p>
</blockquote>
<p>T(n) = O(2n^2+2n+3)。</p>
<h2 id="时间复杂度">时间复杂度</h2>
<p>时间复杂度的全称是<strong>渐进时间复杂度</strong>，<strong>表示算法的执行时间与数据规模之间的增长关系</strong>。</p>
<ol>
<li>
<p><strong>1. 只关注循环执行次数最多的一段代码</strong></p>
<p>大 O 这种复杂度表示方法只是表示一种变化趋势。我们通常会忽略掉公式中的常量、低阶、系数，只需要记录一个最大阶的量级就可以了。</p>
</li>
<li>
<p><strong>加法法则：总复杂度等于量级最大的那段代码的复杂度</strong></p>
<p>整体中有多个独立的复杂度操作，整体的复杂度为独立操作中最大的复杂度</p>
</li>
<li>
<p><strong>乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积</strong></p>
<p>嵌套循环复杂度为内外操作复杂度的乘积</p>
</li>
</ol>
<h3 id="常见时间复杂度">常见时间复杂度</h3>
<img src="https://Joshua-Chang.github.io/post-images/1615628804979.jpg" style="zoom: 50%;" />
<ol>
<li><strong>O(1)</strong><br>
代码的执行时间不随 n 的增大而增长。一般情况下，只要算法中不存在循环语句、递归语句，即使有成千上万行的代码，其时间复杂度也是Ο(1)。</li>
<li><strong>O(m+n)、O(m*n)</strong><br>
时间复杂度<strong>由两个数据的规模</strong>决定</li>
<li><strong>O(logn)、O(nlogn)</strong></li>
</ol>
<pre><code class="language-java">i=1;
while (i &lt;= n)  {
i = i * 2;
}
</code></pre>
<p>时间复杂度可转化成</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mn>2</mn><mi>i</mi></msup><mo>=</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">2^i=n
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8746639999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8746639999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">n</span></span></span></span></span></p>
<p>求i问题，结果为：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>l</mi><mi>o</mi><msub><mi>g</mi><mn>2</mn></msub><mi>n</mi></mrow><annotation encoding="application/x-tex">log_2n
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathdefault">n</span></span></span></span></span></p>
<p>以2为底n的对数，因此这段代码时间复杂度为</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>O</mi><mo>(</mo><mi>l</mi><mi>o</mi><msub><mi>g</mi><mn>2</mn></msub><mi>n</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">O(log_2n)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathdefault">n</span><span class="mclose">)</span></span></span></span></span></p>
<p>同理当循环内为 i = i * 3时因为对数间可以相互转换</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>l</mi><mi>o</mi><msub><mi>g</mi><mn>3</mn></msub><mi>n</mi><mo>=</mo><mi>l</mi><mi>o</mi><msub><mi>g</mi><mn>3</mn></msub><mn>2</mn><mo>∗</mo><mi>l</mi><mi>o</mi><msub><mi>g</mi><mn>2</mn></msub><mi>n</mi></mrow><annotation encoding="application/x-tex">log_3n=log_32 * log_2n
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathdefault">n</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathdefault">n</span></span></span></span></span></p>
<p>所以同理可得</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>O</mi><mo>(</mo><mi>l</mi><mi>o</mi><msub><mi>g</mi><mn>3</mn></msub><mi>n</mi><mo>)</mo><mo>=</mo><mi>O</mi><mo>(</mo><mi>C</mi><mo>∗</mo><mi>l</mi><mi>o</mi><msub><mi>g</mi><mn>2</mn></msub><mi>n</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">O(log_3n) = O(C * log_2n)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathdefault">n</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathdefault">n</span><span class="mclose">)</span></span></span></span></span></p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>C</mi><mo>=</mo><mi>l</mi><mi>o</mi><msub><mi>g</mi><mn>3</mn></msub><mn>2</mn></mrow><annotation encoding="application/x-tex">C=log_32
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">2</span></span></span></span></span></p>
<p>C是一个常量，忽略系数则复杂度相同。因此在对数阶时间复杂度的表示方法里，忽略对数的“底”。</p>
<p>如果一段代码的时间复杂度是 O(logn)，我们循环执行 n 遍，时间复杂度就为:</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>O</mi><mo>(</mo><mi>n</mi><mi>l</mi><mi>o</mi><msub><mi>g</mi><mi>n</mi></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">O(nlog_n)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathdefault">n</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p>
<p>归并排序、快速排序的时间复杂度都是这样。</p>
<p>常见的复杂度从低阶到高阶：O(1)、O(logn)、O(n)、O(nlogn)、O(n2 )</p>
<img src="https://Joshua-Chang.github.io/post-images/1615628794973.jpg" style="zoom: 33%;" />
<h2 id="空间复杂度分析">空间复杂度分析</h2>
<p>空间复杂度全称就是<strong>渐进空间复杂度</strong>（asymptotic space complexity），<strong>表示算法的存储空间与数据规模之间的增长关系</strong>。</p>
<h2 id="概率纬度">概率纬度</h2>
<p><strong>最好情况时间复杂度</strong>（best case time complexity）、<strong>最坏情况时间复杂度</strong>（worst case time complexity）、<strong>平均情况时间复杂度</strong>（average case time complexity）、<strong>均摊时间复杂度</strong>（amortized time complexity）。</p>
<pre><code class="language-java">// n 表示数组 array 的长度
int find(int[] array, int n, int x) {
  int i = 0;
  int pos = -1;
  for (; i &lt; n; ++i) {
    if (array[i] == x){
			pos = i;      
      break;
    } 
  }
  return pos;
}
</code></pre>
<p>在无序的数组中，查找变量的位置</p>
<p><strong>最好情况时间复杂度</strong>:遍历数组时第一位就是O(1)</p>
<p><strong>最坏情况时间复杂度</strong>:遍历数组完毕也没找到O(n)</p>
<p><strong>平均情况时间复杂度</strong>:变量在数组中的位置有n+1种情况（在数组中n种，不在1种）,求得其<strong>加权平均值</strong>为 (3n+1)/4。去掉系数和常量仍为O(n)</p>
<p><strong>均摊时间复杂度</strong>：</p>
<ol>
<li>insert() 在大部分情况下，时间复杂度都为 O(1)，个别情况下为 O(n)。</li>
<li>O(1) 时间复杂度的插入和 O(n) 时间复杂度的插入，的频率有前后时序关系规律。一个 O(n) 插入之后，紧跟着 n-1 个 O(1) 的插入，循环往复。</li>
</ol>
<p><strong>摊还分析法</strong>：把1次耗时多的 O(n) 的插入操作，均摊到接下来的 n-1 次耗时少的操作上。均摊时间复杂度就是 O(1)。</p>
<pre><code class="language-java"> int[] array = new int[n];
 int count = 0;
 void insert(int val) {
    if (count == array.length) {
       int sum = 0;
       for (int i = 0; i &lt; array.length; ++i) {
          sum = sum + array[i];
       }
       array[0] = sum;
       count = 1;
    }
 
    array[count] = val;
    ++count;
 }
</code></pre>
<p>对一个数据结构进行一组连续操作中，大部分情况下时间复杂度都很低，只有个别情况下时间复杂度比较高，而且这些操作之间存在前后连贯的时序关系，这个时候，我们就可以将这一组操作放在一块儿分析，看是否能将较高时间复杂度那次操作的耗时，平摊到其他那些时间复杂度比较低的操作上。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[ 计算机组成原理05处理器设计 下]]></title>
        <id>https://Joshua-Chang.github.io/post/ji-suan-ji-zu-cheng-yuan-li-05-chu-li-qi-she-ji-xia/</id>
        <link href="https://Joshua-Chang.github.io/post/ji-suan-ji-zu-cheng-yuan-li-05-chu-li-qi-she-ji-xia/">
        </link>
        <updated>2021-03-12T17:53:50.000Z</updated>
        <content type="html"><![CDATA[<img src="https://Joshua-Chang.github.io/post-images/1615571610811.png" style="zoom:25%;" />]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[ 计算机组成原理04处理器设计 上]]></title>
        <id>https://Joshua-Chang.github.io/post/ji-suan-ji-zu-cheng-yuan-li-04-chu-li-qi-she-ji-shang/</id>
        <link href="https://Joshua-Chang.github.io/post/ji-suan-ji-zu-cheng-yuan-li-04-chu-li-qi-she-ji-shang/">
        </link>
        <updated>2021-03-12T17:52:40.000Z</updated>
        <content type="html"><![CDATA[<p>指令+运算=CPU</p>
<p>“<strong>指令</strong>”部分，代码如何变成机器能够理解的指令，以及是按照什么样的顺序运行的。</p>
<p>“<strong>计算</strong>”部分，数据的二进制表示、加法和乘法又是通过什么样的电路来实现的。</p>
<p>本文把“指令”和“计算”连通起来，完整的 CPU 运转。</p>
<img src="https://Joshua-Chang.github.io/post-images/1615571610811.png" style="zoom:25%;" />
<h2 id="建立数据通路">建立数据通路</h2>
<h4 id="指令周期instruction-cycle">指令周期（Instruction Cycle）</h4>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[计算机组成原理03指令和运算 下]]></title>
        <id>https://Joshua-Chang.github.io/post/ji-suan-ji-zu-cheng-yuan-li-02-zhi-ling-he-yun-suan-xia/</id>
        <link href="https://Joshua-Chang.github.io/post/ji-suan-ji-zu-cheng-yuan-li-02-zhi-ling-he-yun-suan-xia/">
        </link>
        <updated>2021-03-12T08:00:23.000Z</updated>
        <summary type="html"><![CDATA[<p>程序 = 算法 + 数据结构</p>
<p>算法：各种计算机指令</p>
<p>数据结构：二进制数据</p>
]]></summary>
        <content type="html"><![CDATA[<p>程序 = 算法 + 数据结构</p>
<p>算法：各种计算机指令</p>
<p>数据结构：二进制数据</p>
<!-- more -->
<img src="https://Joshua-Chang.github.io/post-images/1615480260058.png" style="zoom:25%;" />
<h2 id="二进制">二进制</h2>
<p>二进制转十进制：从 0 开始，从右到左的第 N 位✖️2 的 N 次方，然后相加。</p>
<p>十进制转二进制：<strong>短除法</strong>，递归除以 2 的余数，从右往左填入，直到商0。</p>
<p>负数：一个 4 位的二进制数，补码最左侧的一位，当成正负号，0 为正数，1 为负数。这一位并非单独的符号位。在计算整个二进制值的时候，在左侧最高位前面加个正负号。 十进制−5，用4 位的二进制补码数值 1011。-2<sup>3+2</sup>1+2^0。首位前加负号：-8+2+1=-5。</p>
<h3 id="字符串">字符串</h3>
<p>最早计算机只需要使用英文字符，加上数字和一些特殊符号，然后用 8 位的二进制就能表示，即<strong>ASCII 码</strong>（American Standard Code for Information Interchange，美国信息交换标准代码）。ASCII 码就好比一个字典，用 8 位二进制中的 128 个不同的数，映射成 128 个不同的字符。<br>
<img src="https://Joshua-Chang.github.io/post-images/1615548790038.png" style="zoom: 33%;" /></p>
<blockquote>
<p>小写字母 a 在 ASCII 里面，就是第 97 个，8位二进制的 0110 0001，十六进制61</p>
<p>大写字母 A 在 ASCII 里面，就是第 65 个，8位二进制的 0100 0001，十六进制41</p>
<p>单个数字不再用整数表示法，反而用8位二进制，字符串数字9，第57个，用8位二进制0011 1001 ，十六进制39</p>
<p>字符串 数字15 不用 0000 1111 这 8 位来表示，而用两个 8 位来表示，即用两个字符 1 和 5 连续在一起，也就是 0011 0001 和 0011 0101。</p>
</blockquote>
<p>因此在存储数据的时候，采用二进制序列化这样的方式，而不是 CSV 或者 JSON，这样的文本格式。<strong>不管是整数也好，浮点数也好，采用二进制序列化会比存储文本省下不少空间。</strong></p>
<p>随着越来越多的不同国家的人都用上了计算机，ASCII 码128 个字符不够用。于是出现了不同的的<strong>字符集</strong>（Charset）和<strong>字符编码</strong>（Character Encoding）。</p>
<p>其中Unicode字符集，包含了 150 种语言的 14 万个不同的字符。</p>
<p>字符编码则是对于字符集里的字符，用二进制表示出来的一个字典。Unicode，可以用 UTF-8、UTF-16，UTF-32、GB2312等来进行编码，存储成二进制。解码和展示时使用不同的编码方式，就会出现乱码。</p>
<p><strong>ASCII 码</strong>是对有128个字符的“小字符集”的编码。编码的目的就是把文字二进制存储。</p>
<h2 id="理解电路">理解电路</h2>
<p>我们通过电路的“开”和“关”，来表示“1”和“0”，晶体管在不同的情况下，表现为导电的“1”和绝缘的“0”的状态。</p>
<p>一方面，我们可以通过继电器或者中继（Relay），进行长距离的信号传输。另一方面，我们也可以通过设置不同的线路和开关状态，实现更多不同的信号表示和处理方式，这些线路的连接方式就是我们在数字电路中所说的门电路。</p>
<blockquote>
<p>“与（AND）”：提供串联的两个开关，只有两个开关都打开，电路才接通</p>
<p>“或（OR）”：两条线路上各有一个开关，任何一个开关打开了，电路都接通</p>
<p>“非（NOT）”：数字电路中使用<strong>反向器</strong>（Inverter）</p>
</blockquote>
<p><strong>门电路</strong>是我们创建 CPU 和内存的基本逻辑单元。各种对于计算机二进制的“0”和“1”的门电路操作，叫作组合逻辑电路。<br>
<img src="https://Joshua-Chang.github.io/post-images/1615548823929.jpg" alt="" loading="lazy"></p>
<h2 id="加法器">加法器</h2>
<p><strong>bit</strong> （缩写b）位。是计算机存储数据的最小单位，只有0和1两种值。</p>
<p><strong>byte</strong>（缩写B）字节。是8个bit组成了信息的最小单位，也就是字节。来源于<strong>ASCII码</strong>有128个字符，需用8位表示。</p>
<p>二进制，从右往左数，第一列是个位，第二列是“二位”，对应的再往左，就应该分别是四位、八位。</p>
<h3 id="异或门">异或门</h3>
<p>四种个位数相加</p>
<figure data-type="image" tabindex="1"><img src="https://Joshua-Chang.github.io/post-images/1615548862709.jpg" alt="" loading="lazy"></figure>
<p>输入：4 种组合00、01、10、11。</p>
<p>输出：00/11 情况下输出0，10/01 情况下输出1</p>
<p>这种输入输出的对应关系即“异或门（XOR / ^）”。虽然在逻辑运算里面没有出现的形式，但作为一个基本电路。<strong>异或门就是一个最简单的整数加法所需要的基本门电路</strong>。</p>
<h3 id="半加器">半加器</h3>
<p>输入的是 11 的情况下，还需向更左侧进位。对应一个与门：即当且仅当加数和被加数都是 1 的时候，才进位 1。</p>
<p>通过一个<strong>异或门</strong>计算出个位，通过一个<strong>与门</strong>计算出是否进位，就通过电路算出了一个一位数的加法。<strong>我们把两个门电路打包，给它取一个名字，就叫作半加器</strong>（Half Adder）。<br>
<img src="https://Joshua-Chang.github.io/post-images/1615548907425.jpg" alt="" loading="lazy"></p>
<h3 id="全加器">全加器</h3>
<p>半加器不能计算“二位”，因为“二位”是加数、被加数、进位信号 三个数相加。<strong>我们用两个半加器和一个或门，就能组合成一个全加器</strong>。（此处的二位与非个位的其他位原理相同）</p>
<p>第一个半加器，个位的加法，得到是否进位 X 和对应的二个数加和后的结果 Y；</p>
<p>然后把结果 Y和右侧个位数相加后的进位信息 ，连接到第二个半加器上；</p>
<p>就产生一个是否进位的信号 V 和对应的加和后的结果 W 即二位的结果；</p>
<figure data-type="image" tabindex="2"><img src="https://Joshua-Chang.github.io/post-images/1615548945005.jpg" alt="" loading="lazy"></figure>
<p>最后把两个半加器的进位信息，输入或门连接起来。即两次加法中，任何一个需要进位，都向左侧进位。</p>
<p>（即使三个 bit 相加，即使 3 个 bit 都是 1，也最多会进一位）</p>
<p>有了全加器，对两个 8 bit 数相加变得容易，只要把 8 个全加器串联起来即可。个位的全加器的进位信号作为二位全加器的输入信号，二位全加器的进位信号再作为四位的全加器的进位信号。同理可扩展到 16 位、32 位，乃至 64 位。<br>
<img src="https://Joshua-Chang.github.io/post-images/1615548959815.jpg" alt="" loading="lazy"></p>
<p>对于这个8位串联全加器：</p>
<p>在最右侧个位，我们只需要用一个半加器，或者让全加器的进位输入始终是 0。</p>
<p>在最左侧的一位输出的进位信号，并不表示再进一位，而表示加法是否溢出。</p>
<p><strong>分层</strong><br>
<img src="https://Joshua-Chang.github.io/post-images/1615548968172.jpg" style="zoom: 10%;" /></p>
<p>在上面的一层，我们只需要考虑怎么用下一层的组件搭建出自己的功能，而不需要下沉到更低层的其他组件。就像你之前并没有深入学习过计算机组成原理，一样可以直接通过高级语言撰写代码，实现功能。</p>
<p>在硬件层面，通过门电路、半加器、全加器一层层搭出了加法器这样的功能组件。这些用来做算术逻辑计算的组件叫作 ALU，也就是算术逻辑单元。</p>
<p>当进一步打造强大的 CPU 时，我们不再关注最细颗粒的门电路，只需要把门电路组合而成的 ALU，当成一个能够完成基础计算的黑盒子就可以了。</p>
<h2 id="乘法器">乘法器</h2>
<p>实际的乘法，就退化成了位移和加法。</p>
<p>13×9 被乘数 13 表示成二进制是 1101，乘数 9 在二进制里面是 1001。<br>
<img src="https://Joshua-Chang.github.io/post-images/1615563769473.jpg" alt="" loading="lazy"></p>
<p>实际上，像 13×9 这样两个四位数的乘法，不需要把四次单位乘法的结果，用四组独立的开关单独都记录下来，然后再把这四个数加起来。</p>
<p>先拿乘数最右侧的个位乘以被乘数，然后把结果写入用来存放计算结果的开关里面，然后，把被乘数左移一位，把乘数右移一位，仍然用乘数去乘以被乘数，然后把结果加到刚才的结果上。反复重复这一步骤，直到不能再左移和右移位置。<br>
<img src="https://Joshua-Chang.github.io/post-images/1615563804280.jpg" alt="" loading="lazy"></p>
<blockquote>
<p>这里的控制测试，其实就是通过一个时钟信号，来控制左移、右移以及重新计算乘法和加法的时机。</p>
</blockquote>
<p>把乘法展开，变成了“<strong>加法 + 位移</strong>”来实现。 4 位数要进行 4 组“位移 + 加法”的操作。而且这 4 组操作还不能同时进行。因为<strong>下一组的加法要依赖上一组的加法后的计算结果，下一组的位移也要依赖上一组的位移的结果。这样，整个算法是“顺序”的，每一组加法或者位移的运算都需要一定的时间</strong>。</p>
<p>一个顺序乘法器硬件进行计算的时间复杂度是 O(N)。这里的 N，就是乘法的数里面的<strong>位数</strong>。</p>
<h3 id="电路并行">电路并行</h3>
<p>目前的乘法实现就像是单败淘汰赛</p>
<img src="https://Joshua-Chang.github.io/post-images/1615563936931.jpg" style="zoom:25%;" />
<p>我们 CPU 的硬件上，用更多的晶体管开关，来放下中间计算结果。把 O(https://Joshua-Chang.github.io/post-images/1615563995243.jpg&quot; style=&quot;zoom:25%;&quot; /&gt;</p>
<p>加法器中每一个全加器，都要等待上一个全加器，这个等待的时间叫作<strong>门延迟</strong>（Gate Delay）。每通过一个门电路，计作1“T”。全加器就已经有了 3T 的延迟（进位需要经过 3 个门电路），而 4 位整数，最高位的计算需要等待前面三个全加器的进位结果，即等 9T 延迟。</p>
<p>除了门延迟外，还有<strong>时钟频率</strong>，在上面的顺序乘法计算里面，如果我们想要用更少的电路，计算的中间结果需要保存在寄存器里面，然后等待下一个时钟周期的到来，控制测试信号才能进行下一次移位和加法。</p>
<p>因为电路是天然并行的，一个输入信号，可以同时传播到所有接通的线路当中。下图展示了加法器。如果完全展开电路，高位的进位和计算结果，可以和低位的计算结果同时获得。</p>
<blockquote>
<img src="https://Joshua-Chang.github.io/post-images/1615564005050.jpg" style="zoom:15%;" />
C4 是前 4 位的计算结果是否进位的门电路表示。因此一个 4 位整数最高位是否进位，展开门电路图，你会发现，我们只需要 3T 的延迟就可以拿到是否进位的计算结果。
</blockquote>
<p>电路天然的并行性。电路只要接通，输入的信号自动传播到了所有接通的线路里面，这其实也是硬件和软件最大的不同。</p>
<p>无论是把对应的门电路逻辑进行完全展开以减少门延迟，还是通过并行计算多个位的乘法，都把一个计算的电路变复杂了。而电路变复杂了，也就意味着晶体管变多了。通过更多的晶体管，就可以拿到更低的门延迟，以及用更少的时钟周期完成一个计算指令。</p>
<p>是用更少更简单的电路，但是需要更长的门延迟和时钟周期；还是用更复杂的电路，但是更短的门延迟和时钟周期来计算一个复杂的指令，就是RISC 和 CISC 的区别。</p>
<h2 id="浮点数和定点数">浮点数和定点数</h2>
<p>计算机通常用 16或32 个比特（bit）4/8byte来表示一个数，只能表示 2 的 32 次方个不同的数，差不多是 40 亿个。</p>
<p>实数集合是无限多的，让这 40 亿个数映射到实数集合上的哪些数呢？</p>
<h3 id="定点数的表示">定点数的表示</h3>
<p>每4bit来表示 0～9 的整数，32bit即可表示8个这样的正数，把最右边的 2 个 0～9 的整数，当成小数部分；把左边 6 个 0～9 的整数，当成整数部分。这样用 32 个bit，表示从 0 到 999999.99 共 1 亿个实数这种直观的表示法叫<a href="https://zh.wikipedia.org/wiki/%E4%BA%8C%E9%80%B2%E7%A2%BC%E5%8D%81%E9%80%B2%E6%95%B8"><strong>BCD 编码</strong></a>（Binary-Coded Decimal），用于超市、银行这样需要用小数记录金额。</p>
<p><strong>第一，这样的表示方式有点“浪费”</strong>：本来可以表示2^32约40亿个数，结果才表示了1亿个。</p>
<p><strong>第二，这样的表示方式没办法同时表示很大的数字和很小的数字。</strong></p>
<h3 id="浮点数的表示">浮点数的表示</h3>
<p><strong>浮点数</strong>（Floating Point），用科学计数法来表示实数。</p>
<p>因为这个数对应的小数点的位置是“浮动”的，它才被称为浮点数。随着指数位 e 的值的不同，小数点的位置也在变动。而BCD 编码的实数，小数点固定在某一位的方式称为<strong>定点数</strong>。</p>
<p><strong>IEEE</strong>标准定义了，用32 比特表示单精度的浮点数即 float 或者 float32 类型，用 64 比特表示双精度的浮点数即double 或者 float64 类型。</p>
<p>浮点数的组成分成三部分</p>
<p>单精度的 32 个比特如下，双精度则每部分bit增加一倍</p>
<figure data-type="image" tabindex="3"><img src="https://Joshua-Chang.github.io/post-images/1615571233192.jpg" alt="" loading="lazy"></figure>
<ol>
<li>第一部分是一个<strong>符号位</strong> S，用来表示是正数还是负数。浮点数都是有符号的。负数1正数0</li>
<li>接下来的8 bit组成<strong>指数位</strong> e。8bit能够表示的整数是 0～255，用 1～254 映射到 -126～127 这 254 个有正有负的数上。e作为指数可正可负，可以同时表示很大或很小的数。0和255单独表示。</li>
<li>最后是一个 23 bit组成的<strong>有效数位</strong>f</li>
</ol>
<p>最终浮点数表示为：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>(</mo><mo>−</mo><mn>1</mn><msup><mo>)</mo><mi>s</mi></msup><mo>∗</mo><mn>1.</mn><mi>f</mi><mo>∗</mo><msup><mn>2</mn><mi>e</mi></msup></mrow><annotation encoding="application/x-tex">(-1)^s*1.f*2^e
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">−</span><span class="mord">1</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7143919999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">s</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord">1</span><span class="mord">.</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.7143919999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7143919999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">e</span></span></span></span></span></span></span></span></span></span></span></span></p>
<p>在e=0且f=0时表示浮点数的0。当e=255且f=0时，s为0表示无穷大，s为1表示无穷小。</p>
<p>浮点数无论是表示还是计算其实都是近似计算，比如0.3、0.9难以用指数绝对表达。</p>
<h3 id="浮点数的二进制转化">浮点数的二进制转化</h3>
<p>浮点数二进制：<strong>符号位 s+ 指数位 e+ 有效位数 f</strong></p>
<h4 id="二进制小数转十进制小数">二进制小数转十进制小数</h4>
<p>0.1001</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>1</mn><mo>×</mo><msup><mn>2</mn><mi mathvariant="normal">−</mi></msup><mn>1</mn><mo>+</mo><mn>0</mn><mo>×</mo><msup><mn>2</mn><mi mathvariant="normal">−</mi></msup><mn>2</mn><mo>+</mo><mn>0</mn><mo>×</mo><msup><mn>2</mn><mi mathvariant="normal">−</mi></msup><mn>3</mn><mo>+</mo><mn>1</mn><mo>×</mo><msup><mn>2</mn><mi mathvariant="normal">−</mi></msup><mn>4</mn><mo>=</mo><mn>0.5625</mn></mrow><annotation encoding="application/x-tex">1×2^−1+0×2^−2+0×2^−3+1×2^−4=0.5625
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.904661em;vertical-align:-0.08333em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.821331em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">−</span></span></span></span></span></span></span></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">0</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.904661em;vertical-align:-0.08333em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.821331em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">−</span></span></span></span></span></span></span></span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">0</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.904661em;vertical-align:-0.08333em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.821331em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">−</span></span></span></span></span></span></span></span><span class="mord">3</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.821331em;vertical-align:0em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.821331em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">−</span></span></span></span></span></span></span></span><span class="mord">4</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">5</span><span class="mord">6</span><span class="mord">2</span><span class="mord">5</span></span></span></span></span></p>
<h4 id="十进制小数转二进制小数">十进制小数转二进制小数</h4>
<p>和整数的二进制表示采用“除以 2，然后看余数”的方式相反。</p>
<p>乘以 2，看是否超过 1。如果超过 1，我们就记下 1，并把结果减去 1；减去1的结果继续乘以2，进一步循环操作。</p>
<blockquote>
<p><img src="https://Joshua-Chang.github.io/post-images/1615571288146.jpg" alt="" loading="lazy"><br>
以0.1为例，0.000110011。这里的“0011”会无限循环下去。</p>
</blockquote>
<h4 id="例子">例子</h4>
<p><strong>十进制9.1的的二进制表示</strong></p>
<p>1001.000110011…</p>
<p>用科学记数法1.001000110011…×2^3</p>
<p>符号位 s = 0,有效位 f=00100011001100110011001共23位，指数 e=3</p>
<blockquote>
<p>因为指数位有正又有负，指数位在 127 之前代表负数，之后代表正数，那 3 其实对应的是加上 127 的偏移量 130，转化成二进制就是 10000010。</p>
</blockquote>
<figure data-type="image" tabindex="4"><img src="https://Joshua-Chang.github.io/post-images/1615571313898.jpg" alt="" loading="lazy"></figure>
<p>把“s+e+f”拼在一起，浮点数 9.1 的二进制表示为</p>
<p>01000<strong>0010</strong> 0010 <strong>0011001100110011</strong> <strong>001</strong></p>
<p>换算成十进制是 9.09999942779541015625</p>
<h3 id="浮点数的加法和精度损失">浮点数的加法和精度损失</h3>
<p>十进制的数值，转化成 IEEE-754 标准下的浮点数在做加法。</p>
<p>浮点数的加法是<strong>先对齐、再计算</strong>。</p>
<p>两个浮点数的指数位可能是不一样的，所以我们要把两个的指数位，变成一样的，然后只去计算有效位的加法。</p>
<h4 id="例子-2">例子</h4>
<p>0.5，表示成浮点数，指数位是 -1，有效位是 00…（后面全是 0，记住 f 前默认有一个 1）</p>
<p>0.125 表示成浮点数，对应的指数位是 -3，有效位也还是 00…（后面全是 0，记住 f 前默认有一个 1）</p>
<ol>
<li>指数位对齐：把指数位都统一成两个其中较大的 -1，0.125 的有效位 1.00…也要对应右移两位变成0.01。</li>
<li>然后计算两者相加的有效位 1.0+0.01=1.01</li>
<li>得到结果浮点数，符号位是0，指数位是 -1，有效位是1.01</li>
</ol>
<figure data-type="image" tabindex="5"><img src="https://Joshua-Chang.github.io/post-images/1615571340870.jpg" alt="" loading="lazy"></figure>
<h4 id="丢失精度">丢失精度</h4>
<p>浮点数的加法过程中，需要先对齐，其中指数位较小的数，需要在有效位进行右移，在右移的过程中，最右侧的有效位就被丢弃掉了。导致对应的指数位较小的数，在加法发生之前，就<strong>丢失精度</strong>。</p>
<p>两个相加数的指数位差的越大，位移的位数越大，可能丢失的精度也就越大。（丢失的有效位都是 0例外）</p>
<p>在32位浮点数中，有效位长度一共只有 23 位，指数位较小的数右移 24 位之后，所有的有效位就都丢失了。</p>
<p>因此32位浮点数实际计算中，只要两个数差出 2^24，那这两个数相加之后，结果完全不会变化。</p>
<h4 id="kahan-summation-算法">Kahan Summation 算法</h4>
<p>在一些“积少成多”的计算过程中，比如在机器学习中，我们经常要计算海量样本计算出来的梯度或者 loss，于是会出现几亿个浮点数的相加。每个浮点数可能都差不多大，但是随着累积值的越来越大，就会出现“大数吃小数”的情况。</p>
<p>Kahan累加算法：在每次的计算过程中，都用一次减法，把当前加法计算中损失的精度记录下来。然后在后面的循环中，把这个精度损失放在要加的小数上，再做一次运算。</p>
<pre><code class="language-java">public class KahanSummation {
  public static void main(String[] args) {
    float sum = 0.0f;
    float c = 0.0f;
    for (int i = 0; i &lt; 20000000; i++) {
    	float x = 1.0f;
    	float y = x - c;
    	float t = sum + y;
    	c = (t-sum)-y;
    	sum = t;    	
    }
    System.out.println(&quot;sum is &quot; + sum);   
  }	
}
</code></pre>
<p>一般情况下，在实践应用中，对于需要精确数值的，比如银行存款、电商交易，我们都会使用定点数或者整数类型。比如在 MySQL 里的 decimal(12,2)，</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[ 计算机组成原理02指令和运算 上]]></title>
        <id>https://Joshua-Chang.github.io/post/ji-suan-ji-zu-cheng-yuan-li-02-zhi-ling-he-yun-suan/</id>
        <link href="https://Joshua-Chang.github.io/post/ji-suan-ji-zu-cheng-yuan-li-02-zhi-ling-he-yun-suan/">
        </link>
        <updated>2021-03-11T09:41:24.000Z</updated>
        <summary type="html"><![CDATA[<p>从硬件角度来看，CPU 就是一个超大规模集成电路，通过电路实现了加法、乘法乃至各种各样的处理逻辑<br>
从软件角度讲，CPU 就是一个执行各种计算机指令（Instruction Code）的逻辑机器。计算机指令，就好比一门 CPU 能够听得懂的语言，我们也可以把它叫作机器语言（Machine Language）。</p>
]]></summary>
        <content type="html"><![CDATA[<p>从硬件角度来看，CPU 就是一个超大规模集成电路，通过电路实现了加法、乘法乃至各种各样的处理逻辑<br>
从软件角度讲，CPU 就是一个执行各种计算机指令（Instruction Code）的逻辑机器。计算机指令，就好比一门 CPU 能够听得懂的语言，我们也可以把它叫作机器语言（Machine Language）。</p>
<!-- more -->
<p>不同的 CPU 能够听懂的语言不太一样，即计算机指令集Instruction Set<br>
<img src="https://Joshua-Chang.github.io/post-images/1615480260058.png" style="zoom:25%;" /></p>
<h2 id="指令和机器码">指令和机器码</h2>
<ol>
<li>
<p>把高级语言程序翻译成汇编语言（ASM，Assembly Language）程序，的过程叫编译（Compile）成汇编代码</p>
</li>
<li>
<p>再用汇编器（Assembler）翻译成机器码（Machine Code），CPU 能够真正认识的计算机指令<br>
<img src="https://Joshua-Chang.github.io/post-images/1615460135310.png" style="zoom: 33%;" /><br>
<img src="https://Joshua-Chang.github.io/post-images/1615460148801.jpg" alt="" loading="lazy"></p>
</li>
</ol>
<blockquote>
<p>e.g.<br>
<img src="https://Joshua-Chang.github.io/post-images/1615460725402.jpg" alt="" loading="lazy"><br>
MIPS 的指令是一个 32 位的整数，高 6 位叫操作码（Opcode），分别是 R、I 和 J，代表这条指令具体的操作类别。rt、rt、rd均为寄存器地址。<br>
R 指令是一般用来做算术和逻辑操作，里面有读取和写入数据的寄存器的地址。如果是逻辑位移操作，后面还有位移操作的位移量，而最后的功能码，则是在前面的操作码不够的时候，扩展操作码表示对应的具体指令的。</p>
<p>I 指令，则通常是用在数据传输、条件分支，以及在运算的时候使用的并非变量还是常数的时候。这个时候，没有了位移量和操作码，也没有了第三个寄存器，而是把这三部分直接合并成了一个地址值或者一个常数。</p>
<p>J 指令就是一个跳转指令，高 6 位之外的 26 位都是一个跳转后的地址。</p>
<p><code>add $t0,$s2,$s1</code>为例 s1 17    s2 18      t0 8<br>
<img src="https://Joshua-Chang.github.io/post-images/1615461145867.jpg" alt="" loading="lazy"><br>
<img src="https://Joshua-Chang.github.io/post-images/1615461154758.png" style="zoom: 15%;" /></p>
</blockquote>
<p>除了 C 这样的编译型的语言之外，Python 这样的解释型语言，是通过解释器在程序运行的时候逐句翻译，而 Java 这样使用虚拟机的语言，则是由虚拟机对编译出来的中间代码进行解释，或者即时编译(JIT)成为机器码来最终执行。</p>
<h2 id="指令跳转">指令跳转</h2>
<blockquote>
<p>CPU 其实就是由一堆寄存器组成的。而寄存器是由多个触发器（Flip-Flop）或者锁存器（Latches）组成的简单电路。</p>
<p>N 个触发器或者锁存器，就可以组成一个 N 位（Bit）的寄存器，能够保存 N 位的数据。比方说，我们用的 64 位 Intel 服务器，寄存器就是 64 位的。</p>
</blockquote>
<h3 id="cpu-里面的寄存器">CPU 里面的寄存器：</h3>
<p>一个是<strong>PC 寄存器</strong>（Program Counter Register），我们也叫<strong>指令地址寄存器</strong>（Instruction Address Register）。它就是用来存放下一条需要执行的计算机指令的内存地址。</p>
<p>第二个是<strong>指令寄存器</strong>（Instruction Register），用来存放当前正在执行的指令。</p>
<p>第三个是<strong>条件码寄存器</strong>（Status Register），用里面的一个一个标记位（Flag），存放 CPU 进行算术或者逻辑计算的结果。<strong>零标志条件码</strong>（对应的条件码是 ZF，Zero Flag 不等为0）、<strong>进位标志</strong>（CF，Carry Flag A&gt;B 为0）、<strong>符号标志</strong>（SF，Sign Flag正数为0）以及<strong>溢出标志</strong>（OF，Overflow Flag）</p>
<p>其他用来存储数据和内存地址的寄存器：通常根据存放的数据内容来给它们取名字，比如整数寄存器、浮点数寄存器、向量寄存器和地址寄存器等等，通用寄存器（既可以存放数据，又能存放地址）</p>
<p>一个程序执行的时候，CPU 会根据 PC 寄存器里的地址，从内存里面把需要执行的指令，读取到指令寄存器里面执行，然后顺序读取下一条指令。<br>
<img src="https://Joshua-Chang.github.io/post-images/1615472744523.jpg" alt="" loading="lazy"></p>
<h3 id="ifelse">if…else</h3>
<pre><code class="language-c">#include &lt;time.h&gt;
#include &lt;stdlib.h&gt;
int main()
{
  srand(time(NULL));
  int r = rand() % 2;
  int a = 10;
  if (r == 0)
  {
    a = 1;
  } else {
    a = 2;
  } 
}
</code></pre>
<pre><code class="language-shell">$ gcc -g -c test.c
$ objdump -d -M intel -S test.o 
</code></pre>
<p><strong>汇编代码</strong></p>
<p>r == 0 的条件判断，被编译成了 cmp 和 jne 这两条指令</p>
<p>cmp 指令比较了前后两个操作数的值： 操作对象1 - 操作对象2 但不保存结果，只是根据结果修改相应的标志位。</p>
<ol>
<li>DWORD PTR 代表操作的数据类型是 32 位的整数，[rbp-0x4] 则是一个寄存器的地址。</li>
<li>第二个操作数 0x0 就是我们设定的常量 0 的 16 进制表示</li>
</ol>
<p>cmp 指令的比较结果，会存入到<strong>条件码寄存器</strong>当中去，<strong>零标志条件码</strong>ZF 相等为1，不等为0</p>
<p>cmp 指令执行完成之后，PC 寄存器会自动自增，开始执行下一条 jne 的指令</p>
<p>jne 指令： jump not equal 查看零标志位ZF不等于0，则跳转到4a（当跳转发生的时候，PC 寄存器就不再是自增变成下一条指令的地址）</p>
<p>CPU 再把 4a 地址里的指令加载到指令寄存器中来执行，mov 指令把 2 设置到对应的寄存器里去，相当于一个赋值操作。然后，PC 寄存器里的值继续自增，执行下一条 mov 指令。</p>
<p>mov 指令的第一个操作数 eax，代表累加寄存器，这条指令其实没有实际的作用，它的作用是一个占位符。</p>
<p>if 条件满足的话，在赋值的 mov 指令执行完成之后，有一个 jmp 的无条件跳转指令，跳转的地址就是51。</p>
<p>main 函数没有设定返回值，而 mov eax, 0x0 其实就是给 main 函数生成了一个默认的为 0 的返回值到累加器里面。</p>
<pre><code class="language-shell"> if (r == 0)
  3b:   83 7d fc 00             cmp    DWORD PTR [rbp-0x4],0x0 //只比较，结果存入标识位
  3f:   75 09                   jne    4a &lt;main+0x4a&gt; //标识位ZF不等于0则执行
    {
        a = 1;
  41:   c7 45 f8 01 00 00 00    mov    DWORD PTR [rbp-0x8],0x1
  48:   eb 07                   jmp    51 &lt;main+0x51&gt;
    }
    else
    {
        a = 2;
  4a:   c7 45 f8 02 00 00 00    mov    DWORD PTR [rbp-0x8],0x2
  51:   b8 00 00 00 00          mov    eax,0x0
    } 
</code></pre>
<figure data-type="image" tabindex="1"><img src="https://Joshua-Chang.github.io/post-images/1615472764389.jpg" alt="" loading="lazy"></figure>
<h3 id="forwhile">for/while</h3>
<p>对应的循环也是用 1e 这个地址上的 cmp 比较指令，和紧接着的 jle 条件跳转指令来实现的。</p>
<p>jle 跳转的地址，是在这条指令之前的地址 14。往前跳转使得，PC 寄存器会把指令地址设置到之前执行过的指令位置，重新执行之前执行过的指令，直到条件不满足，顺序往下执行 jle 之后的指令，整个循环才结束。<br>
<img src="https://Joshua-Chang.github.io/post-images/1615472775030.jpg" alt="" loading="lazy"></p>
<p>除了简单地通过 PC 寄存器自增的方式顺序执行外，条件码寄存器会记录下当前执行指令的条件判断状态，然后通过跳转指令读取对应的条件码，修改 PC 寄存器内的下一条指令的地址，最终实现 if…else 以及 for/while 这样的程序控制流程。</p>
<h2 id="函数调用">函数调用</h2>
<blockquote>
<p>函数调用和 if…else 和 for/while 循环有点像。都是在原来顺序执行的指令过程里，执行了一个内存地址的跳转指令，让指令从原来顺序执行的过程里跳开，从新的跳转后的位置开始执行。</p>
<p>区别是，if…else 和 for/while 的跳转，是跳转走了就不再回来了，就在跳转后的新地址开始顺序地执行指令。</p>
<p>而函数调用的跳转，在对应函数的指令执行完了之后，还要再回到函数调用的地方，继续执行 call 之后的指令。</p>
<p>把被调用函数的指令直接插入在调用处的方法不太好。那就把后面要跳回来执行的指令地址给记录下来。</p>
</blockquote>
<p>我们在内存里面开辟一段空间，用栈这个<strong>后进先出</strong>（LIFO，Last In First Out）的数据结构。</p>
<p>每次程序调用函数之前，都把函数调用完成后的返回地址、参数数据等开辟一块内存空间，即<strong>栈帧</strong>（Stack Frame）。<strong>压栈</strong>。如果函数执行完了，这就<strong>出栈</strong>。栈底的内存地址是在一开始就固定的，而一层层压栈之后，栈顶的内存地址是在逐渐变小。</p>
<p>指令地址本身的压栈和出栈是在 call 和 ret 的部分进行的。</p>
<p>call 的同时进行了一次 push把PC寄存器里面的内容压栈了，而在 ret 的时候 pop 把这部分数据出栈写回到PC寄存器里面了。</p>
<pre><code class="language-c">// function_example.c
#include &lt;stdio.h&gt;
int static add(int a, int b)
{
    return a+b;
}
int main()
{
    int x = 5;
    int y = 10;
    int u = add(x, y);
}
</code></pre>
<pre><code class="language-shell">int static add(int a, int b)
{
   0:   55                      push   rbp //压栈register base pointer原栈帧指针
   1:   48 89 e5                mov    rbp,rsp //register stack pointer当前栈指针
   4:   89 7d fc                mov    DWORD PTR [rbp-0x4],edi
   7:   89 75 f8                mov    DWORD PTR [rbp-0x8],esi
    return a+b;
   a:   8b 55 fc                mov    edx,DWORD PTR [rbp-0x4]
   d:   8b 45 f8                mov    eax,DWORD PTR [rbp-0x8]
  10:   01 d0                   add    eax,edx
}
  12:   5d                      pop    rbp //将当前的栈顶出栈
  13:   c3                      ret //出栈 到call调用时PC里的下一条地址  
0000000000000014 &lt;main&gt;:
int main()
{
  14:   55                      push   rbp
  15:   48 89 e5                mov    rbp,rsp
  18:   48 83 ec 10             sub    rsp,0x10
    int x = 5;
  1c:   c7 45 fc 05 00 00 00    mov    DWORD PTR [rbp-0x4],0x5
    int y = 10;
  23:   c7 45 f8 0a 00 00 00    mov    DWORD PTR [rbp-0x8],0xa
    int u = add(x, y);
  2a:   8b 55 f8                mov    edx,DWORD PTR [rbp-0x8]
  2d:   8b 45 fc                mov    eax,DWORD PTR [rbp-0x4]
  30:   89 d6                   mov    esi,edx
  32:   89 c7                   mov    edi,eax
  34:   e8 c7 ff ff ff          call   0 &lt;add&gt;//跳转后的程序地址 PC里的下一条地址等信息压栈
  39:   89 45 f4                mov    DWORD PTR [rbp-0xc],eax
  3c:   b8 00 00 00 00          mov    eax,0x0
}
  41:   c9                      leave  
  42:   c3                      ret    
</code></pre>
<h3 id="stack-overflow">stack overflow</h3>
<p>通过引入栈，函数调用只需要通过维持 rbp 和 rsp，这两个维护栈顶所在地址的寄存器，就能管理好不同函数之间的跳转。但函数调用层数太多，我们往栈里压入它存不下的内容，程序在执行的过程中就会遇到栈溢出的错误。（如：函数调用自己，并且不设任何终止条件）</p>
<p>除了无限递归，递归层数过深，在栈空间里面创建非常占内存的变量（比如一个巨大的数组），这些情况都很可能给你带来 stack overflow。</p>
<h3 id="函数内联inline">函数内联inline</h3>
<p>只要在 GCC 编译的时候，加上对应的一个让编译器自动优化的参数 -O，编译器就会在可行的情况下，进行这样的指令替换。或者在定义函数的地方，加上 inline 的关键字，来提示编译器对函数进行内联。</p>
<p>内联意味着，我们把可以复用的程序指令在调用它的地方完全展开了。</p>
<p>没有调用其他函数，只会被调用的函数，我们一般称之为<strong>叶子函数（或叶子过程）</strong></p>
<h2 id="elf和静态链接">ELF和静态链接</h2>
<blockquote>
<p><strong>C 语言代码 - 汇编代码 - 机器码</strong></p>
<p>这个描述把过程大大简化了。</p>
<p>通过 objdump 命令查看它们的汇编代码，发现两个程序的地址都是从 0 开始的，如果需要通过 call 指令调用函数的话，它怎么知道应该跳转到哪一个文件里呢？</p>
</blockquote>
<pre><code class="language-c">// add_lib.c
int add(int a, int b)
{
    return a+b;
}
</code></pre>
<pre><code class="language-c">// link_example.c
#include &lt;stdio.h&gt;
int main()
{
    int a = 10;
    int b = 5;
    int c = add(a, b);
    printf(&quot;c = %d\n&quot;, c);
}
</code></pre>
<pre><code class="language-shell">$ gcc -g -c add_lib.c link_example.c
$ objdump -d -M intel -S add_lib.o
$ objdump -d -M intel -S link_example.o
</code></pre>
<p>add_lib.o 以及 link_example.o 并不是一个<strong>可执行文件</strong>（Executable Program），而是<strong>目标文件</strong>（Object File）。</p>
<p>只有通过链接器（Linker）把多个目标文件以及调用的各种函数库链接起来，我们才能得到一个可执行文件。</p>
<pre><code class="language-shell">$ gcc -o link-example add_lib.o link_example.o
$ ./link_example
c = 15
</code></pre>
<p>“<strong>C 语言代码 - 汇编代码 - 机器码</strong>” 这个过程，在我们的计算机上进行的时候是由两部分组成的。</p>
<p>第一个部分由编译（Compile）、汇编（Assemble）以及链接（Link）三个阶段组成。在这三个阶段完成之后，我们就生成了一个可执行文件。</p>
<p>第二部分，我们通过装载器（Loader）把可执行文件装载（Load）到内存中。CPU 从内存中读取指令和数据，来开始真正执行程序。<br>
<img src="https://Joshua-Chang.github.io/post-images/1615482190792.jpg" style="zoom: 25%;" /></p>
<h3 id="elf-格式和链接">ELF 格式和链接</h3>
<p>可执行代码 通过objdump命令dump 出来的内容，不仅有编译成的汇编指令，还保留了很多别的数据。因为在 Linux 下，可执行文件和目标文件所使用的都是一种叫<strong>ELF</strong>（Execuatable and Linkable File Format）的文件格式，中文名字叫<strong>可执行与可链接文件格式</strong>。</p>
<p>ELF文件有三类:可重定向文件、可执行文件、共享目标文件。代码经过预处理、编译、汇编后形成可重定向文件，可重定向文件经过链接后生成可执行文件。</p>
<p>ELF 文件格式把各种信息，分成一个一个的 Section 保存起来。ELF 有一个基本的文件头（File Header），用来表示这个文件的基本属性，比如是否是可执行文件，对应的 CPU、操作系统等等<br>
<img src="https://Joshua-Chang.github.io/post-images/1615482163121.jpg" alt="" loading="lazy"><br>
除了这些基本属性之外，大部分程序还有这么一些 Section：</p>
<ol>
<li>首先是.text Section，也叫作<strong>代码段</strong>或者指令段（Code Section），用来保存程序的代码和指令；</li>
<li>接着是.data Section，也叫作<strong>数据段</strong>（Data Section），用来保存程序里面设置好的初始化数据信息；</li>
<li>然后就是.rel.text Secion，叫作<strong>重定位表</strong>（Relocation Table）。重定位表里，保留的是当前的文件里面，哪些跳转地址其实是我们不知道的。比如上面的 link_example.o 里面，我们在 main 函数里面调用了 add 和 printf 这两个函数，但是在链接发生之前，我们并不知道该跳转到哪里，这些信息就会存储在重定位表里；</li>
<li>最后是.symtab Section，叫作<strong>符号表</strong>（Symbol Table）。符号表保留了我们所说的当前文件里面定义的函数名称和对应地址的地址簿。</li>
</ol>
<h3 id="链接过程">链接过程</h3>
<img src="https://Joshua-Chang.github.io/post-images/1615482146761.jpg" style="zoom:50%;" />
<blockquote>
<p>链接器会扫描所有输入的目标文件，然后把所有符号表里的信息收集起来，构成一个全局的符号表。然后再根据重定位表，把所有不确定要跳转地址的代码，根据符号表里面存储的地址，进行一次修正。最后，把所有的目标文件的对应段进行一次合并，变成了最终的可执行代码。因此可执行文件里面的函数调用的地址都是正确的。</p>
</blockquote>
<h3 id="动态链接">动态链接</h3>
<p>在动态链接的过程中，我们想要“链接”的，不是存储在硬盘上的目标文件代码，而是加载到内存中的<strong>共享库</strong>（Shared Libraries）</p>
<blockquote>
<p>Windows 下，.dll 文件，Dynamic-Link Libary（DLL，动态链接库）。</p>
<p>Linux 下，这些共享库文件就是.so 文件，Shared Object（一般我们也称之为动态链接库）。</p>
<p>“动态链接”、“共享”</p>
</blockquote>
<p>在程序运行的时候共享代码，这些机器码必须是“<strong>地址无关</strong>”的。编译出来的共享库文件的指令代码，是地址无关码（Position-Independent Code）。动态代码库内部变量和函数调用要使用<strong>相对地址</strong>（Relative Address）<br>
<img src="https://Joshua-Chang.github.io/post-images/1615535954056.jpg" alt="" loading="lazy"><br>
虽然共享库用的都是同一段物理内存地址，但是在不同的应用程序里，它所在的虚拟内存地址是不同的。</p>
<h4 id="plt-got">PLT GOT</h4>
<pre><code class="language-c">// lib.c
#include &lt;stdio.h&gt;
void show_me_the_money(int money)
{
    printf(&quot;Show me USD %d from lib.c \n&quot;, money);
}
// show_me_poor.c
#include &quot;lib.h&quot;
int main()
{
    int money = 5;
    show_me_the_money(money);
}
</code></pre>
<pre><code class="language-shell">$ gcc lib.c -fPIC -shared -o lib.so
$ gcc -o show_me_poor show_me_poor.c ./lib.so
</code></pre>
<pre><code class="language-shell">……
0000000000400540 &lt;show_me_the_money@plt-0x10&gt;:
  400540:       ff 35 12 05 20 00       push   QWORD PTR [rip+0x200512]        # 600a58 &lt;_GLOBAL_OFFSET_TABLE_+0x8&gt;//全局偏移表GOT
  400546:       ff 25 14 05 20 00       jmp    QWORD PTR [rip+0x200514]        # 600a60 &lt;_GLOBAL_OFFSET_TABLE_+0x10&gt;
  40054c:       0f 1f 40 00             nop    DWORD PTR [rax+0x0]
 
0000000000400550 &lt;show_me_the_money@plt&gt;:
  400550:       ff 25 12 05 20 00       jmp    QWORD PTR [rip+0x200512]        # 600a68 &lt;_GLOBAL_OFFSET_TABLE_+0x18&gt;
  400556:       68 00 00 00 00          push   0x0
  40055b:       e9 e0 ff ff ff          jmp    400540 &lt;_init+0x28&gt;
……
0000000000400676 &lt;main&gt;:
....
  40068a:       e8 c1 fe ff ff          call   400550 &lt;show_me_the_money@plt&gt;
....//从PLT（程序链接表Procedure Link Table）里找要调用的函数,地址 400550 
……
</code></pre>
<p>在动态链接对应的共享库时，在共享库的 data section 里面，保存了一张<strong>全局偏移表</strong>（GOT，Global Offset Table）。<strong>虽然共享库的代码部分的物理内存是共享的，但是数据部分是各个动态链接它的应用程序里面各加载一份的。</strong><br>
<img src="https://Joshua-Chang.github.io/post-images/1615535922650.jpg" alt="" loading="lazy"><br>
不同的进程，调用同样的动态库，各自 GOT 里面指向最终加载的动态链接库里面的虚拟内存地址是不同的。</p>
<h3 id="延伸">延伸</h3>
<p>Windows 的可执行文件格式是一种叫作<strong>PE</strong>（Portable Executable Format）的文件格式。Linux 下的装载器只能解析 ELF 格式而不能解析 PE 格式，Linux 的Wine/ 微软的WSL，也就是 Windows Subsystem for Linux可以兼容</p>
<h2 id="程序装载">程序装载</h2>
<blockquote>
<p>在运行这些可执行文件的时候，我们其实是通过一个装载器，解析 ELF 或者 PE 格式的可执行文件。装载器会把对应的指令和数据加载到内存里面来，实际上装载器需要满足两个要求。</p>
<p><strong>第一，可执行程序加载后占用的内存空间应该是连续的</strong>。PC程序计数器是顺序地一条一条指令执行下去</p>
<p>**第二，我们需要同时加载很多个程序，并且不能让程序自己规定在内存中加载的位置。**因为我们现在的计算机通常会同时运行很多个程序，可能你想要的内存地址已经被其他加载了的程序占用了。</p>
</blockquote>
<h3 id="虚拟内存">虚拟内存</h3>
<p>在内存里面，找到一段连续的内存空间，然后分配给装载的程序，然后把这段连续的内存空间地址，和整个程序指令里指定的内存地址做一个映射。我们维护一个虚拟内存到物理内存的映射表，这样实际程序指令执行的时候，会通过虚拟内存地址，找到对应的物理内存地址，然后执行。因为是连续的内存地址空间，所以我们只需要维护映射关系的起始地址和对应的空间大小就可以了。</p>
<p>指令里用到的内存地址叫作<strong>虚拟内存地址</strong>（Virtual Memory Address），实际在内存硬件里面的空间地址，叫<strong>物理内存地址</strong>（Physical Memory Address）<br>
<img src="https://Joshua-Chang.github.io/post-images/1615484615617.png" alt="" loading="lazy"></p>
<h3 id="内存分段">内存分段</h3>
<p>这种找出一段连续的物理内存和虚拟内存地址进行映射的方法，我们叫<strong>分段</strong>（Segmentation）**。**这里的段，就是指系统分配出来的那个连续的内存空间。</p>
<p>缺点第一个就是<strong>内存碎片</strong>（Memory Fragmentation）的问题。<br>
<img src="https://Joshua-Chang.github.io/post-images/1615484604209.png" alt="" loading="lazy"><br>
解决的办法叫<strong>内存交换</strong>（Memory Swapping），即把不足够连续的程序占用的内存写到硬盘上，再从硬盘上读回来到内存里面，不过读回来的时候，我们不再把它加载到原来的位置，而是放在连续的位置。</p>
<h3 id="内存分页">内存分页</h3>
<p>硬盘的访问速度要比内存慢很多，因此简单的内存交换并不高效。</p>
<p><strong>和分段这样分配一整段连续的空间给到程序相比，分页是把整个物理内存空间切成一段段固定尺寸的大小</strong>。</p>
<p>对应的程序所需要占用的虚拟内存空间，也会同样切成一段段固定尺寸的大小。这样一个连续并且尺寸固定的内存空间，我们叫<strong>页</strong>（Page）。从虚拟内存到物理内存的映射，不再是拿整段连续的内存的物理地址，而是按照一个一个页来的。<br>
<img src="https://Joshua-Chang.github.io/post-images/1615484579925.png" alt="" loading="lazy"><br>
即使内存空间不够，需要让现有的、正在运行的其他程序，通过内存交换释放出一些内存的页出来更加高效。</p>
<p>分页的方式使得我们在加载程序的时候，不再需要一次性都把程序加载到物理内存中。</p>
<blockquote>
<p>在进行虚拟内存和物理内存的页之间的映射之后，并不真的把页加载到物理内存里，而是只在程序运行中，需要用到对应虚拟内存页里面的指令和数据时，再加载到物理内存里面去。当要读取特定的页，却发现数据并没有加载到物理内存里的时候，就会触发一个来自于 CPU 的<strong>缺页错误</strong>（Page Fault）。我们的操作系统会捕捉到这个错误，然后将对应的页，从存放在硬盘上的虚拟内存里读取出来，加载到物理内存里。可以运行那些远大于我们实际物理内存的程序</p>
</blockquote>
]]></content>
    </entry>
</feed>